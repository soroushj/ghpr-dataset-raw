{
  "active_lock_reason": null,
  "assignee": null,
  "assignees": [],
  "author_association": "NONE",
  "body": "**Is this a bug report or feature request?**\r\n* Bug Report\r\n\r\n**Deviation from expected behavior:**\r\nObserved a panic: \"invalid memory address or nil pointer dereference\" (runtime error: invalid memory address or nil pointer dereference) \r\n\r\n**Expected behavior:**\r\nOperator doesn't crash and starts upgrade process\r\n\r\n**How to reproduce it (minimal and precise):**\r\nNot sure how to reproduce. I can reproduce it by trying upgrade from 1.2.7 to 1.3.0 or 1.3.3.\r\n\r\n**File(s) to submit**:\r\n```\r\n2020-05-18 09:39:29.892669 I | rookcmd: starting Rook v1.3.0 with arguments '/usr/local/bin/rook ceph operator' \r\n2020-05-18 09:39:29.892920 I | rookcmd: flag values: --add_dir_header=false, --alsologtostderr=false, --csi-cephfs-plugin-template-path=/etc/ceph-csi/cephfs/csi-cephfsplugin.yaml, --csi-cephfs-provisioner-dep-template-path=/etc/ceph-csi/cephfs/csi-cephfsplugin-provisioner-dep.yaml, --csi-cephfs-provisioner-sts-template-path=/etc/ceph-csi/cephfs/csi-cephfsplugin-provisioner-sts.yaml, --csi-rbd-plugin-template-path=/etc/ceph-csi/rbd/csi-rbdplugin.yaml, --csi-rbd-provisioner-dep-template-path=/etc/ceph-csi/rbd/csi-rbdplugin-provisioner-dep.yaml, --csi-rbd-provisioner-sts-template-path=/etc/ceph-csi/rbd/csi-rbdplugin-provisioner-sts.yaml, --enable-discovery-daemon=true, --enable-flex-driver=false, --enable-machine-disruption-budget=false, --help=false, --kubeconfig=, --log-flush-frequency=5s, --log-level=INFO, --log_backtrace_at=:0, --log_dir=, --log_file=, --log_file_max_size=1800, --logtostderr=true, --master=, --mon-healthcheck-interval=45s, --mon-out-timeout=10m0s, --operator-image=, --service-account=, --skip_headers=false, --skip_log_headers=false, --stderrthreshold=2, --v=0, --vmodule= \r\n2020-05-18 09:39:29.892934 I | cephcmd: starting operator \r\n2020-05-18 09:39:29.990670 I | op-discover: rook-discover daemonset already exists, updating ... \r\n2020-05-18 09:39:30.009787 I | operator: rook-provisioner ceph.rook.io/block started using ceph.rook.io flex vendor dir \r\nI0518 09:39:30.009930       6 leaderelection.go:242] attempting to acquire leader lease  rook-ceph/ceph.rook.io-block... \r\n2020-05-18 09:39:30.010519 I | operator: rook-provisioner rook.io/block started using rook.io flex vendor dir \r\n2020-05-18 09:39:30.010559 I | operator: Watching all namespaces for cluster CRDs \r\n2020-05-18 09:39:30.010575 I | op-cluster: start watching clusters in all namespaces \r\nI0518 09:39:30.010616       6 leaderelection.go:242] attempting to acquire leader lease  rook-ceph/rook.io-block... \r\n2020-05-18 09:39:30.010654 I | op-cluster: Enabling hotplug orchestration: ROOK_DISABLE_DEVICE_HOTPLUG=false \r\n2020-05-18 09:39:30.010681 I | operator: setting up the controller-runtime manager \r\n2020-05-18 09:39:30.194019 I | op-cluster: starting cluster in namespace rook-ceph \r\n2020-05-18 09:39:30.920876 I | operator: starting the controller-runtime manager \r\n2020-05-18 09:39:31.505195 I | ceph-csi: detecting the ceph csi image version for image \"quay.io/cephcsi/cephcsi:v2.0.1\" \r\n2020-05-18 09:39:33.732772 I | ceph-spec: \"ceph-file-controller\": operator is not ready to run ceph command, cannot reconcile yet. \r\n2020-05-18 09:39:34.316773 I | ceph-csi: Detected ceph CSI image version: \"v2.0.1\" \r\n2020-05-18 09:39:34.366558 I | ceph-csi: successfully created csi config map \"rook-ceph-csi-config\" \r\n2020-05-18 09:39:37.518121 I | ceph-csi: CSIDriver CRD already had been registered for \"rook-ceph.rbd.csi.ceph.com\" \r\n2020-05-18 09:39:37.527757 I | ceph-csi: CSIDriver CRD already had been registered for \"rook-ceph.cephfs.csi.ceph.com\" \r\n2020-05-18 09:39:37.527804 I | operator: successfully started Ceph CSI driver(s) \r\n2020-05-18 09:39:43.594838 I | op-cluster: detecting the ceph image version for image ceph/ceph:v14.2.4-20190917... \r\n2020-05-18 09:39:44.017581 I | ceph-spec: \"ceph-file-controller\": operator is not ready to run ceph command, cannot reconcile yet. \r\n2020-05-18 09:39:46.047015 I | op-cluster: Detected ceph image version: \"14.2.4-0 nautilus\" \r\n2020-05-18 09:39:46.047090 E | op-cluster: failed the ceph version check. the version does not meet the minimum version \"14.2.5-0 nautilus\" \r\n2020-05-18 09:39:46.047111 I | op-client: start watching client resources in namespace \"rook-ceph\" \r\n2020-05-18 09:39:46.047124 I | op-bucket-prov: Ceph Bucket Provisioner launched \r\nI0518 09:39:46.049411       6 manager.go:118] objectbucket.io/provisioner-manager \"msg\"=\"starting provisioner\"  \"name\"=\"ceph.rook.io/bucket\" \r\nE0518 09:39:46.049452       6 runtime.go:78] Observed a panic: \"invalid memory address or nil pointer dereference\" (runtime error: invalid memory address or nil pointer dereference) \r\ngoroutine 45 [running]: \r\nk8s.io/apimachinery/pkg/util/runtime.logPanic(0x1df0c80, 0x35de520) \r\n\t/home/rook/go/pkg/mod/k8s.io/apimachinery@v0.17.2/pkg/util/runtime/runtime.go:74 +0xa3 \r\nk8s.io/apimachinery/pkg/util/runtime.HandleCrash(0x0, 0x0, 0x0) \r\n\t/home/rook/go/pkg/mod/k8s.io/apimachinery@v0.17.2/pkg/util/runtime/runtime.go:48 +0x82 \r\npanic(0x1df0c80, 0x35de520) \r\n\t/usr/local/go/src/runtime/panic.go:679 +0x1b2 \r\ngithub.com/rook/rook/pkg/operator/ceph/cluster.(*ClusterController).initializeCluster(0xc00049b280, 0xc000172900, 0xc00034a000) \r\n\t/home/rook/go/src/github.com/rook/rook/pkg/operator/ceph/cluster/controller.go:520 +0x512 \r\ngithub.com/rook/rook/pkg/operator/ceph/cluster.(*ClusterController).onAdd(0xc00049b280, 0x208f8c0, 0xc0003e7c00) \r\n\t/home/rook/go/src/github.com/rook/rook/pkg/operator/ceph/cluster/controller.go:290 +0x36a \r\nk8s.io/client-go/tools/cache.ResourceEventHandlerFuncs.OnAdd(...) \r\n\t/home/rook/go/pkg/mod/k8s.io/client-go@v0.17.2/tools/cache/controller.go:198 \r\nk8s.io/client-go/tools/cache.newInformer.func1(0x1e24d20, 0xc0006c4040, 0x1, 0xc0006c4040) \r\n\t/home/rook/go/pkg/mod/k8s.io/client-go@v0.17.2/tools/cache/controller.go:370 +0x1b6 \r\nk8s.io/client-go/tools/cache.(*DeltaFIFO).Pop(0xc0008e4c60, 0xc00078a090, 0x0, 0x0, 0x0, 0x0) \r\n\t/home/rook/go/pkg/mod/k8s.io/client-go@v0.17.2/tools/cache/delta_fifo.go:422 +0x230 \r\nk8s.io/client-go/tools/cache.(*controller).processLoop(0xc000364800) \r\n\t/home/rook/go/pkg/mod/k8s.io/client-go@v0.17.2/tools/cache/controller.go:153 +0x40 \r\nk8s.io/apimachinery/pkg/util/wait.JitterUntil.func1(0xc0009aafb0) \r\n\t/home/rook/go/pkg/mod/k8s.io/apimachinery@v0.17.2/pkg/util/wait/wait.go:152 +0x5e \r\nk8s.io/apimachinery/pkg/util/wait.JitterUntil(0xc003d27fb0, 0x3b9aca00, 0x0, 0xc0003e6e01, 0xc000590cc0) \r\n\t/home/rook/go/pkg/mod/k8s.io/apimachinery@v0.17.2/pkg/util/wait/wait.go:153 +0xf8 \r\nk8s.io/apimachinery/pkg/util/wait.Until(...) \r\n\t/home/rook/go/pkg/mod/k8s.io/apimachinery@v0.17.2/pkg/util/wait/wait.go:88 \r\nk8s.io/client-go/tools/cache.(*controller).Run(0xc000364800, 0xc000590cc0) \r\n\t/home/rook/go/pkg/mod/k8s.io/client-go@v0.17.2/tools/cache/controller.go:125 +0x2fd \r\ncreated by github.com/rook/rook/pkg/operator/k8sutil.WatchCR \r\n\t/home/rook/go/src/github.com/rook/rook/pkg/operator/k8sutil/customresource.go:68 +0x1ac \r\nI0518 09:39:46.213514       6 leaderelection.go:252] successfully acquired lease rook-ceph/rook.io-block \r\nI0518 09:39:46.213707       6 controller.go:780] Starting provisioner controller rook.io/block_rook-ceph-operator-85c78858b-smbzn_d7640b21-91f0-465e-92e2-56f3f51bf6ff! \r\nI0518 09:39:46.213771       6 event.go:281] Event(v1.ObjectReference{Kind:\"Endpoints\", Namespace:\"rook-ceph\", Name:\"rook.io-block\", UID:\"10dcf62a-de35-40a0-aa62-2084649f8a28\", APIVersion:\"v1\", ResourceVersion:\"99171895\", FieldPath:\"\"}): type: 'Normal' reason: 'LeaderElection' rook-ceph-operator-85c78858b-smbzn_d7640b21-91f0-465e-92e2-56f3f51bf6ff became leader \r\nI0518 09:39:46.314051       6 controller.go:829] Started provisioner controller rook.io/block_rook-ceph-operator-85c78858b-smbzn_d7640b21-91f0-465e-92e2-56f3f51bf6ff! \r\nI0518 09:39:46.485446       6 leaderelection.go:252] successfully acquired lease rook-ceph/ceph.rook.io-block \r\nI0518 09:39:46.485642       6 event.go:281] Event(v1.ObjectReference{Kind:\"Endpoints\", Namespace:\"rook-ceph\", Name:\"ceph.rook.io-block\", UID:\"339462b0-f678-4741-9d1c-bb3e2c6ada7d\", APIVersion:\"v1\", ResourceVersion:\"99171898\", FieldPath:\"\"}): type: 'Normal' reason: 'LeaderElection' rook-ceph-operator-85c78858b-smbzn_712b2a02-8d11-467b-ab0b-5fd986c45282 became leader \r\nI0518 09:39:46.485721       6 controller.go:780] Starting provisioner controller ceph.rook.io/block_rook-ceph-operator-85c78858b-smbzn_712b2a02-8d11-467b-ab0b-5fd986c45282! \r\nI0518 09:39:47.086065       6 controller.go:829] Started provisioner controller ceph.rook.io/block_rook-ceph-operator-85c78858b-smbzn_712b2a02-8d11-467b-ab0b-5fd986c45282! \r\n2020-05-18 09:39:54.319765 I | ceph-spec: \"ceph-file-controller\": operator is not ready to run ceph command, cannot reconcile yet. \r\n2020-05-18 09:40:04.608829 I | ceph-spec: \"ceph-file-controller\": operator is not ready to run ceph command, cannot reconcile yet. \r\n2020-05-18 09:40:14.996777 I | ceph-spec: \"ceph-file-controller\": operator is not ready to run ceph command, cannot reconcile yet. \r\n2020-05-18 09:40:25.323463 I | ceph-spec: \"ceph-file-controller\": operator is not ready to run ceph command, cannot reconcile yet. \r\npanic: runtime error: invalid memory address or nil pointer dereference \r\n[signal SIGSEGV: segmentation violation code=0x1 addr=0x38 pc=0x17f7c5b] \r\ngoroutine 822 [running]: \r\ngithub.com/rook/rook/pkg/operator/ceph/cluster/mon.(*Cluster).checkHealth(0xc0002eb180, 0x0, 0x0) \r\n\t/home/rook/go/src/github.com/rook/rook/pkg/operator/ceph/cluster/mon/health.go:82 +0xab \r\ngithub.com/rook/rook/pkg/operator/ceph/cluster/mon.(*HealthChecker).Check(0xc000b621c0, 0xc0000bc0c0) \r\n\t/home/rook/go/src/github.com/rook/rook/pkg/operator/ceph/cluster/mon/health.go:70 +0x13c \r\ncreated by github.com/rook/rook/pkg/operator/ceph/cluster.(*ClusterController).initializeCluster \r\n\t/home/rook/go/src/github.com/rook/rook/pkg/operator/ceph/cluster/controller.go:516 +0x387 \r\n```\r\n\r\n```\r\napiVersion: ceph.rook.io/v1\r\nkind: CephCluster\r\nmetadata:\r\n  annotations:\r\n    kubectl.kubernetes.io/last-applied-configuration: |\r\n      {\"apiVersion\":\"ceph.rook.io/v1\",\"kind\":\"CephCluster\",\"metadata\":{\"annotations\":{},\"name\":\"rook-ceph\",\"namespace\":\"rook-ceph\"},\"spec\":{\"cephVersion\":{\"image\":\"ceph/ceph:v14.2.4-20190917\"},\"crashCollector\":{\"disable\":false},\"dashboard\":{\"enabled\":true,\"ssl\":true},\"dataDirHostPath\":\"/var/lib/rook\",\"disruptionManagement\":{\"machineDisruptionBudgetNamespace\":\"openshift-machine-api\",\"osdMaintenanceTimeout\":30},\"external\":{\"enable\":false},\"mgr\":{},\"mon\":{\"count\":3},\"monitoring\":{\"rulesNamespace\":\"rook-ceph\"},\"network\":{\"hostNetwork\":false,\"provider\":\"\",\"selectors\":null},\"rbdMirroring\":{\"workers\":0},\"removeOSDsIfOutAndSafeToRemove\":false,\"storage\":{\"config\":null,\"nodes\":[{\"config\":null,\"directories\":[{\"config\":null,\"path\":\"/rook/storage-dir\"}],\"name\":\"z\",\"resources\":{\"limits\":{\"memory\":\"4Gi\"}}},{\"config\":null,\"directories\":[{\"config\":null,\"path\":\"/rook/storage-dir\"}],\"name\":\"y2\",\"resources\":{\"limits\":{\"memory\":\"4Gi\"}}},{\"config\":null,\"directories\":[{\"config\":null,\"path\":\"/rook/storage-dir\"}],\"name\":\"y3\",\"resources\":{\"limits\":{\"memory\":\"4Gi\"}}},{\"config\":null,\"directories\":[{\"config\":null,\"path\":\"/rook/storage-dir\"}],\"name\":\"y4\",\"resources\":{\"limits\":{\"memory\":\"4Gi\"}}},{\"config\":null,\"directories\":[{\"config\":null,\"path\":\"/rook/storage-dir\"}],\"name\":\"x\",\"resources\":{\"limits\":{\"memory\":\"4Gi\"}}}],\"storageClassDeviceSets\":null,\"useAllDevices\":false}}}\r\n  creationTimestamp: \"2020-03-13T17:01:38Z\"\r\n  finalizers:\r\n  - cephcluster.ceph.rook.io\r\n  generation: 91525\r\n  name: rook-ceph\r\n  namespace: rook-ceph\r\n  resourceVersion: \"99170961\"\r\n  selfLink: /apis/ceph.rook.io/v1/namespaces/rook-ceph/cephclusters/rook-ceph\r\n  uid: cb151e37-4e10-4b48-8513-eae25d8096db\r\nspec:\r\n  cephVersion:\r\n    image: ceph/ceph:v14.2.4-20190917\r\n  cleanupPolicy:\r\n    deleteDataDirOnHosts: \"\"\r\n  crashCollector:\r\n    disable: false\r\n  dashboard:\r\n    enabled: true\r\n    ssl: true\r\n  dataDirHostPath: /var/lib/rook\r\n  disruptionManagement:\r\n    machineDisruptionBudgetNamespace: openshift-machine-api\r\n    osdMaintenanceTimeout: 30\r\n  external:\r\n    enable: false\r\n  mgr: {}\r\n  mon:\r\n    count: 3\r\n  monitoring:\r\n    rulesNamespace: rook-ceph\r\n  network:\r\n    hostNetwork: false\r\n    provider: \"\"\r\n    selectors: null\r\n  rbdMirroring:\r\n    workers: 0\r\n  removeOSDsIfOutAndSafeToRemove: false\r\n  storage:\r\n    config: null\r\n    nodes:\r\n    - config: null\r\n      directories:\r\n      - config: null\r\n        path: /rook/storage-dir\r\n      name: z\r\n      resources:\r\n        limits:\r\n          memory: 4Gi\r\n    - config: null\r\n      directories:\r\n      - config: null\r\n        path: /rook/storage-dir\r\n      name: y2\r\n      resources:\r\n        limits:\r\n          memory: 4Gi\r\n    - config: null\r\n      devices:\r\n      - config: null\r\n        name: xvdb\r\n      name: y4\r\n      resources:\r\n        limits:\r\n          memory: 4Gi\r\n    - config: null\r\n      devices:\r\n      - config: null\r\n        name: sda5\r\n      name: x\r\n      resources:\r\n        limits:\r\n          memory: 4Gi\r\n    - config: null\r\n      devices:\r\n      - config: null\r\n        name: xvdb\r\n      name: y3\r\n      resources:\r\n        limits:\r\n          memory: 4Gi\r\n    - config: null\r\n      devices:\r\n      - config: null\r\n        name: xvdb\r\n      name: y5\r\n      resources:\r\n        limits:\r\n          memory: 4Gi\r\n    storageClassDeviceSets: null\r\n    useAllDevices: false\r\nstatus:\r\n  ceph:\r\n    details:\r\n      PG_NOT_DEEP_SCRUBBED:\r\n        message: 48 pgs not deep-scrubbed in time\r\n        severity: HEALTH_WARN\r\n      PG_NOT_SCRUBBED:\r\n        message: 20 pgs not scrubbed in time\r\n        severity: HEALTH_WARN\r\n    health: HEALTH_WARN\r\n    lastChanged: \"2020-05-12T20:20:54Z\"\r\n    lastChecked: \"2020-05-18T09:37:50Z\"\r\n    previousHealth: HEALTH_OK\r\n  conditions:\r\n  - lastHeartbeatTime: \"2020-05-18T09:38:28Z\"\r\n    lastTransitionTime: \"2020-05-18T09:38:28Z\"\r\n    status: \"False\"\r\n    type: Failure\r\n  - lastHeartbeatTime: \"2020-05-18T09:38:28Z\"\r\n    lastTransitionTime: \"2020-05-18T09:38:28Z\"\r\n    status: \"False\"\r\n    type: Ignored\r\n  - lastHeartbeatTime: \"2020-05-18T09:38:28Z\"\r\n    lastTransitionTime: \"2020-05-18T09:38:28Z\"\r\n    status: \"False\"\r\n    type: Upgrading\r\n  state: Created\r\n  version:\r\n    image: ceph/ceph:v14.2.4-20190917\r\n    version: 14.2.4-0\r\n```\r\n\r\n**Environment**:\r\n* OS (e.g. from /etc/os-release):\r\nFedora CoreOS\r\n* Kernel (e.g. `uname -a`):\r\nLinux x 5.5.17-200.fc31.x86_64 #1 SMP Mon Apr 13 15:29:42 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n* Cloud provider or hardware configuration:\r\nRancher kubernetes on Fedora CoreOS\r\n* Rook version (use `rook version` inside of a Rook Pod):\r\n1.3.X\r\n* Storage backend version (e.g. for ceph do `ceph -v`):\r\nv14.2.4-20190917\r\n* Kubernetes version (use `kubectl version`):\r\nClient Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.3\", GitCommit:\"2d3c76f9091b6bec110a5e63777c332469e0cba2\", GitTreeState:\"clean\", BuildDate:\"2019-08-19T11:13:54Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\r\nServer Version: version.Info{Major:\"1\", Minor:\"17\", GitVersion:\"v1.17.5\", GitCommit:\"e0fccafd69541e3750d460ba0f9743b90336f24f\", GitTreeState:\"clean\", BuildDate:\"2020-04-16T11:35:47Z\", GoVersion:\"go1.13.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\r\n* Kubernetes cluster type (e.g. Tectonic, GKE, OpenShift):\r\nRancher\r\n",
  "closed_at": "2020-05-20T16:17:18Z",
  "closed_by": {
    "avatar_url": "https://avatars3.githubusercontent.com/u/912735?v=4",
    "events_url": "https://api.github.com/users/leseb/events{/privacy}",
    "followers_url": "https://api.github.com/users/leseb/followers",
    "following_url": "https://api.github.com/users/leseb/following{/other_user}",
    "gists_url": "https://api.github.com/users/leseb/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/leseb",
    "id": 912735,
    "login": "leseb",
    "node_id": "MDQ6VXNlcjkxMjczNQ==",
    "organizations_url": "https://api.github.com/users/leseb/orgs",
    "received_events_url": "https://api.github.com/users/leseb/received_events",
    "repos_url": "https://api.github.com/users/leseb/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/leseb/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/leseb/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/leseb"
  },
  "comments": 9,
  "comments_url": "https://api.github.com/repos/rook/rook/issues/5498/comments",
  "created_at": "2020-05-18T09:50:17Z",
  "events_url": "https://api.github.com/repos/rook/rook/issues/5498/events",
  "html_url": "https://github.com/rook/rook/issues/5498",
  "id": 620070169,
  "labels": [
    {
      "color": "ee0000",
      "default": true,
      "description": "",
      "id": 405241115,
      "name": "bug",
      "node_id": "MDU6TGFiZWw0MDUyNDExMTU=",
      "url": "https://api.github.com/repos/rook/rook/labels/bug"
    }
  ],
  "labels_url": "https://api.github.com/repos/rook/rook/issues/5498/labels{/name}",
  "locked": false,
  "milestone": null,
  "node_id": "MDU6SXNzdWU2MjAwNzAxNjk=",
  "number": 5498,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/rook/rook",
  "state": "closed",
  "title": "Upgrade fails from 1.2.7 to 1.3.X: invalid memory address or nil pointer dereference",
  "updated_at": "2020-05-20T16:17:19Z",
  "url": "https://api.github.com/repos/rook/rook/issues/5498",
  "user": {
    "avatar_url": "https://avatars3.githubusercontent.com/u/8665642?v=4",
    "events_url": "https://api.github.com/users/TeroPihlaja/events{/privacy}",
    "followers_url": "https://api.github.com/users/TeroPihlaja/followers",
    "following_url": "https://api.github.com/users/TeroPihlaja/following{/other_user}",
    "gists_url": "https://api.github.com/users/TeroPihlaja/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/TeroPihlaja",
    "id": 8665642,
    "login": "TeroPihlaja",
    "node_id": "MDQ6VXNlcjg2NjU2NDI=",
    "organizations_url": "https://api.github.com/users/TeroPihlaja/orgs",
    "received_events_url": "https://api.github.com/users/TeroPihlaja/received_events",
    "repos_url": "https://api.github.com/users/TeroPihlaja/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/TeroPihlaja/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/TeroPihlaja/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/TeroPihlaja"
  }
}