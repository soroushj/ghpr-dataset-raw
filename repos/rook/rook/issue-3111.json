{
  "active_lock_reason": null,
  "assignee": null,
  "assignees": [],
  "author_association": "CONTRIBUTOR",
  "body": "<!-- **Are you in the right place?**\r\n1. For issues or feature requests, please create an issue in this repository.\r\n2. For general technical and non-technical questions, we are happy to help you on our [Rook.io Slack](https://slack.rook.io/).\r\n3. Did you already search the existing open issues for anything similar? -->\r\n\r\n**Is this a bug report or feature request?**\r\n* Bug Report\r\n\r\n**Deviation from expected behavior:**\r\nMonitors are not reachable after changing the operator image\r\n\r\n**Expected behavior:**\r\nWould expect monitors to still be reachable after changing the operator image\r\n\r\n**How to reproduce it (minimal and precise):**\r\n- Install a 0.9.3 ceph cluster\r\n- Change the operator image to 1.0.0\r\n\r\n**Environment**:\r\n## Setup\r\nOS: CoreOS Container Linux (2023.4.0)\r\nK8-Distro: kubeadm (1.14.0)\r\nCNI: Calico\r\nCeph Version: v13.2.5-20190410\r\nHardware: KVM virtualization on laptop\r\n\r\n## operator.yaml\r\n```json\r\napiVersion: apps/v1beta1\r\nkind: Deployment\r\nmetadata:\r\n  name: rook-ceph-operator\r\n  namespace: rook-ceph-system\r\n  labels:\r\n    operator: rook\r\n    storage-backend: ceph\r\nspec:\r\n  replicas: 1\r\n  template:\r\n    metadata:\r\n      labels:\r\n        app: rook-ceph-operator\r\n    spec:\r\n      serviceAccountName: rook-ceph-system\r\n      containers:\r\n      - name: rook-ceph-operator\r\n        image: rook/ceph:v0.9.3\r\n        args: [\"ceph\", \"operator\"]\r\n        volumeMounts:\r\n        - mountPath: /var/lib/rook\r\n          name: rook-config\r\n        - mountPath: /etc/ceph\r\n          name: default-config-dir\r\n        env:\r\n        - name: FLEXVOLUME_DIR_PATH\r\n          value: \"/var/lib/kubelet/volumeplugins\"\r\n        - name: ROOK_ALLOW_MULTIPLE_FILESYSTEMS\r\n          value: \"false\"\r\n        - name: ROOK_LOG_LEVEL\r\n          value: \"INFO\"\r\n        - name: ROOK_MON_HEALTHCHECK_INTERVAL\r\n          value: \"45s\"\r\n        - name: ROOK_MON_OUT_TIMEOUT\r\n          value: \"300s\"\r\n        - name: ROOK_DISCOVER_DEVICES_INTERVAL\r\n          value: \"60m\"\r\n        - name: ROOK_HOSTPATH_REQUIRES_PRIVILEGED\r\n          value: \"false\"\r\n        - name: ROOK_ENABLE_SELINUX_RELABELING\r\n          value: \"true\"\r\n        - name: ROOK_ENABLE_FSGROUP\r\n          value: \"true\"\r\n        - name: NODE_NAME\r\n          valueFrom:\r\n            fieldRef:\r\n              fieldPath: spec.nodeName\r\n        - name: POD_NAME\r\n          valueFrom:\r\n            fieldRef:\r\n              fieldPath: metadata.name\r\n        - name: POD_NAMESPACE\r\n          valueFrom:\r\n            fieldRef:\r\n              fieldPath: metadata.namespace\r\n      volumes:\r\n      - name: rook-config\r\n        emptyDir: {}\r\n      - name: default-config-dir\r\n        emptyDir: {}\r\n```\r\n\r\n## cluster.yaml\r\n```json\r\napiVersion: ceph.rook.io/v1\r\nkind: CephCluster\r\nmetadata:\r\n  name: rook-ceph\r\n  namespace: rook-ceph\r\nspec:\r\n  cephVersion:\r\n    image: ceph/ceph:v13.2.5-20190410\r\n  dataDirHostPath: /var/lib/rook\r\n  mon:\r\n    count: 3\r\n    allowMultiplePerNode: false\r\n  dashboard:\r\n    enabled: true\r\n  network:\r\n    hostNetwork: true\r\n  rbdMirroring:\r\n    workers: 0\r\n  resources:\r\n  storage: # cluster level storage configuration and selection\r\n    useAllNodes: true\r\n    useAllDevices: false\r\n    deviceFilter: \"^vd[b-d]\"\r\n    location:\r\n    config:\r\n      osdsPerDevice: \"1\" # this value can be overridden at the node or device level\r\n```\r\n\r\n## Pre-upgrade\r\n\r\n### Namespaces (v0.9.3)\r\n```bash\r\nkubectl get pods -o wide --all-namespaces\r\nNAMESPACE          NAME                                       READY   STATUS      RESTARTS   AGE     IP               NODE           NOMINATED NODE   READINESS GATES\r\nkube-system        calico-kube-controllers-5cbcccc885-vcl95   1/1     Running     0          6m39s   10.244.207.193   172.18.0.205   <none>           <none>\r\nkube-system        calico-node-2khfx                          1/1     Running     0          6m39s   172.18.0.205     172.18.0.205   <none>           <none>\r\nkube-system        calico-node-btp6g                          1/1     Running     0          6m22s   172.18.0.160     172.18.0.160   <none>           <none>\r\nkube-system        calico-node-kw4cb                          1/1     Running     0          6m22s   172.18.0.225     172.18.0.225   <none>           <none>\r\nkube-system        calico-node-wlk2b                          1/1     Running     0          6m22s   172.18.0.144     172.18.0.144   <none>           <none>\r\nkube-system        coredns-fb8b8dccf-9s2q4                    1/1     Running     0          6m39s   10.244.207.195   172.18.0.205   <none>           <none>\r\nkube-system        coredns-fb8b8dccf-zs65f                    1/1     Running     0          6m39s   10.244.207.194   172.18.0.205   <none>           <none>\r\nkube-system        etcd-172.18.0.205                          1/1     Running     0          5m56s   172.18.0.205     172.18.0.205   <none>           <none>\r\nkube-system        keepalived-controller-172.18.0.205         1/1     Running     0          5m41s   172.18.0.205     172.18.0.205   <none>           <none>\r\nkube-system        kube-apiserver-172.18.0.205                1/1     Running     0          5m41s   172.18.0.205     172.18.0.205   <none>           <none>\r\nkube-system        kube-controller-manager-172.18.0.205       1/1     Running     0          5m56s   172.18.0.205     172.18.0.205   <none>           <none>\r\nkube-system        kube-proxy-l7tnp                           1/1     Running     0          6m39s   172.18.0.205     172.18.0.205   <none>           <none>\r\nkube-system        kube-proxy-ls484                           1/1     Running     0          6m22s   172.18.0.160     172.18.0.160   <none>           <none>\r\nkube-system        kube-proxy-pm49q                           1/1     Running     0          6m22s   172.18.0.144     172.18.0.144   <none>           <none>\r\nkube-system        kube-proxy-rh9pt                           1/1     Running     0          6m22s   172.18.0.225     172.18.0.225   <none>           <none>\r\nkube-system        kube-scheduler-172.18.0.205                1/1     Running     0          6m6s    172.18.0.205     172.18.0.205   <none>           <none>\r\nrook-ceph-system   rook-ceph-agent-95rzt                      1/1     Running     0          4m29s   172.18.0.160     172.18.0.160   <none>           <none>\r\nrook-ceph-system   rook-ceph-agent-vd8m8                      1/1     Running     0          4m29s   172.18.0.225     172.18.0.225   <none>           <none>\r\nrook-ceph-system   rook-ceph-agent-zmqw5                      1/1     Running     0          4m29s   172.18.0.144     172.18.0.144   <none>           <none>\r\nrook-ceph-system   rook-ceph-operator-7c6dd9c688-lfmg7        1/1     Running     0          4m45s   10.244.84.192    172.18.0.144   <none>           <none>\r\nrook-ceph-system   rook-discover-86bpq                        1/1     Running     0          4m29s   10.244.40.64     172.18.0.160   <none>           <none>\r\nrook-ceph-system   rook-discover-hzmb5                        1/1     Running     0          4m29s   10.244.196.128   172.18.0.225   <none>           <none>\r\nrook-ceph-system   rook-discover-pbrnr                        1/1     Running     0          4m29s   10.244.84.193    172.18.0.144   <none>           <none>\r\nrook-ceph          rook-ceph-mgr-a-85d88c85dc-xst7w           1/1     Running     0          2m36s   172.18.0.225     172.18.0.225   <none>           <none>\r\nrook-ceph          rook-ceph-mon-a-5bd456bcd9-xkgdm           1/1     Running     0          3m31s   172.18.0.144     172.18.0.144   <none>           <none>\r\nrook-ceph          rook-ceph-mon-b-58c7f9d4b6-946ch           1/1     Running     0          3m11s   172.18.0.160     172.18.0.160   <none>           <none>\r\nrook-ceph          rook-ceph-mon-c-7bb6fbcb5d-mhbpp           1/1     Running     0          2m47s   172.18.0.225     172.18.0.225   <none>           <none>\r\nrook-ceph          rook-ceph-osd-0-8557c8cf7c-sjtmt           1/1     Running     0          90s     172.18.0.144     172.18.0.144   <none>           <none>\r\nrook-ceph          rook-ceph-osd-1-5f4977c658-h8zjf           1/1     Running     0          84s     172.18.0.160     172.18.0.160   <none>           <none>\r\nrook-ceph          rook-ceph-osd-2-79fb67986c-s5mtz           1/1     Running     0          90s     172.18.0.225     172.18.0.225   <none>           <none>\r\nrook-ceph          rook-ceph-osd-3-84fff9776b-s7n9k           1/1     Running     0          90s     172.18.0.144     172.18.0.144   <none>           <none>\r\nrook-ceph          rook-ceph-osd-4-7d9ccc4bf9-6hl6l           1/1     Running     0          90s     172.18.0.225     172.18.0.225   <none>           <none>\r\nrook-ceph          rook-ceph-osd-5-5cf85876-rsz5z             1/1     Running     0          84s     172.18.0.160     172.18.0.160   <none>           <none>\r\nrook-ceph          rook-ceph-osd-prepare-172.18.0.144-2dszq   0/2     Completed   0          2m22s   172.18.0.144     172.18.0.144   <none>           <none>\r\nrook-ceph          rook-ceph-osd-prepare-172.18.0.160-272k2   0/2     Completed   0          2m20s   172.18.0.160     172.18.0.160   <none>           <none>\r\nrook-ceph          rook-ceph-osd-prepare-172.18.0.225-gbbxx   0/2     Completed   0          2m19s   172.18.0.225     172.18.0.225   <none>           <none>\r\nrook-ceph          rook-ceph-tools-bffbf4d8f-qbq57            1/1     Running     0          11s     172.18.0.144     172.18.0.144   <none>           <none>\r\n```\r\n\r\n### Ceph Status \r\n```bash\r\nceph -w\r\n  cluster:\r\n    id:     8c296c33-1999-4723-9c4f-db7dedcc245f\r\n    health: HEALTH_OK\r\n \r\n  services:\r\n    mon: 3 daemons, quorum a,b,c\r\n    mgr: a(active)\r\n    osd: 6 osds: 6 up, 6 in\r\n \r\n  data:\r\n    pools:   1 pools, 100 pgs\r\n    objects: 0  objects, 0 B\r\n    usage:   6.0 GiB used, 54 GiB / 60 GiB avail\r\n    pgs:     100 active+clean\r\n\r\n2019-05-03 17:26:36.633070 mon.a [INF] Health check cleared: TOO_FEW_PGS (was: too few PGs per OSD (16 < min 30))\r\n2019-05-03 17:26:36.633092 mon.a [INF] Cluster is now healthy\r\n```\r\n\r\n### rook-ceph-mon-endpoints\r\n```bash\r\nkubectl get configmaps -n rook-ceph rook-ceph-mon-endpoints -o yaml\r\napiVersion: v1\r\ndata:\r\n  data: a=172.18.0.144:6790,b=172.18.0.160:6790,c=172.18.0.225:6790\r\n  mapping: '{\"node\":{\"a\":{\"Name\":\"172.18.0.144\",\"Hostname\":\"172.18.0.144\",\"Address\":\"172.18.0.144\"},\"b\":{\"Name\":\"172.18.0.160\",\"Hostname\":\"172.18.0.160\",\"Address\":\"172.18.0.160\"},\"c\":{\"Name\":\"172.18.0.225\",\"Hostname\":\"172.18.0.225\",\"Address\":\"172.18.0.225\"}},\"port\":{\"172.18.0.144\":6790,\"172.18.0.160\":6790,\"172.18.0.225\":6790}}'\r\n  maxMonId: \"2\"\r\nkind: ConfigMap\r\nmetadata:\r\n  creationTimestamp: \"2019-05-03T17:19:48Z\"\r\n  name: rook-ceph-mon-endpoints\r\n  namespace: rook-ceph\r\n  ownerReferences:\r\n  - apiVersion: v1\r\n    blockOwnerDeletion: true\r\n    kind: CephCluster\r\n    name: rook-ceph\r\n    uid: 97789661-6dc7-11e9-8637-620f0a3e7bc3\r\n  resourceVersion: \"1330\"\r\n  selfLink: /api/v1/namespaces/rook-ceph/configmaps/rook-ceph-mon-endpoints\r\n  uid: a712b0ab-6dc7-11e9-8637-620f0a3e7bc3\r\n```\r\n\r\n### Ceph config \r\n```bash\r\ncat /etc/ceph/ceph.conf\r\n[global]\r\nfsid                      = 8c296c33-1999-4723-9c4f-db7dedcc245f\r\nrun dir                   = /var/lib/rook/mon-a\r\nmon initial members       = a\r\nmon host                  = 172.18.0.144:6790\r\nlog file                  = /dev/stderr\r\nmon cluster log file      = /dev/stderr\r\npublic addr               = 172.18.0.144\r\ncluster addr              = 172.18.0.144\r\nmon keyvaluedb            = rocksdb\r\nmon_allow_pool_delete     = true\r\nmon_max_pg_per_osd        = 1000\r\ndebug default             = 0\r\ndebug rados               = 0\r\ndebug mon                 = 0\r\ndebug osd                 = 0\r\ndebug bluestore           = 0\r\ndebug filestore           = 0\r\ndebug journal             = 0\r\ndebug leveldb             = 0\r\nfilestore_omap_backend    = rocksdb\r\nosd pg bits               = 11\r\nosd pgp bits              = 11\r\nosd pool default size     = 1\r\nosd pool default min size = 1\r\nosd pool default pg num   = 100\r\nosd pool default pgp num  = 100\r\nrbd_default_features      = 3\r\nfatal signal handlers     = false\r\n\r\n[mon.a]\r\nkeyring          = /var/lib/rook/mon-a/keyring\r\npublic bind addr = 172.18.0.144:6790\r\n```\r\n\r\n## Post upgrade (v1.0.0)\r\n\r\n### Ceph config \r\n```bash\r\ncat /etc/ceph/ceph.conf \r\n[global]\r\nmon_allow_pool_delete     = true\r\nlog_file                  = \r\nmon_cluster_log_file      = \r\nmon_max_pg_per_osd        = 1000\r\nosd_pg_bits               = 11\r\nosd_pgp_bits              = 11\r\nosd_pool_default_size     = 1\r\nosd_pool_default_min_size = 1\r\nosd_pool_default_pg_num   = 100\r\nosd_pool_default_pgp_num  = 100\r\nrbd_default_features      = 3\r\nfatal_signal_handlers     = false\r\n```\r\n\r\n### rook-ceph-config\r\n```bash\r\nkubectl get configmaps -n rook-ceph rook-ceph-config -o yaml\r\napiVersion: v1\r\ndata:\r\n  ceph.conf: \"[global]\\nmon_allow_pool_delete     = true\\nlog_file                  =\r\n    \\nmon_cluster_log_file      = \\nmon_max_pg_per_osd        = 1000\\nosd_pg_bits\r\n    \\              = 11\\nosd_pgp_bits              = 11\\nosd_pool_default_size     =\r\n    1\\nosd_pool_default_min_size = 1\\nosd_pool_default_pg_num   = 100\\nosd_pool_default_pgp_num\r\n    \\ = 100\\nrbd_default_features      = 3\\nfatal_signal_handlers     = false\\n\\n\"\r\nkind: ConfigMap\r\nmetadata:\r\n  creationTimestamp: \"2019-05-03T17:30:32Z\"\r\n  name: rook-ceph-config\r\n  namespace: rook-ceph\r\n  ownerReferences:\r\n  - apiVersion: v1\r\n    blockOwnerDeletion: true\r\n    kind: CephCluster\r\n    name: rook-ceph\r\n    uid: 97789661-6dc7-11e9-8637-620f0a3e7bc3\r\n  resourceVersion: \"2716\"\r\n  selfLink: /api/v1/namespaces/rook-ceph/configmaps/rook-ceph-config\r\n  uid: 27429b2a-6dc9-11e9-8637-620f0a3e7bc3\r\n```\r\n\r\n### Monitor environment variables\r\n```bash\r\nkubectl exec -it -n rook-ceph rook-ceph-mon-a-7cd58b7fd9-pbtl7 bash\r\nbash: warning: setlocale: LC_CTYPE: cannot change locale (en_US.UTF-8): No such file or directory\r\nbash: warning: setlocale: LC_COLLATE: cannot change locale (en_US.UTF-8): No such file or directory\r\nbash: warning: setlocale: LC_MESSAGES: cannot change locale (en_US.UTF-8): No such file or directory\r\nbash: warning: setlocale: LC_NUMERIC: cannot change locale (en_US.UTF-8): No such file or directory\r\nbash: warning: setlocale: LC_TIME: cannot change locale (en_US.UTF-8): No such file or directory\r\n[root@localhost /]# env\r\nROOK_CEPH_MGR_DASHBOARD_PORT_8443_TCP_ADDR=10.96.242.94\r\nROOK_CEPH_MGR_PORT_9283_TCP_PORT=9283\r\nPOD_NAMESPACE=rook-ceph\r\nROOK_CEPH_MGR_SERVICE_HOST=10.96.66.159\r\nHOSTNAME=localhost\r\nKUBERNETES_PORT_443_TCP_PORT=443\r\nKUBERNETES_PORT=tcp://10.96.0.1:443\r\nTERM=xterm\r\nROOK_CEPH_MGR_PORT=tcp://10.96.66.159:9283\r\nKUBERNETES_SERVICE_PORT=443\r\nKUBERNETES_SERVICE_HOST=10.96.0.1\r\nPOD_NAME=rook-ceph-mon-a-7cd58b7fd9-pbtl7\r\nROOK_CEPH_MGR_DASHBOARD_PORT_8443_TCP_PROTO=tcp\r\nLS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:\r\nPOD_CPU_LIMIT=4\r\nROOK_CEPH_MGR_DASHBOARD_PORT=tcp://10.96.242.94:8443\r\nROOK_CEPH_MGR_PORT_9283_TCP=tcp://10.96.66.159:9283\r\nROOK_CEPH_MGR_DASHBOARD_SERVICE_PORT=8443\r\nROOK_CEPH_MGR_SERVICE_PORT_HTTP_METRICS=9283\r\nPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\r\nROOK_CEPH_MGR_PORT_9283_TCP_ADDR=10.96.66.159\r\nROOK_CEPH_MGR_DASHBOARD_PORT_8443_TCP_PORT=8443\r\nROOK_CEPH_MON_INITIAL_MEMBERS=a,b,c\r\nPWD=/\r\nCEPH_VERSION=mimic\r\nROOK_CEPH_MGR_DASHBOARD_SERVICE_PORT_HTTPS_DASHBOARD=8443\r\nLANG=en_US.UTF-8\r\nROOK_CEPH_MGR_SERVICE_PORT=9283\r\nSHLVL=1\r\nHOME=/root\r\nCEPH_POINT_RELEASE=-13.2.5\r\nKUBERNETES_PORT_443_TCP_PROTO=tcp\r\nKUBERNETES_SERVICE_PORT_HTTPS=443\r\nROOK_CEPH_MGR_PORT_9283_TCP_PROTO=tcp\r\nPOD_MEMORY_LIMIT=7029817344\r\nROOK_CEPH_MON_HOST=172.18.0.144:6790,172.18.0.160:6790,172.18.0.225:6790\r\nROOK_CEPH_MGR_DASHBOARD_PORT_8443_TCP=tcp://10.96.242.94:8443\r\nNODE_NAME=172.18.0.144\r\nCONTAINER_IMAGE=ceph/ceph:v13.2.5-20190410\r\nROOK_POD_IP=172.18.0.144\r\nKUBERNETES_PORT_443_TCP_ADDR=10.96.0.1\r\nPOD_MEMORY_REQUEST=0\r\nKUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443\r\nPOD_CPU_REQUEST=0\r\nROOK_CEPH_MGR_DASHBOARD_SERVICE_HOST=10.96.242.94\r\n_=/usr/bin/env\r\n```\r\n\r\n### Rook Operator logs\r\n```bash\r\np-mon: mons running: [a b c]\r\n2019-05-03 17:44:48.375148 I | exec: Running command: ceph mon_status --connect-timeout=15 --cluster=rook-ceph --conf=/var/lib/rook/rook-ceph/rook-ceph.config --keyring=/var/lib/rook/rook-ceph/client.admin.keyring --format json --out-file /tmp/545567355\r\n2019-05-03 17:45:03.471325 I | exec: timed out\r\n2019-05-03 17:45:08.503633 I | op-mon: mons running: [a b c]\r\n2019-05-03 17:45:08.503890 I | exec: Running command: ceph mon_status --connect-timeout=15 --cluster=rook-ceph --conf=/var/lib/rook/rook-ceph/rook-ceph.config --keyring=/var/lib/rook/rook-ceph/client.admin.keyring --format json --out-file /tmp/644789150\r\n2019-05-03 17:45:23.606816 I | exec: timed out\r\n2019-05-03 17:45:28.642528 I | op-mon: mons running: [a b c]\r\n2019-05-03 17:45:28.642682 I | exec: Running command: ceph mon_status --connect-timeout=15 --cluster=rook-ceph --conf=/var/lib/rook/rook-ceph/rook-ceph.config --keyring=/var/lib/rook/rook-ceph/client.admin.keyring --format json --out-file /tmp/965211749\r\n2019-05-03 17:45:43.740326 I | exec: timed out\r\n2019-05-03 17:45:48.750935 I | op-mon: mons running: [a b c]\r\n2019-05-03 17:45:48.751018 I | exec: Running command: ceph mon_status --connect-timeout=15 --cluster=rook-ceph --conf=/var/lib/rook/rook-ceph/rook-ceph.config --keyring=/var/lib/rook/rook-ceph/client.admin.keyring --format json --out-file /tmp/058027648\r\n2019-05-03 17:46:03.834993 I | exec: timed out\r\n2019-05-03 17:46:08.872192 I | op-mon: mons running: [a b c]\r\n2019-05-03 17:46:08.872732 I | exec: Running command: ceph mon_status --connect-timeout=15 --cluster=rook-ceph --conf=/var/lib/rook/rook-ceph/rook-ceph.config --keyring=/var/lib/rook/rook-ceph/client.admin.keyring --format json --out-file /tmp/799672287\r\n2019-05-03 17:46:23.960383 I | exec: timed out\r\n2019-05-03 17:46:28.996788 I | op-mon: mons running: [a b c]\r\n2019-05-03 17:46:28.996942 I | exec: Running command: ceph mon_status --connect-timeout=15 --cluster=rook-ceph --conf=/var/lib/rook/rook-ceph/rook-ceph.config --keyring=/var/lib/rook/rook-ceph/client.admin.keyring --format json --out-file /tmp/572383666\r\n2019-05-03 17:46:44.105339 I | exec: timed out\r\n2019-05-03 17:46:49.125074 I | op-mon: mons running: [a b c]\r\n2019-05-03 17:46:49.125212 I | exec: Running command: ceph mon_status --connect-timeout=15 --cluster=rook-ceph --conf=/var/lib/rook/rook-ceph/rook-ceph.config --keyring=/var/lib/rook/rook-ceph/client.admin.keyring --format json --out-file /tmp/304249705\r\n2019-05-03 17:47:04.223576 I | exec: timed out\r\n2019-05-03 17:47:09.242504 I | op-mon: mons running: [a b c]\r\n2019-05-03 17:47:09.242691 I | exec: Running command: ceph mon_status --connect-timeout=15 --cluster=rook-ceph --conf=/var/lib/rook/rook-ceph/rook-ceph.config --keyring=/var/lib/rook/rook-ceph/client.admin.keyring --format json --out-file /tmp/983880628\r\n2019-05-03 17:47:24.324178 I | exec: timed out\r\n2019-05-03 17:47:29.362302 I | op-mon: mons running: [a b c]\r\n2019-05-03 17:47:29.362463 I | exec: Running command: ceph mon_status --connect-timeout=15 --cluster=rook-ceph --conf=/var/lib/rook/rook-ceph/rook-ceph.config --keyring=/var/lib/rook/rook-ceph/client.admin.keyring --format json --out-file /tmp/411424643\r\n2019-05-03 17:47:44.464068 I | exec: timed out\r\n2019-05-03 17:47:49.485069 I | op-mon: mons running: [a b c]\r\n2019-05-03 17:47:49.485407 I | exec: Running command: ceph mon_status --connect-timeout=15 --cluster=rook-ceph --conf=/var/lib/rook/rook-ceph/rook-ceph.config --keyring=/var/lib/rook/rook-ceph/client.admin.keyring --format json --out-file /tmp/046415110\r\n```\r\n",
  "closed_at": "2019-05-13T15:34:55Z",
  "closed_by": {
    "avatar_url": "https://avatars0.githubusercontent.com/u/1048514?v=4",
    "events_url": "https://api.github.com/users/travisn/events{/privacy}",
    "followers_url": "https://api.github.com/users/travisn/followers",
    "following_url": "https://api.github.com/users/travisn/following{/other_user}",
    "gists_url": "https://api.github.com/users/travisn/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/travisn",
    "id": 1048514,
    "login": "travisn",
    "node_id": "MDQ6VXNlcjEwNDg1MTQ=",
    "organizations_url": "https://api.github.com/users/travisn/orgs",
    "received_events_url": "https://api.github.com/users/travisn/received_events",
    "repos_url": "https://api.github.com/users/travisn/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/travisn/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/travisn/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/travisn"
  },
  "comments": 8,
  "comments_url": "https://api.github.com/repos/rook/rook/issues/3111/comments",
  "created_at": "2019-05-03T18:36:39Z",
  "events_url": "https://api.github.com/repos/rook/rook/issues/3111/events",
  "html_url": "https://github.com/rook/rook/issues/3111",
  "id": 440169880,
  "labels": [
    {
      "color": "ee0000",
      "default": true,
      "description": "",
      "id": 405241115,
      "name": "bug",
      "node_id": "MDU6TGFiZWw0MDUyNDExMTU=",
      "url": "https://api.github.com/repos/rook/rook/labels/bug"
    }
  ],
  "labels_url": "https://api.github.com/repos/rook/rook/issues/3111/labels{/name}",
  "locked": false,
  "milestone": {
    "closed_at": "2020-01-28T21:43:45Z",
    "closed_issues": 119,
    "created_at": "2018-11-21T16:40:13Z",
    "creator": {
      "avatar_url": "https://avatars0.githubusercontent.com/u/1048514?v=4",
      "events_url": "https://api.github.com/users/travisn/events{/privacy}",
      "followers_url": "https://api.github.com/users/travisn/followers",
      "following_url": "https://api.github.com/users/travisn/following{/other_user}",
      "gists_url": "https://api.github.com/users/travisn/gists{/gist_id}",
      "gravatar_id": "",
      "html_url": "https://github.com/travisn",
      "id": 1048514,
      "login": "travisn",
      "node_id": "MDQ6VXNlcjEwNDg1MTQ=",
      "organizations_url": "https://api.github.com/users/travisn/orgs",
      "received_events_url": "https://api.github.com/users/travisn/received_events",
      "repos_url": "https://api.github.com/users/travisn/repos",
      "site_admin": false,
      "starred_url": "https://api.github.com/users/travisn/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/travisn/subscriptions",
      "type": "User",
      "url": "https://api.github.com/users/travisn"
    },
    "description": "",
    "due_on": null,
    "html_url": "https://github.com/rook/rook/milestone/11",
    "id": 3838796,
    "labels_url": "https://api.github.com/repos/rook/rook/milestones/11/labels",
    "node_id": "MDk6TWlsZXN0b25lMzgzODc5Ng==",
    "number": 11,
    "open_issues": 0,
    "state": "closed",
    "title": "1.0",
    "updated_at": "2020-01-28T21:43:45Z",
    "url": "https://api.github.com/repos/rook/rook/milestones/11"
  },
  "node_id": "MDU6SXNzdWU0NDAxNjk4ODA=",
  "number": 3111,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/rook/rook",
  "state": "closed",
  "title": "Upgrade from v0.9.3 to v1.0.0 with host networking - Monitors no longer reachable",
  "updated_at": "2019-05-14T13:08:53Z",
  "url": "https://api.github.com/repos/rook/rook/issues/3111",
  "user": {
    "avatar_url": "https://avatars1.githubusercontent.com/u/6299645?v=4",
    "events_url": "https://api.github.com/users/andrewwebber/events{/privacy}",
    "followers_url": "https://api.github.com/users/andrewwebber/followers",
    "following_url": "https://api.github.com/users/andrewwebber/following{/other_user}",
    "gists_url": "https://api.github.com/users/andrewwebber/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/andrewwebber",
    "id": 6299645,
    "login": "andrewwebber",
    "node_id": "MDQ6VXNlcjYyOTk2NDU=",
    "organizations_url": "https://api.github.com/users/andrewwebber/orgs",
    "received_events_url": "https://api.github.com/users/andrewwebber/received_events",
    "repos_url": "https://api.github.com/users/andrewwebber/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/andrewwebber/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/andrewwebber/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/andrewwebber"
  }
}