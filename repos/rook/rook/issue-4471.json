{
  "active_lock_reason": null,
  "assignee": null,
  "assignees": [],
  "author_association": "NONE",
  "body": "* Bug Report\r\n\r\n**CephCluster and CephObjectStorage manifest**\r\nhttps://gist.github.com/minh-nguyenquang/730c7e84f7d1c1d7293c3bfd75bd61cb\r\n\r\n**How to reproduce it (minimal and precise):**\r\nMy cluster has worker nodes with instance type t2.xlarge. After I upgrade worker nodes to t2.2xlarge, I encounter the issue one of pod as below.\r\n\r\n```\r\ndebug 2019-12-11 09:53:46.870 7f1ef191d780  0 framework: beast\r\ndebug 2019-12-11 09:53:46.870 7f1ef191d780  0 framework conf key: port, val: 7480\r\ndebug 2019-12-11 09:53:46.870 7f1ef191d780  0 deferred set uid:gid to 167:167 (ceph:ceph)\r\ndebug 2019-12-11 09:53:46.871 7f1ef191d780  0 ceph version 14.2.4 (75f4de193b3ea58512f204623e6c5a16e6c1e1ba) nautilus (stable), process radosgw, pid 1\r\ndebug 2019-12-11 09:53:47.001 7f1ef191d780  0 starting handler: beast\r\ndebug 2019-12-11 09:53:47.002 7f1ef191d780  0 set uid:gid to 167:167 (ceph:ceph)\r\ndebug 2019-12-11 09:53:47.016 7f1ef191d780  1 mgrc service_daemon_register rgw.test.bucket.a metadata {arch=x86_64,ceph_release=nautilus,ceph_version=ceph version 14.2.4 (75f4de193b3ea58512f204623e6c5a16e6c1e1ba) nautilus (stable),ceph_version_short=14.2.4,container_hostname=rook-ceph-rgw-test-bucket-a-65dcf95c67-q4s8l,container_image=ceph/ceph:v14.2.4-20190917,cpu=Intel(R) Xeon(R) CPU E5-2676 v3 @ 2.40GHz,distro=centos,distro_description=CentOS Linux 7 (Core),distro_version=7,frontend_config#0=beast port=7480,frontend_type#0=beast,hostname=ip-10-30-18-126.ap-southeast-1.compute.internal,kernel_description=#1 SMP Thu May 25 17:04:51 UTC 2017,kernel_version=3.10.0-514.21.1.el7.x86_64,mem_swap_kb=0,mem_total_kb=32518448,num_handles=1,os=Linux,pid=1,pod_name=rook-ceph-rgw-test-bucket-a-65dcf95c67-q4s8l,pod_namespace=storage,zone_id=a120d467-5d28-478c-8607-1805cd934885,zone_name=test-bucket,zonegroup_id=5fa39cd6-59ca-4983-b400-a7d47bb0cd55,zonegroup_name=test-bucket}\r\ndebug 2019-12-11 09:54:23.524 7f1edbd18700 -1 received  signal: Terminated from Kernel ( Could be generated by pthread_kill(), raise(), abort(), alarm() ) UID: 0\r\ndebug 2019-12-11 09:54:23.524 7f1edbd18700  1 handle_sigterm\r\ndebug 2019-12-11 09:54:23.524 7f1edbd18700  1 handle_sigterm set alarm for 120\r\ndebug 2019-12-11 09:54:23.524 7f1ef191d780 -1 shutting down\r\ndebug 2019-12-11 09:54:23.582 7f1ef191d780  1 final shutdown\r\n```\r\nContinue to check and find that container failed because of liveness probe\r\n```\r\n  Type     Reason     Age                   From                                                      Message\r\n  ----     ------     ----                  ----                                                      -------\r\n  Normal   Scheduled  16m                   default-scheduler                                         Successfully assigned storage/rook-ceph-rgw-cxa2-bucket-a-65dcf95c67-q4s8l to ip-10-30-18-126.ap-southeast-1.compute.internal\r\n  Normal   Pulled     16m                   kubelet, ip-10-30-18-126.ap-southeast-1.compute.internal  Container image \"ceph/ceph:v14.2.4-20190917\" already present on machine\r\n  Normal   Created    16m                   kubelet, ip-10-30-18-126.ap-southeast-1.compute.internal  Created container chown-container-data-dir\r\n  Normal   Started    16m                   kubelet, ip-10-30-18-126.ap-southeast-1.compute.internal  Started container chown-container-data-dir\r\n  Normal   Created    15m (x3 over 16m)     kubelet, ip-10-30-18-126.ap-southeast-1.compute.internal  Created container rgw\r\n  Normal   Started    15m (x3 over 16m)     kubelet, ip-10-30-18-126.ap-southeast-1.compute.internal  Started container rgw\r\n  Normal   Killing    15m (x3 over 16m)     kubelet, ip-10-30-18-126.ap-southeast-1.compute.internal  Container rgw failed liveness probe, will be restarted\r\n  Normal   Pulled     11m (x7 over 16m)     kubelet, ip-10-30-18-126.ap-southeast-1.compute.internal  Container image \"ceph/ceph:v14.2.4-20190917\" already present on machine\r\n  Warning  BackOff    6m30s (x33 over 14m)  kubelet, ip-10-30-18-126.ap-southeast-1.compute.internal  Back-off restarting failed container\r\n  Warning  Unhealthy  90s (x28 over 16m)    kubelet, ip-10-30-18-126.ap-southeast-1.compute.internal  Liveness probe failed: Get http://10.233.80.239:80/: dial tcp 10.233.80.239:80: connect: connection refused\r\n```\r\n\r\nAll of 3 pods running on the same server but only one get issue\r\n```\r\nrook-ceph-rgw-cxa2-bucket-a-65dcf95c67-q4s8l                      0/1     CrashLoopBackOff   9          17m     10.233.80.239    ip-10-30-18-126.ap-southeast-1.compute.internal    <none>           <none>\r\nrook-ceph-rgw-cxa2-bucket-b-9b5968fd7-6bgsh                       1/1     Running            0          59m     10.233.111.195   ip-10-30-18-126.ap-southeast-1.compute.internal   <none>           <none>\r\nrook-ceph-rgw-cxa2-bucket-c-6955fb99c5-2jrcf                      1/1     Running            0          59m     10.233.111.244  ip-10-30-18-126.ap-southeast-1.compute.internal   <none>           <none>\r\n```\r\n**Environment**:\r\n* OS (e.g. from /etc/os-release): CentOS \r\n* Kernel (e.g. `uname -a`): 3.10.0-957.1.3.el7.x86_64\r\n* Cloud provider or hardware configuration: AWS\r\n* Rook version (use `rook version` inside of a Rook Pod): rook: v1.1.0-beta.0.544.gab69d75\r\n* Storage backend version: ceph\r\n* Kubernetes version: 1.14.3\r\n* Kubernetes cluster type: built by kubespray\r\n* Storage backend status:\r\n```\r\ncluster:\r\n    id:     36f193d4-3689-4ecc-9200-2879b147273e\r\n    health: HEALTH_OK\r\n\r\nservices:\r\n    mon: 5 daemons, quorum c,d,e,f,g (age 3h)\r\n    mgr: a(active, since 14m)\r\n    osd: 3 osds: 3 up (since 14m), 3 in (since 6d)\r\n    rgw: 2 daemons active (test.bucket.b, test.bucket.c)\r\n\r\ndata:\r\n    pools:   8 pools, 64 pgs\r\n    objects: 287 objects, 10 KiB\r\n    usage:   3.1 GiB used, 84 GiB / 87 GiB avail\r\n    pgs:     64 active+clean\r\n```\r\n",
  "closed_at": "2019-12-11T15:45:58Z",
  "closed_by": {
    "avatar_url": "https://avatars3.githubusercontent.com/u/912735?v=4",
    "events_url": "https://api.github.com/users/leseb/events{/privacy}",
    "followers_url": "https://api.github.com/users/leseb/followers",
    "following_url": "https://api.github.com/users/leseb/following{/other_user}",
    "gists_url": "https://api.github.com/users/leseb/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/leseb",
    "id": 912735,
    "login": "leseb",
    "node_id": "MDQ6VXNlcjkxMjczNQ==",
    "organizations_url": "https://api.github.com/users/leseb/orgs",
    "received_events_url": "https://api.github.com/users/leseb/received_events",
    "repos_url": "https://api.github.com/users/leseb/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/leseb/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/leseb/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/leseb"
  },
  "comments": 10,
  "comments_url": "https://api.github.com/repos/rook/rook/issues/4471/comments",
  "created_at": "2019-12-11T10:05:09Z",
  "events_url": "https://api.github.com/repos/rook/rook/issues/4471/events",
  "html_url": "https://github.com/rook/rook/issues/4471",
  "id": 536265891,
  "labels": [
    {
      "color": "ee0000",
      "default": true,
      "description": "",
      "id": 405241115,
      "name": "bug",
      "node_id": "MDU6TGFiZWw0MDUyNDExMTU=",
      "url": "https://api.github.com/repos/rook/rook/labels/bug"
    }
  ],
  "labels_url": "https://api.github.com/repos/rook/rook/issues/4471/labels{/name}",
  "locked": false,
  "milestone": null,
  "node_id": "MDU6SXNzdWU1MzYyNjU4OTE=",
  "number": 4471,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/rook/rook",
  "state": "closed",
  "title": "Fail liveness probe on cephobjectstorage pod",
  "updated_at": "2019-12-13T05:55:16Z",
  "url": "https://api.github.com/repos/rook/rook/issues/4471",
  "user": {
    "avatar_url": "https://avatars2.githubusercontent.com/u/57938800?v=4",
    "events_url": "https://api.github.com/users/minh-nguyenquang/events{/privacy}",
    "followers_url": "https://api.github.com/users/minh-nguyenquang/followers",
    "following_url": "https://api.github.com/users/minh-nguyenquang/following{/other_user}",
    "gists_url": "https://api.github.com/users/minh-nguyenquang/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/minh-nguyenquang",
    "id": 57938800,
    "login": "minh-nguyenquang",
    "node_id": "MDQ6VXNlcjU3OTM4ODAw",
    "organizations_url": "https://api.github.com/users/minh-nguyenquang/orgs",
    "received_events_url": "https://api.github.com/users/minh-nguyenquang/received_events",
    "repos_url": "https://api.github.com/users/minh-nguyenquang/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/minh-nguyenquang/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/minh-nguyenquang/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/minh-nguyenquang"
  }
}