{
  "active_lock_reason": null,
  "assignee": null,
  "assignees": [],
  "author_association": "NONE",
  "body": "Check [CONTRIBUTING guideline](https://github.com/fluent/fluentd/blob/master/CONTRIBUTING.md) first and here is the list to help us investigate the problem.\r\n\r\n**Describe the bug**\r\n<!-- A clear and concise description of what the bug is. -->\r\nI have fluentd tailing kubernetes logs, and sending them to elasticsearch and s3. Both outputs are configured to use file buffers in order to avoid the loss of logs if something happens to the fluentd pod. On one cluster in particular, the s3 file buffer has been filling up with a huge number of empty buffer metadata files (all zero bytes), to the point that it uses up all the inodes on the volume. There is not associated log buffer file, just the metadata. Some of these empty metadata files were months old. I had to go manually clean up all the zero byte metadata files in order to restore cluster functionality. Looking for some insight into why these blank metadata files are created, and why they are never cleaned up by fluentd.\r\n\r\nIn the past, we were seeing issues with fluentd throughput, and the log buffers would get backed up and fill up all the disk space, so I do have it configured to aggressively create and flush chunks.\r\n\r\n${archive_path} is configured from kubernetes metadata like so: `${'container-logs/' + record['kubernetes']['namespace_name'] + '/' + record['kubernetes']['container_name'] + '/' + record['kubernetes']['pod_name'] + '/'}`. That along with the 60s chunk interval can make for a lot of chunks when many pods are redeployed, but I still would not expect to see over a million chunks, and it doesn't explain why these empty metadata files are left in place, seemingly forever.\r\n\r\nAlso asked a question about this [here](https://github.com/fluent/fluentd/issues/1768#issuecomment-523200558), but it does seem like it's a different issue than what the original question was about so I figured I'd create a new one.\r\n\r\n**To Reproduce**\r\n\r\nStill working on reproducing this behavior in a dev cluster. Best I can tell, lots of pod redeploys and nightly cronjob pods. \r\n\r\n**Expected behavior**\r\nEmpty metadata files should be cleaned up by fluentd.\r\n\r\n**Your Environment**\r\n\r\n- Fluentd or td-agent version: `fluentd --version` or `td-agent --version`\r\ntd-agent 1.3.3\r\n- Operating system: `cat /etc/os-release`\r\nNAME=\"Container Linux by CoreOS\"\r\nID=coreos\r\nVERSION=1967.6.0\r\nVERSION_ID=1967.6.0\r\nBUILD_ID=2019-02-12-2138\r\nPRETTY_NAME=\"Container Linux by CoreOS 1967.6.0 (Rhyolite)\"\r\nANSI_COLOR=\"38;5;75\"\r\nHOME_URL=\"https://coreos.com/\"\r\nBUG_REPORT_URL=\"https://issues.coreos.com\"\r\nCOREOS_BOARD=\"amd64-usr\"\r\n- Kernel version: `uname -r`\r\n4.14.96-coreos-r1\r\n\r\nIf you hit the problem with older fluentd version, try latest version first.\r\n\r\n**Your Configuration**\r\n\r\n```\r\n    <match **>\r\n      @type copy_ex\r\n      <store ignore_error>\r\n        @id elasticsearch\r\n        @type elasticsearch\r\n        @log_level debug\r\n        id_key _hash\r\n        remove_keys _hash,_tag # Remove temp key\r\n        include_tag_key true\r\n        host \"#{ENV['FLUENT_ELASTICSEARCH_HOST']}\"\r\n        port \"#{ENV['FLUENT_ELASTICSEARCH_PORT']}\"\r\n        scheme \"#{ENV['FLUENT_ELASTICSEARCH_SCHEME'] || 'http'}\"\r\n        logstash_prefix \"#{ENV['FLUENT_ELASTICSEARCH_LOGSTASH_PREFIX'] || 'logstash'}\"\r\n        logstash_format true\r\n        reload_connections false\r\n        reconnect_on_error true\r\n        reload_on_failure true\r\n        <buffer>\r\n          @type file\r\n          path /var/log/fluent/elasticsearch\r\n          flush_mode interval\r\n          retry_type exponential_backoff\r\n          flush_interval 5s\r\n          retry_forever\r\n          retry_max_interval 30m\r\n          chunk_limit_size 2M\r\n          overflow_action block\r\n        </buffer>\r\n      </store>\r\n      <store ignore_error>\r\n        @id s3\r\n        @type s3\r\n        @log_level info\r\n        aws_key_id \"#{ENV['AWS_ACCESS_KEY_ID']}\"\r\n        aws_sec_key \"#{ENV['AWS_SECRET_ACCESS_KEY']}\"\r\n        s3_region \"#{ENV['AWS_DEFAULT_REGION']}\"\r\n        s3_bucket \"#{ENV['AWS_S3_BUCKET']}\"\r\n        store_as json\r\n        path ${archive_path}\r\n        time_slice_format %Y-%m-%d-%H:%M\r\n        <buffer archive_path,time>\r\n          @type file\r\n          path /var/log/fluent/s3\r\n          timekey 60s\r\n          timekey_wait 10s\r\n          timekey_use_utc true # use utc\r\n          chunk_limit_size 64m\r\n          flush_thread_count 4\r\n          flush_mode interval\r\n          flush_interval 60s\r\n          retry_forever\r\n          overflow_action block\r\n        </buffer>\r\n      </store>\r\n    </match>\r\n```\r\n\r\n**Your Error Log**\r\n\r\nCouldn't find any error logs. Even with debug mode on and removing the ignore_error flag.\r\n\r\n",
  "closed_at": "2019-09-04T06:43:08Z",
  "closed_by": {
    "avatar_url": "https://avatars0.githubusercontent.com/u/5616899?v=4",
    "events_url": "https://api.github.com/users/ganmacs/events{/privacy}",
    "followers_url": "https://api.github.com/users/ganmacs/followers",
    "following_url": "https://api.github.com/users/ganmacs/following{/other_user}",
    "gists_url": "https://api.github.com/users/ganmacs/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/ganmacs",
    "id": 5616899,
    "login": "ganmacs",
    "node_id": "MDQ6VXNlcjU2MTY4OTk=",
    "organizations_url": "https://api.github.com/users/ganmacs/orgs",
    "received_events_url": "https://api.github.com/users/ganmacs/received_events",
    "repos_url": "https://api.github.com/users/ganmacs/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/ganmacs/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/ganmacs/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/ganmacs"
  },
  "comments": 7,
  "comments_url": "https://api.github.com/repos/fluent/fluentd/issues/2593/comments",
  "created_at": "2019-08-29T17:44:05Z",
  "events_url": "https://api.github.com/repos/fluent/fluentd/issues/2593/events",
  "html_url": "https://github.com/fluent/fluentd/issues/2593",
  "id": 487092188,
  "labels": [
    {
      "color": "e11d21",
      "default": true,
      "description": null,
      "id": 94152935,
      "name": "bug",
      "node_id": "MDU6TGFiZWw5NDE1MjkzNQ==",
      "url": "https://api.github.com/repos/fluent/fluentd/labels/bug"
    }
  ],
  "labels_url": "https://api.github.com/repos/fluent/fluentd/issues/2593/labels{/name}",
  "locked": false,
  "milestone": null,
  "node_id": "MDU6SXNzdWU0ODcwOTIxODg=",
  "number": 2593,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/fluent/fluentd",
  "state": "closed",
  "title": "Fluentd fails to cleanup buffer metadata",
  "updated_at": "2019-09-04T06:43:08Z",
  "url": "https://api.github.com/repos/fluent/fluentd/issues/2593",
  "user": {
    "avatar_url": "https://avatars2.githubusercontent.com/u/11621797?v=4",
    "events_url": "https://api.github.com/users/bhperry/events{/privacy}",
    "followers_url": "https://api.github.com/users/bhperry/followers",
    "following_url": "https://api.github.com/users/bhperry/following{/other_user}",
    "gists_url": "https://api.github.com/users/bhperry/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/bhperry",
    "id": 11621797,
    "login": "bhperry",
    "node_id": "MDQ6VXNlcjExNjIxNzk3",
    "organizations_url": "https://api.github.com/users/bhperry/orgs",
    "received_events_url": "https://api.github.com/users/bhperry/received_events",
    "repos_url": "https://api.github.com/users/bhperry/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/bhperry/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/bhperry/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/bhperry"
  }
}