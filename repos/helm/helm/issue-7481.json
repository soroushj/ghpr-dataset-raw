{
  "active_lock_reason": null,
  "assignee": null,
  "assignees": [],
  "author_association": "CONTRIBUTOR",
  "body": "Output of `helm version`:\r\n```\r\n$ helm-3.0.2 version\r\nversion.BuildInfo{Version:\"v3.0.2\", GitCommit:\"19e47ee3283ae98139d98460de796c1be1e3975f\", GitTreeState:\"clean\", GoVersion:\"go1.13.5\"}\r\n```\r\n\r\nOutput of `kubectl version`:\r\n```\r\nClient Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.0\", GitCommit:\"2bd9643cee5b3b3a5ecbd3af49d09018f0773c77\", GitTreeState:\"clean\", BuildDate:\"2019-09-18T14:36:53Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"darwin/amd64\"}\r\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.6\", GitCommit:\"7015f71e75f670eb9e7ebd4b5749639d42e20079\", GitTreeState:\"clean\", BuildDate:\"2019-11-13T11:11:50Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\r\n```\r\n\r\nCloud Provider/Platform (AKS, GKE, Minikube etc.): AWS, via Kops.\r\n\r\nI'm running an `upgrade` over a successfully deployed release. The `upgrade` sets image tag to a non-existent one, causing deployment to never succeed and timeout.\r\n\r\nExpectation: release is rolled back to the previous version\r\nActual: `helm` fails with `Error: UPGRADE FAILED: an error occurred while cleaning up resources. original upgrade error: timed out waiting for the condition: unable to cleanup resources: object not found, skipping delete` error.\r\n\r\nFull log:\r\n```\r\n$ helm-3.0.2 upgrade --install myapp charts/some-chart --version 0.6.0 --values values.yaml --set ingress.host=myapp.dot.com --set-string name=myapp,image.name=registry/myapp,image.tag=WRONGTAG --wait --atomic --cleanup-on-fail --namespace helm3-test-1 --timeout 1m --debug -v 5\r\nhistory.go:52: [debug] getting history for release myapp\r\nupgrade.go:79: [debug] preparing upgrade for myapp\r\nI0128 19:46:56.330953   72366 cached_discovery.go:78] skipped caching discovery info due to Unauthorized\r\naction.go:120: [debug] WARNING: The Kubernetes server has an orphaned API service. Server reports: unable to retrieve the complete list of server APIs: node.k8s.io/v1beta1: Unauthorized\r\naction.go:121: [debug] WARNING: To fix this, kubectl delete apiservice <service-name>\r\nupgrade.go:87: [debug] performing update for myapp\r\nupgrade.go:225: [debug] creating upgraded release for myapp\r\nclient.go:151: [debug] checking 5 resources for changes\r\nclient.go:386: [debug] Looks like there are no changes for PodDisruptionBudget \"myapp\"\r\nclient.go:386: [debug] Looks like there are no changes for Service \"myapp\"\r\nclient.go:386: [debug] Looks like there are no changes for Ingress \"myapp\"\r\nclient.go:386: [debug] Looks like there are no changes for ServiceMonitor \"myapp-monitor\"\r\nwait.go:51: [debug] beginning wait for 5 resources with timeout of 1m0s\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nwait.go:199: [debug] Deployment is not ready: mynamespace/myapp. 0 out of 1 expected pods are ready\r\nupgrade.go:280: [debug] warning: Upgrade \"myapp\" failed: timed out waiting for the condition\r\nupgrade.go:286: [debug] Cleanup on fail set, cleaning up 0 resources\r\nError: UPGRADE FAILED: an error occurred while cleaning up resources. original upgrade error: timed out waiting for the condition: unable to cleanup resources: object not found, skipping delete\r\nhelm.go:76: [debug] unable to cleanup resources: object not found, skipping delete\r\nan error occurred while cleaning up resources. original upgrade error: timed out waiting for the condition\r\nhelm.sh/helm/v3/pkg/action.(*Upgrade).failRelease\r\n        /home/circleci/helm.sh/helm/pkg/action/upgrade.go:293\r\nhelm.sh/helm/v3/pkg/action.(*Upgrade).performUpgrade\r\n        /home/circleci/helm.sh/helm/pkg/action/upgrade.go:258\r\nhelm.sh/helm/v3/pkg/action.(*Upgrade).Run\r\n        /home/circleci/helm.sh/helm/pkg/action/upgrade.go:88\r\nmain.newUpgradeCmd.func1\r\n        /home/circleci/helm.sh/helm/cmd/helm/upgrade.go:134\r\ngithub.com/spf13/cobra.(*Command).execute\r\n        /go/pkg/mod/github.com/spf13/cobra@v0.0.5/command.go:826\r\ngithub.com/spf13/cobra.(*Command).ExecuteC\r\n        /go/pkg/mod/github.com/spf13/cobra@v0.0.5/command.go:914\r\ngithub.com/spf13/cobra.(*Command).Execute\r\n        /go/pkg/mod/github.com/spf13/cobra@v0.0.5/command.go:864\r\nmain.main\r\n        /home/circleci/helm.sh/helm/cmd/helm/helm.go:75\r\nruntime.main\r\n        /usr/local/go/src/runtime/proc.go:203\r\nruntime.goexit\r\n        /usr/local/go/src/runtime/asm_amd64.s:1357\r\nUPGRADE FAILED\r\nmain.newUpgradeCmd.func1\r\n        /home/circleci/helm.sh/helm/cmd/helm/upgrade.go:136\r\ngithub.com/spf13/cobra.(*Command).execute\r\n        /go/pkg/mod/github.com/spf13/cobra@v0.0.5/command.go:826\r\ngithub.com/spf13/cobra.(*Command).ExecuteC\r\n        /go/pkg/mod/github.com/spf13/cobra@v0.0.5/command.go:914\r\ngithub.com/spf13/cobra.(*Command).Execute\r\n        /go/pkg/mod/github.com/spf13/cobra@v0.0.5/command.go:864\r\nmain.main\r\n        /home/circleci/helm.sh/helm/cmd/helm/helm.go:75\r\nruntime.main\r\n        /usr/local/go/src/runtime/proc.go:203\r\nruntime.goexit\r\n        /usr/local/go/src/runtime/asm_amd64.s:1357\r\n```\r\n\r\nUnsure why the `Unauthorized` error occurs. `helm` is clearly able to connect to the cluster, as can `kubectl` (auth is via `aws-iam-authenticator`).\r\n\r\nAdditional info: I ran this with a debugger (with the same settings and results), and noticed that `results.Created` https://github.com/helm/helm/blob/19e47ee3283ae98139d98460de796c1be1e3975f/pkg/action/upgrade.go#L265 is `nil`. `results.Updated`, however, contained objects. Perhaps here https://github.com/helm/helm/blob/19e47ee3283ae98139d98460de796c1be1e3975f/pkg/action/upgrade.go#L285 an additional check for `&& len(created) > 0` is missing?",
  "closed_at": "2020-01-29T16:11:11Z",
  "closed_by": {
    "avatar_url": "https://avatars2.githubusercontent.com/u/1360539?v=4",
    "events_url": "https://api.github.com/users/bacongobbler/events{/privacy}",
    "followers_url": "https://api.github.com/users/bacongobbler/followers",
    "following_url": "https://api.github.com/users/bacongobbler/following{/other_user}",
    "gists_url": "https://api.github.com/users/bacongobbler/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/bacongobbler",
    "id": 1360539,
    "login": "bacongobbler",
    "node_id": "MDQ6VXNlcjEzNjA1Mzk=",
    "organizations_url": "https://api.github.com/users/bacongobbler/orgs",
    "received_events_url": "https://api.github.com/users/bacongobbler/received_events",
    "repos_url": "https://api.github.com/users/bacongobbler/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/bacongobbler/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/bacongobbler/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/bacongobbler"
  },
  "comments": 2,
  "comments_url": "https://api.github.com/repos/helm/helm/issues/7481/comments",
  "created_at": "2020-01-28T19:13:41Z",
  "events_url": "https://api.github.com/repos/helm/helm/issues/7481/events",
  "html_url": "https://github.com/helm/helm/issues/7481",
  "id": 556410988,
  "labels": [
    {
      "color": "e11d21",
      "default": true,
      "description": "Categorizes issue or PR as related to a bug.",
      "id": 778135666,
      "name": "bug",
      "node_id": "MDU6TGFiZWw3NzgxMzU2NjY=",
      "url": "https://api.github.com/repos/helm/helm/labels/bug"
    }
  ],
  "labels_url": "https://api.github.com/repos/helm/helm/issues/7481/labels{/name}",
  "locked": false,
  "milestone": null,
  "node_id": "MDU6SXNzdWU1NTY0MTA5ODg=",
  "number": 7481,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/helm/helm",
  "state": "closed",
  "title": "Failed upgrade with --cleanup-on-fail errors out with \"unable to cleanup resources: object not found\"",
  "updated_at": "2020-01-29T16:11:11Z",
  "url": "https://api.github.com/repos/helm/helm/issues/7481",
  "user": {
    "avatar_url": "https://avatars0.githubusercontent.com/u/355800?v=4",
    "events_url": "https://api.github.com/users/diversario/events{/privacy}",
    "followers_url": "https://api.github.com/users/diversario/followers",
    "following_url": "https://api.github.com/users/diversario/following{/other_user}",
    "gists_url": "https://api.github.com/users/diversario/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/diversario",
    "id": 355800,
    "login": "diversario",
    "node_id": "MDQ6VXNlcjM1NTgwMA==",
    "organizations_url": "https://api.github.com/users/diversario/orgs",
    "received_events_url": "https://api.github.com/users/diversario/received_events",
    "repos_url": "https://api.github.com/users/diversario/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/diversario/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/diversario/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/diversario"
  }
}