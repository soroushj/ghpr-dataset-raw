{
  "active_lock_reason": null,
  "assignee": null,
  "assignees": [],
  "author_association": "CONTRIBUTOR",
  "body": "#### Overview of the Issue\r\n\r\nVttablets running with the `-restore_from_backup` flag will check the disk on boot, and if it is completely empty, they attempt to find a backup to restore from.  If this process is interrupted for any reason (VM failure, pod rescheduled, network failure, whatever) the disk ends up in an incomplete state: some of the backup has been restored, but not all of it.  At this point, the tablet becomes unusable without manual intervention, which usually consists of manually wiping the disk and restarting the restore.\r\n\r\nIt would be ideal if there were some kind of basic sanity checking with respect to backup restores: checking that the size of the data on disk matches what we expect from the bucket, or perhaps actually hashing the data in the bucket and comparing it to the hash of the data on the disk.  If the restore doesn't match, the disk should be wiped and the restore started over.\r\n\r\n#### Reproduction Steps\r\n\r\n1.  Create a shard `0` in a keyspace `ks`.  Create a backup with e.g. `./kvtctl.sh BackupShard ks/0`.\r\n1.  Destroy the shard once the backup is complete, and then recreate it with the `-restore_from_backup` flag on the vttablets.\r\n1.  Delete one of the pods while its vttablet logs report it is `copying all files` during the restore.\r\n1.  When the tablet restarts, it will skip restoring because it finds there is _some_ data on disk.  However, the data is incomplete and typically the tablet gets stuck in a loop where it attempts to start replication, which fails, because so much of the data directory is missing.\r\n\r\nDepending on when the restore process is interrupted, and how much write traffic the master is receiving, the failure mode varies.  I have seen everything from the tablet never becoming available because replication is fundamentally broken due to missing data dir files, to the tablet joining replication but literally missing data which only becomes evident when running a query.\r\n\r\n#### Binary version\r\nI first noticed this problem with a build from the master branch around Dec 2018, and as of a build from 4/16/2019 it is ongoing.\r\n\r\n\r\n#### Operating system and Environment details\r\n\r\nWe are on COS nodes in GKE 1.11.6\r\n\r\n#### Log Fragments\r\n\r\nIf the restore is interrupted early on, the vttablet container for the tablet enters a \"replication start loop\" like so:\r\n\r\n```\r\nI0417 19:51:29.802283       1 replication_reporter.go:69] Slave is stopped. Trying to reconnect to master...\r\nI0417 19:51:29.805436       1 locks.go:361] Locking shard keyspace/e8- for action repairReplication to app-0666719400 as parent)\r\nI0417 19:51:29.814082       1 query.go:73] exec CHANGE MASTER TO\r\n  MASTER_HOST = 'app-keyspace-xe8-x-replica-0.vttablet',\r\n  MASTER_PORT = 3306,\r\n  MASTER_USER = 'vt_repl',\r\n  MASTER_PASSWORD = '',\r\n  MASTER_CONNECT_RETRY = 10,\r\n  MASTER_AUTO_POSITION = 1\r\nI0417 19:51:29.975446       1 query.go:73] exec START SLAVE\r\nI0417 19:51:29.975805       1 locks.go:400] Unlocking shard keyspace/e8- for action repairReplication to app-0666719400 as parent) with error ExecuteFetch(START SLAVE) failed: Slave failed to initialize relay log info structure from the repository (errno 1872) (sqlstate HY000) during query: START SLAVE\r\nI0417 19:51:29.981451       1 replication_reporter.go:72] Failed to reconnect to master: ExecuteFetch(START SLAVE) failed: Slave failed to initialize relay log info structure from the repository (errno 1872) (sqlstate HY000) during query: START SLAVE\r\nI0417 19:51:29.982460       1 tabletserver.go:357] TabletServer state: NOT_SERVING (Not Connected) -> NOT_SERVING (Transitioning)\r\nI0417 19:51:30.102972       1 engine.go:134] Time taken to load the schema: 92ns\r\nI0417 19:51:30.103035       1 tx_engine.go:423] No grace period specified: performing normal wait.\r\nI0417 19:51:30.103056       1 tabletserver.go:357] TabletServer state: NOT_SERVING (Transitioning) -> NOT_SERVING (Not Connected)\r\nI0417 19:51:35.104567       1 replication_reporter.go:69] Slave is stopped. Trying to reconnect to master...\r\n```\r\n\r\nAnd this loops infinitely, leaving the tablet in an unhealthy state.  The only fix is to manually wipe the disk so that restore starts over entirely.",
  "closed_at": "2019-06-20T17:12:30Z",
  "closed_by": {
    "avatar_url": "https://avatars1.githubusercontent.com/u/388311?v=4",
    "events_url": "https://api.github.com/users/deepthi/events{/privacy}",
    "followers_url": "https://api.github.com/users/deepthi/followers",
    "following_url": "https://api.github.com/users/deepthi/following{/other_user}",
    "gists_url": "https://api.github.com/users/deepthi/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/deepthi",
    "id": 388311,
    "login": "deepthi",
    "node_id": "MDQ6VXNlcjM4ODMxMQ==",
    "organizations_url": "https://api.github.com/users/deepthi/orgs",
    "received_events_url": "https://api.github.com/users/deepthi/received_events",
    "repos_url": "https://api.github.com/users/deepthi/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/deepthi/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/deepthi/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/deepthi"
  },
  "comments": 2,
  "comments_url": "https://api.github.com/repos/vitessio/vitess/issues/4821/comments",
  "created_at": "2019-04-17T20:08:07Z",
  "events_url": "https://api.github.com/repos/vitessio/vitess/issues/4821/events",
  "html_url": "https://github.com/vitessio/vitess/issues/4821",
  "id": 434463399,
  "labels": [],
  "labels_url": "https://api.github.com/repos/vitessio/vitess/issues/4821/labels{/name}",
  "locked": false,
  "milestone": null,
  "node_id": "MDU6SXNzdWU0MzQ0NjMzOTk=",
  "number": 4821,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/vitessio/vitess",
  "state": "closed",
  "title": "Interrupted Restores Fail/Please Sanity Check Restores ",
  "updated_at": "2019-06-20T17:12:30Z",
  "url": "https://api.github.com/repos/vitessio/vitess/issues/4821",
  "user": {
    "avatar_url": "https://avatars1.githubusercontent.com/u/4452380?v=4",
    "events_url": "https://api.github.com/users/msolters/events{/privacy}",
    "followers_url": "https://api.github.com/users/msolters/followers",
    "following_url": "https://api.github.com/users/msolters/following{/other_user}",
    "gists_url": "https://api.github.com/users/msolters/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/msolters",
    "id": 4452380,
    "login": "msolters",
    "node_id": "MDQ6VXNlcjQ0NTIzODA=",
    "organizations_url": "https://api.github.com/users/msolters/orgs",
    "received_events_url": "https://api.github.com/users/msolters/received_events",
    "repos_url": "https://api.github.com/users/msolters/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/msolters/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/msolters/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/msolters"
  }
}