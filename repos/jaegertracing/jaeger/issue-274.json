{
  "active_lock_reason": null,
  "assignee": null,
  "assignees": [],
  "author_association": "MEMBER",
  "body": "I feel that Kafka could be a good storage backend because the primary way of discovering traces is over time windows that are short. \r\n\r\n### Basic idea\r\nHave `jaeger-agent` or `jaeger-collector` emit spans into Kafka with the `traceID` as key. Instead of using Cassandra/Elasticsearch as an index, simply operate on the data itself. \r\n\r\n### What charecteristics of Kafka apply?\r\n- Durable, high [read/write throughput](https://engineering.linkedin.com/kafka/benchmarking-apache-kafka-2-million-writes-second-three-cheap-machines) \r\n- Easy(?) to scale\r\n \r\n### What charecteristics of traces/spans apply?\r\n- Immutability \r\n\r\n### What is the data model? \r\nThe data model could be a thrift serialized representation of the span.\r\n\r\n### How do we combine spans into traces?\r\nKafka guarantees that all messages for a given key end up on a single partition. Combining spans into traces can be done on consumers by using Kafka's session windows based on traceID during query time. \r\n\r\nThis assumes that all spans with a given window fit in memory, which depends on window size and data volume. We might be able to improve upon the session window implementation by making it aware of the service name and operation name, allowing us to quickly discard unwanted spans. \r\n\r\nI think that the viability of Kafka as a backend storage hinges on whether we are able to do this operation quickly for a particular service name. If we aren't, we would need to rely on a streaming solution like Flink, Samza, etc which greatly increase complexity for common use cases. \r\n\r\n### How would search work?\r\nOnce we've combined spans into traces, we could use [Lucene-Luwak](https://github.com/flaxsearch/luwak) for searches.\r\n\r\nBecause we are reading from Kafka, we can easily tell users how far we are into the search process, and how much data remains in the time window. \r\nWe would also be able to keep expanding the time window until we hit a match. \r\nWe would be able to support `tail -f` style searches for debugging, etc. \r\nSearch performance would also be linear wrt the time windows selected, assuming a constant data volume. \r\n\r\n### How about aggregations?\r\nWe could use a similar approach to search, and maintain a running percentile, etc. \r\n\r\n### How does adaptive sampling work?\r\nAdaptive sampling parameters can be computed by a kafka consumer, and propagated to kafka producers using kafka itself. We could use the same mechanism for baggage whitelisting and other configuration changes. \r\n\r\nSee also: https://github.com/uber/jaeger/issues/212, which argues for not having kafka streaming directly out of Jaeger clients. \r\n",
  "closed_at": "2018-06-29T16:07:23Z",
  "closed_by": {
    "avatar_url": "https://avatars2.githubusercontent.com/u/3523016?v=4",
    "events_url": "https://api.github.com/users/yurishkuro/events{/privacy}",
    "followers_url": "https://api.github.com/users/yurishkuro/followers",
    "following_url": "https://api.github.com/users/yurishkuro/following{/other_user}",
    "gists_url": "https://api.github.com/users/yurishkuro/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/yurishkuro",
    "id": 3523016,
    "login": "yurishkuro",
    "node_id": "MDQ6VXNlcjM1MjMwMTY=",
    "organizations_url": "https://api.github.com/users/yurishkuro/orgs",
    "received_events_url": "https://api.github.com/users/yurishkuro/received_events",
    "repos_url": "https://api.github.com/users/yurishkuro/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/yurishkuro/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/yurishkuro/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/yurishkuro"
  },
  "comments": 3,
  "comments_url": "https://api.github.com/repos/jaegertracing/jaeger/issues/274/comments",
  "created_at": "2017-07-16T22:21:28Z",
  "events_url": "https://api.github.com/repos/jaegertracing/jaeger/issues/274/events",
  "html_url": "https://github.com/jaegertracing/jaeger/issues/274",
  "id": 243270663,
  "labels": [],
  "labels_url": "https://api.github.com/repos/jaegertracing/jaeger/issues/274/labels{/name}",
  "locked": false,
  "milestone": null,
  "node_id": "MDU6SXNzdWUyNDMyNzA2NjM=",
  "number": 274,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/jaegertracing/jaeger",
  "state": "closed",
  "title": "Kafka for trace storage",
  "updated_at": "2018-06-29T16:07:23Z",
  "url": "https://api.github.com/repos/jaegertracing/jaeger/issues/274",
  "user": {
    "avatar_url": "https://avatars0.githubusercontent.com/u/833009?v=4",
    "events_url": "https://api.github.com/users/vprithvi/events{/privacy}",
    "followers_url": "https://api.github.com/users/vprithvi/followers",
    "following_url": "https://api.github.com/users/vprithvi/following{/other_user}",
    "gists_url": "https://api.github.com/users/vprithvi/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/vprithvi",
    "id": 833009,
    "login": "vprithvi",
    "node_id": "MDQ6VXNlcjgzMzAwOQ==",
    "organizations_url": "https://api.github.com/users/vprithvi/orgs",
    "received_events_url": "https://api.github.com/users/vprithvi/received_events",
    "repos_url": "https://api.github.com/users/vprithvi/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/vprithvi/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/vprithvi/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/vprithvi"
  }
}