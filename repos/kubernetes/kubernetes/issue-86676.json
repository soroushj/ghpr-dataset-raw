{
  "active_lock_reason": null,
  "assignee": null,
  "assignees": [],
  "author_association": "MEMBER",
  "body": "<!-- Please use this template while reporting a bug and provide as much info as possible. Not doing so may result in your bug not being addressed in a timely manner. Thanks!\r\n\r\nIf the matter is security related, please disclose it privately via https://kubernetes.io/security/\r\n-->\r\n\r\n**TL;DR:** we discovered the checkpoint file panic in the kubelet that was introduced recently.\r\nsee the comments bellow.\r\n\r\n**What happened**:\r\ncreated a 3 control-plane cluster from latest CI 1.17 using kubeadm.\r\ninitiated a upgraded from latest CI 1.17 to latest CI 1.18 using kubeadm.\r\n\r\npods such as api-server, etcd end up with stopped containers:\r\n```\r\nKUBECONFIG=/etc/kubernetes/admin.conf kubectl describe po -n kube-system etcd-kinder-upgrade-control-plane-1 | grep Events -A 10\r\nEvents:\r\n  Type     Reason            Age                 From                                     Message\r\n  ----     ------            ----                ----                                     -------\r\n  Warning  DNSConfigForming  27m (x17 over 45m)  kubelet, kinder-upgrade-control-plane-1  Nameserver limits were exceeded, some nameservers have been omitted, the applied nameserver line is: 8.8.8.8 8.8.4.4 2001:4860:4860::8888\r\n  Normal   Killing           26m                 kubelet, kinder-upgrade-control-plane-1  Stopping container etcd\r\n```\r\n\r\nthe pod list gets stuck at this state, which is slightly incorrect as all containers running on the `-1` node are terminated:\r\n\r\n```\r\nroot@kinder-upgrade-control-plane-1:/# KUBECONFIG=/etc/kubernetes/admin.conf kubectl get po -A   \r\nNAMESPACE     NAME                                                     READY   STATUS        RESTARTS   AGE\r\nkube-system   calico-kube-controllers-564b6667d7-j6qzw                 0/1     Running       0          42m\r\nkube-system   calico-node-fg6mt                                        1/1     Running       0          39m\r\nkube-system   calico-node-k94w9                                        1/1     Running       0          37m\r\nkube-system   calico-node-nkfp6                                        0/1     Running       0          42m\r\nkube-system   coredns-6955765f44-nvj5d                                 0/1     Running       0          42m\r\nkube-system   coredns-6955765f44-trz6l                                 1/1     Running       0          24m\r\nkube-system   etcd-kinder-upgrade-control-plane-1                      1/1     Running       0          42m\r\nkube-system   etcd-kinder-upgrade-control-plane-2                      1/1     Running       0          39m\r\nkube-system   etcd-kinder-upgrade-control-plane-3                      1/1     Running       0          37m\r\nkube-system   kube-apiserver-kinder-upgrade-control-plane-1            1/1     Running       0          24m\r\nkube-system   kube-apiserver-kinder-upgrade-control-plane-2            1/1     Running       0          39m\r\nkube-system   kube-apiserver-kinder-upgrade-control-plane-3            1/1     Running       0          37m\r\nkube-system   kube-controller-manager-kinder-upgrade-control-plane-1   1/1     Running       0          24m\r\nkube-system   kube-controller-manager-kinder-upgrade-control-plane-2   1/1     Running       1          39m\r\nkube-system   kube-controller-manager-kinder-upgrade-control-plane-3   1/1     Running       0          37m\r\nkube-system   kube-proxy-cmssx                                         1/1     Running       0          39m\r\nkube-system   kube-proxy-f9vvn                                         1/1     Terminating   0          42m\r\nkube-system   kube-proxy-hqq22                                         1/1     Running       0          23m\r\nkube-system   kube-scheduler-kinder-upgrade-control-plane-1            1/1     Running       0          24m\r\nkube-system   kube-scheduler-kinder-upgrade-control-plane-2            1/1     Running       0          39m\r\nkube-system   kube-scheduler-kinder-upgrade-control-plane-3            1/1     Running       0          37m\r\n```\r\n\r\na panic is observed in the kubelet logs of the primary node:\r\n```\r\n$ journalctl -xeu kubelet\r\n\r\n<snip>\r\n\r\nDec 27 21:41:30 kinder-upgrade-control-plane-1 kubelet[30265]: goroutine 603 [running]:\r\nDec 27 21:41:30 kinder-upgrade-control-plane-1 kubelet[30265]: k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/util/runtime.logPanic(0x3a2dec0, 0x6d6df80)\r\nDec 27 21:41:30 kinder-upgrade-control-plane-1 kubelet[30265]:         /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/vendor/k8s.io/apimachinery/\r\npkg/util/runtime/runtime.go:74 +0xa3\r\nDec 27 21:41:30 kinder-upgrade-control-plane-1 kubelet[30265]: k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/util/runtime.HandleCrash(0x0, 0x0, 0x0)\r\nDec 27 21:41:30 kinder-upgrade-control-plane-1 kubelet[30265]:         /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/vendor/k8s.io/apimachinery/\r\npkg/util/runtime/runtime.go:48 +0x82\r\nDec 27 21:41:30 kinder-upgrade-control-plane-1 kubelet[30265]: panic(0x3a2dec0, 0x6d6df80)\r\nDec 27 21:41:30 kinder-upgrade-control-plane-1 kubelet[30265]:         /usr/local/go/src/runtime/panic.go:679 +0x1b2\r\nDec 27 21:41:30 kinder-upgrade-control-plane-1 kubelet[30265]: k8s.io/kubernetes/pkg/kubelet/cm.(*qosContainerManagerImpl).setCPUCgroupConfig(0xc000a8a0a0, 0xc000f14f38\r\n, 0x428037b, 0xa)\r\nDec 27 21:41:30 kinder-upgrade-control-plane-1 kubelet[30265]:         /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/pkg/kubelet/cm/qos_containe\r\nr_manager_linux.go:169 +0x3b\r\nDec 27 21:41:30 kinder-upgrade-control-plane-1 kubelet[30265]: k8s.io/kubernetes/pkg/kubelet/cm.(*qosContainerManagerImpl).UpdateCgroups(0xc000a8a0a0, 0x0, 0x0)\r\nDec 27 21:41:30 kinder-upgrade-control-plane-1 kubelet[30265]:         /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/pkg/kubelet/cm/qos_containe\r\nr_manager_linux.go:285 +0x291\r\nDec 27 21:41:30 kinder-upgrade-control-plane-1 kubelet[30265]: k8s.io/kubernetes/pkg/kubelet/cm.(*containerManagerImpl).UpdateQOSCgroups(0xc000415200, 0xc000b7c800, 0xc\r\n000d7e580)\r\nDec 27 21:41:30 kinder-upgrade-control-plane-1 kubelet[30265]:         /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/pkg/kubelet/cm/container_ma\r\nnager_linux.go:561 +0x3a\r\nDec 27 21:41:30 kinder-upgrade-control-plane-1 kubelet[30265]: k8s.io/kubernetes/pkg/kubelet.(*Kubelet).killPod(0xc000c2e000, 0xc000b7c800, 0x0, 0xc000d15300, 0x0, 0x4,\r\n 0x4)\r\nDec 27 21:41:30 kinder-upgrade-control-plane-1 kubelet[30265]:         /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/pkg/kubelet/kubelet_pods.go\r\n:832 +0x113\r\nDec 27 21:41:30 kinder-upgrade-control-plane-1 kubelet[30265]: k8s.io/kubernetes/pkg/kubelet.(*Kubelet).syncPod(0xc000c2e000, 0x0, 0xc000b7c800, 0x2, 0xc000d15300, 0x0,\r\n 0xc000143320, 0xc000d3bbf0)\r\nDec 27 21:41:30 kinder-upgrade-control-plane-1 kubelet[30265]:         /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/pkg/kubelet/kubelet.go:1613\r\n +0x2493\r\nDec 27 21:41:30 kinder-upgrade-control-plane-1 kubelet[30265]: k8s.io/kubernetes/pkg/kubelet.(*podWorkers).managePodLoop.func1(0xc0007a2ea0, 0xc000213730, 0xc000f15e88,\r\n 0xc0003271e0, 0x4a5ebc0)\r\nDec 27 21:41:30 kinder-upgrade-control-plane-1 kubelet[30265]:         /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/pkg/kubelet/pod_workers.go:\r\n175 +0x25d\r\nDec 27 21:41:30 kinder-upgrade-control-plane-1 kubelet[30265]: k8s.io/kubernetes/pkg/kubelet.(*podWorkers).managePodLoop(0xc000213730, 0xc000959f20)\r\nDec 27 21:41:30 kinder-upgrade-control-plane-1 kubelet[30265]:         /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/pkg/kubelet/pod_workers.go:\r\n184 +0x13f\r\nDec 27 21:41:30 kinder-upgrade-control-plane-1 kubelet[30265]: k8s.io/kubernetes/pkg/kubelet.(*podWorkers).UpdatePod.func1(0xc000213730, 0xc000959f20)\r\nDec 27 21:41:30 kinder-upgrade-control-plane-1 kubelet[30265]:         /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/pkg/kubelet/pod_workers.go:\r\n222 +0x6c\r\nDec 27 21:41:30 kinder-upgrade-control-plane-1 kubelet[30265]: created by k8s.io/kubernetes/pkg/kubelet.(*podWorkers).UpdatePod\r\nDec 27 21:41:30 kinder-upgrade-control-plane-1 kubelet[30265]:         /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/pkg/kubelet/pod_workers.go:\r\n220 +0x3d3\r\nDec 27 21:41:30 kinder-upgrade-control-plane-1 kubelet[30265]: E1227 21:41:30.920880   30265 runtime.go:78] Observed a panic: \"invalid memory address or nil pointer der\r\neference\" (runtime error: invalid memory address or nil pointer dereference)\r\nDec 27 21:41:30 kinder-upgrade-control-plane-1 kubelet[30265]: goroutine 497 [running]:\r\n```\r\n\r\n**What you expected to happen**:\r\nthe kubelet not killing containers.\r\n\r\n**How to reproduce it (as minimally and precisely as possible)**:\r\n\r\nit is possible with the tool `kinder` in the kubeadm repository, but it might take a while depending on your internet speed.\r\n\r\n```\r\ngit clone git@github.com:kubernetes/kubeadm.git --depth=1\r\ncd ./kubeadm/kinder\r\ngo build\r\n\r\ndocker pull kindest/base:v20190403-1ebf15f\r\n./kinder build node-image-variant --base-image=kindest/base:v20190403-1ebf15f --image=kindest/node:test --with-init-artifacts=v1.17.1-beta.0.30+7d04da8a4a80f2 --with-upgrade-artifacts=v1.18.0-alpha.1.181+13133857aff48f --loglevel=debug\r\n./kinder create cluster --name=kinder-upgrade --image=kindest/node:test --control-plane-nodes=3 --loglevel=debug\r\n./kinder do kubeadm-init --name=kinder-upgrade --automatic-copy-certs --loglevel=debug --kubeadm-verbosity=6\r\n./kinder do kubeadm-join --name=kinder-upgrade --automatic-copy-certs --loglevel=debug --kubeadm-verbosity=6\r\n./kinder do kubeadm-upgrade --upgrade-version=v1.18.0-alpha.1.181+13133857aff48f --name=kinder-upgrade --loglevel=debug --kubeadm-verbosity=6\r\n```\r\n^ the last command (upgrade) should fail near upgrading the etcd member on the second CP node.\r\n\r\n> Failed to get etcd status for https://172.17.0.3:2379: failed to dial endpoint https://172.17.0.3:2379 with maintenance client: context deadline exceeded\r\n\r\nat this point it is possible to ctrl+c (or wait for timeout - 10minutes) and execute in the primary CP node:\r\n\r\n```\r\ndocker exec -it  kinder-upgrade-control-plane-1 bash\r\nkubectl --kubeconfig /etc/kubernetes/admin.conf kubectl describe po -n kube-system etcd-kinder-upgrade-control-plane-1\r\njournalctl -xeu kubelet\r\ncrictl ps -a\r\n```\r\n\r\nto delete the cluster:\r\n```\r\nkinder delete cluster --name kinder-upgrade\r\n```\r\n\r\n**Anything else we need to know?**:\r\n- the tool kinder is doing something wrong, it upgrades the primary CP node kubelet before upgrading the api server on the second CP node. this is incorrect upgrade order, which i will TODO/verify if it affects the panic behavior here. [1]\r\n- the kinder runs containerd on the DIND nodes (based on kind).\r\n\r\nthis started failing after this DIFF:\r\nhttps://github.com/kubernetes/kubernetes/compare/0b830f3d6...e5f0648c6\r\n\r\na PR that touches `pkg/kubelet/cm/container_manager_linux.go` in that diff is:\r\nhttps://github.com/kubernetes/kubernetes/pull/84462\r\n\r\n/sig node\r\n/kind bug\r\ncc @klueska @liggitt\r\n\r\ni'm adding this priority:\r\n/priority awaiting-more-evidence\r\n\r\nbut if it still fails once [1] is corrected, i will escalate the priority.\r\n\r\nxref:\r\nhttps://github.com/kubernetes/kubeadm/issues/1981\r\n\r\n**Environment**:\r\n- Kubernetes version (use `kubectl version`): see above.\r\n- Cloud provider or hardware configuration: docker-in-docker\r\n- OS (e.g: `cat /etc/os-release`): `Ubuntu 18.04.1 LTS` in the DIND nodes.\r\n- Kernel (e.g. `uname -a`): `Linux kinder-upgrade-control-plane-1 4.13.0-41-generic #46-Ubuntu SMP Wed May 2 13:38:30 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux`\r\n- Install tools: kubeadm/kinder\r\n- Network plugin and version (if this is a network-related bug): calico 3.8.2\r\n- Others: NONE\r\n",
  "closed_at": "2020-01-08T10:57:41Z",
  "closed_by": {
    "avatar_url": "https://avatars0.githubusercontent.com/u/20407524?v=4",
    "events_url": "https://api.github.com/users/k8s-ci-robot/events{/privacy}",
    "followers_url": "https://api.github.com/users/k8s-ci-robot/followers",
    "following_url": "https://api.github.com/users/k8s-ci-robot/following{/other_user}",
    "gists_url": "https://api.github.com/users/k8s-ci-robot/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/k8s-ci-robot",
    "id": 20407524,
    "login": "k8s-ci-robot",
    "node_id": "MDQ6VXNlcjIwNDA3NTI0",
    "organizations_url": "https://api.github.com/users/k8s-ci-robot/orgs",
    "received_events_url": "https://api.github.com/users/k8s-ci-robot/received_events",
    "repos_url": "https://api.github.com/users/k8s-ci-robot/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/k8s-ci-robot/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/k8s-ci-robot/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/k8s-ci-robot"
  },
  "comments": 19,
  "comments_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/86676/comments",
  "created_at": "2019-12-27T22:29:57Z",
  "events_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/86676/events",
  "html_url": "https://github.com/kubernetes/kubernetes/issues/86676",
  "id": 543008941,
  "labels": [
    {
      "color": "e11d21",
      "default": false,
      "description": "Categorizes issue or PR as related to a bug.",
      "id": 105146071,
      "name": "kind/bug",
      "node_id": "MDU6TGFiZWwxMDUxNDYwNzE=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/kind/bug"
    },
    {
      "color": "eb6420",
      "default": false,
      "description": "Important over the long term, but may not be staffed and/or may need multiple releases to complete.",
      "id": 496752236,
      "name": "priority/important-longterm",
      "node_id": "MDU6TGFiZWw0OTY3NTIyMzY=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/priority/important-longterm"
    },
    {
      "color": "d2b48c",
      "default": false,
      "description": "Categorizes an issue or PR as relevant to SIG Node.",
      "id": 173493665,
      "name": "sig/node",
      "node_id": "MDU6TGFiZWwxNzM0OTM2NjU=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/sig/node"
    }
  ],
  "labels_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/86676/labels{/name}",
  "locked": false,
  "milestone": null,
  "node_id": "MDU6SXNzdWU1NDMwMDg5NDE=",
  "number": 86676,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/kubernetes/kubernetes",
  "state": "closed",
  "title": "1.18: panic in \"pkg/kubelet/cm/qos_container_manager_linux.go\"",
  "updated_at": "2020-01-08T10:57:41Z",
  "url": "https://api.github.com/repos/kubernetes/kubernetes/issues/86676",
  "user": {
    "avatar_url": "https://avatars3.githubusercontent.com/u/331852?v=4",
    "events_url": "https://api.github.com/users/neolit123/events{/privacy}",
    "followers_url": "https://api.github.com/users/neolit123/followers",
    "following_url": "https://api.github.com/users/neolit123/following{/other_user}",
    "gists_url": "https://api.github.com/users/neolit123/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/neolit123",
    "id": 331852,
    "login": "neolit123",
    "node_id": "MDQ6VXNlcjMzMTg1Mg==",
    "organizations_url": "https://api.github.com/users/neolit123/orgs",
    "received_events_url": "https://api.github.com/users/neolit123/received_events",
    "repos_url": "https://api.github.com/users/neolit123/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/neolit123/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/neolit123/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/neolit123"
  }
}