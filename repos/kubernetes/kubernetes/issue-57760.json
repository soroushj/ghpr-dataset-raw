{
  "active_lock_reason": null,
  "assignee": null,
  "assignees": [],
  "author_association": "NONE",
  "body": "/kind bug\r\n\r\n\r\n**What happened**:\r\nAttempting to start kubelet on CoreOS machine with latest stable (`1576.4.0`). I have many other blades which are PXE booting where the commands work. For some reason on this box where CoreOS is installed to disk, it is not working. I have checked every possible setting and file and they are all identical ( permissions and values ).\r\n\r\n**What you expected to happen**:\r\nKubelet to start and start up manifests ( api, proxy, controller ). \r\n\r\n**How to reproduce it (as minimally and precisely as possible)**:\r\n\r\n\r\n\r\n**Anything else we need to know?**:\r\nKubelet never actually starts a docker container. Doing `docker ps -a` doesn't show anything exited. I can docker pull the images from google. I've tried almost every setting I can change over the past 2 days. \r\n\r\n**Environment**:\r\n- Kubernetes version (use `kubectl version`):\r\nI've tried both: v1.8.5 and v1.9.0\r\n- Cloud provider or hardware configuration:\r\nDell R720XD. 24core 64gb ram, 22 SSDs. Most are ceph OSDs, sda is raid 1 SSDs for the OS and ideally kubernetes master. Bonded 10G cards for private network ( flannel ) and bonded 1g cards for public network.\r\n- OS (e.g. from /etc/os-release):\r\n- Kernel (e.g. `uname -a`):\r\n`4.13.16-coreos-r2`\r\n- Install tools:\r\nBaremetal plain install. No tools used. \r\n- Others:\r\nDownloaded the bins into /opt/bin/ as described in kubernetes docs. The node is a member of etcd cluster. Manifests files are the usual, but kubelet doesn't get that far so I dont want to clutter and post configs. \r\n\r\nSystemd Kubelet Config:\r\n```\r\n[Service]\r\nEnvironment=\"PATH=/opt/bin/:/usr/bin/:/usr/sbin:$PATH\"\r\n\r\nExecStart=/opt/bin/kubelet \\\r\n  --kubeconfig=/etc/kubernetes/master-kubeconfig.yaml \\\r\n  --register-schedulable=false \\\r\n  --cni-conf-dir=/etc/kubernetes/cni/net.d \\\r\n  --network-plugin=cni \\\r\n  --cgroup-driver=cgroupfs \\\r\n  --max-pods=300 \\\r\n  --container-runtime=docker \\\r\n  --allow-privileged=true \\\r\n  --cloud-provider= \\\r\n  --pod-manifest-path=/etc/kubernetes/manifests \\\r\n  --hostname-override=blade33 \\\r\n  --cluster_dns=10.3.0.10 \\\r\n  --fail-swap-on=false \\\r\n  --v=5 \\\r\n  --cluster_domain=cluster.local\r\nRestart=always\r\nRestartSec=10\r\n\r\n[Install]\r\nWantedBy=multi-user.target\r\n[Unit]\r\nRequires=flanneld.service etcd-member.service\r\nAfter=flanneld.service\r\n```\r\nmaster-kubeconfig.yaml:\r\n```\r\napiVersion: v1\r\nkind: Config\r\nclusters:\r\n- name: local\r\n  cluster:\r\n    server: http://127.0.0.1:8080\r\nusers:\r\n- name: kubelet\r\ncontexts:\r\n- context:\r\n    cluster: local\r\n    user: kubelet\r\n  name: kubelet-context\r\ncurrent-context: kubelet-context\r\n```\r\n\r\n\r\nLogs from kubelet:\r\n```\r\nsystemd[1]: Started kubelet.service.\r\nFlag --register-schedulable has been deprecated, will be removed in a future version\r\nI0102 10:40:08.656965   27429 flags.go:52] FLAG: --address=\"0.0.0.0\"\r\nI0102 10:40:08.657104   27429 flags.go:52] FLAG: --allow-privileged=\"true\"\r\nI0102 10:40:08.657126   27429 flags.go:52] FLAG: --alsologtostderr=\"false\"\r\nI0102 10:40:08.657143   27429 flags.go:52] FLAG: --anonymous-auth=\"true\"\r\nI0102 10:40:08.657157   27429 flags.go:52] FLAG: --application-metrics-count-limit=\"100\"\r\nI0102 10:40:08.657172   27429 flags.go:52] FLAG: --authentication-token-webhook=\"false\"\r\nI0102 10:40:08.657184   27429 flags.go:52] FLAG: --authentication-token-webhook-cache-ttl=\"2m0s\"\r\nI0102 10:40:08.657204   27429 flags.go:52] FLAG: --authorization-mode=\"AlwaysAllow\"\r\nI0102 10:40:08.657222   27429 flags.go:52] FLAG: --authorization-webhook-cache-authorized-ttl=\"5m0s\"\r\nI0102 10:40:08.657237   27429 flags.go:52] FLAG: --authorization-webhook-cache-unauthorized-ttl=\"30s\"\r\nI0102 10:40:08.657250   27429 flags.go:52] FLAG: --azure-container-registry-config=\"\"\r\nI0102 10:40:08.657263   27429 flags.go:52] FLAG: --boot-id-file=\"/proc/sys/kernel/random/boot_id\"\r\nI0102 10:40:08.657278   27429 flags.go:52] FLAG: --bootstrap-checkpoint-path=\"\"\r\nI0102 10:40:08.657290   27429 flags.go:52] FLAG: --bootstrap-kubeconfig=\"\"\r\nI0102 10:40:08.657303   27429 flags.go:52] FLAG: --cadvisor-port=\"4194\"\r\nI0102 10:40:08.657322   27429 flags.go:52] FLAG: --cert-dir=\"/var/lib/kubelet/pki\"\r\nI0102 10:40:08.657337   27429 flags.go:52] FLAG: --cgroup-driver=\"cgroupfs\"\r\nI0102 10:40:08.657350   27429 flags.go:52] FLAG: --cgroup-root=\"\"\r\nI0102 10:40:08.657362   27429 flags.go:52] FLAG: --cgroups-per-qos=\"true\"\r\nI0102 10:40:08.657375   27429 flags.go:52] FLAG: --chaos-chance=\"0\"\r\nI0102 10:40:08.657395   27429 flags.go:52] FLAG: --client-ca-file=\"\"\r\nI0102 10:40:08.657407   27429 flags.go:52] FLAG: --cloud-config=\"\"\r\nI0102 10:40:08.657420   27429 flags.go:52] FLAG: --cloud-provider=\"\"\r\nI0102 10:40:08.657432   27429 flags.go:52] FLAG: --cloud-provider-gce-lb-src-cidrs=\"130.211.0.0/22,35.191.0.0/16,209.85.152.0/22,209.85.204.0/22\"\r\nI0102 10:40:08.657452   27429 flags.go:52] FLAG: --cluster-dns=\"[10.3.0.10]\"\r\nI0102 10:40:08.657475   27429 flags.go:52] FLAG: --cluster-domain=\"cluster.local\"\r\nI0102 10:40:08.657488   27429 flags.go:52] FLAG: --cni-bin-dir=\"\"\r\nI0102 10:40:08.657500   27429 flags.go:52] FLAG: --cni-conf-dir=\"/etc/kubernetes/cni/net.d\"\r\nI0102 10:40:08.657514   27429 flags.go:52] FLAG: --container-hints=\"/etc/cadvisor/container_hints.json\"\r\nI0102 10:40:08.657528   27429 flags.go:52] FLAG: --container-runtime=\"docker\"\r\nI0102 10:40:08.657541   27429 flags.go:52] FLAG: --container-runtime-endpoint=\"unix:///var/run/dockershim.sock\"\r\nI0102 10:40:08.657555   27429 flags.go:52] FLAG: --containerd=\"unix:///var/run/containerd.sock\"\r\nI0102 10:40:08.657569   27429 flags.go:52] FLAG: --containerized=\"false\"\r\nI0102 10:40:08.657596   27429 flags.go:52] FLAG: --contention-profiling=\"false\"\r\nI0102 10:40:08.657609   27429 flags.go:52] FLAG: --cpu-cfs-quota=\"true\"\r\nI0102 10:40:08.657622   27429 flags.go:52] FLAG: --cpu-manager-policy=\"none\"\r\nI0102 10:40:08.657635   27429 flags.go:52] FLAG: --cpu-manager-reconcile-period=\"10s\"\r\nI0102 10:40:08.657648   27429 flags.go:52] FLAG: --docker=\"unix:///var/run/docker.sock\"\r\nI0102 10:40:08.657663   27429 flags.go:52] FLAG: --docker-disable-shared-pid=\"true\"\r\nI0102 10:40:08.657675   27429 flags.go:52] FLAG: --docker-endpoint=\"unix:///var/run/docker.sock\"\r\nI0102 10:40:08.657689   27429 flags.go:52] FLAG: --docker-env-metadata-whitelist=\"\"\r\nI0102 10:40:08.657702   27429 flags.go:52] FLAG: --docker-only=\"false\"\r\nI0102 10:40:08.657715   27429 flags.go:52] FLAG: --docker-root=\"/var/lib/docker\"\r\nI0102 10:40:08.657728   27429 flags.go:52] FLAG: --docker-tls=\"false\"\r\nI0102 10:40:08.657741   27429 flags.go:52] FLAG: --docker-tls-ca=\"ca.pem\"\r\nI0102 10:40:08.657755   27429 flags.go:52] FLAG: --docker-tls-cert=\"cert.pem\"\r\nI0102 10:40:08.657768   27429 flags.go:52] FLAG: --docker-tls-key=\"key.pem\"\r\nI0102 10:40:08.657781   27429 flags.go:52] FLAG: --dynamic-config-dir=\"\"\r\nI0102 10:40:08.657800   27429 flags.go:52] FLAG: --enable-controller-attach-detach=\"true\"\r\nI0102 10:40:08.657812   27429 flags.go:52] FLAG: --enable-custom-metrics=\"false\"\r\nI0102 10:40:08.657825   27429 flags.go:52] FLAG: --enable-debugging-handlers=\"true\"\r\nI0102 10:40:08.657865   27429 flags.go:52] FLAG: --enable-load-reader=\"false\"\r\nI0102 10:40:08.657882   27429 flags.go:52] FLAG: --enable-server=\"true\"\r\nI0102 10:40:08.657895   27429 flags.go:52] FLAG: --enforce-node-allocatable=\"[pods]\"\r\nI0102 10:40:08.657919   27429 flags.go:52] FLAG: --event-burst=\"10\"\r\nI0102 10:40:08.657933   27429 flags.go:52] FLAG: --event-qps=\"5\"\r\nI0102 10:40:08.657946   27429 flags.go:52] FLAG: --event-storage-age-limit=\"default=0\"\r\nI0102 10:40:08.657960   27429 flags.go:52] FLAG: --event-storage-event-limit=\"default=0\"\r\nI0102 10:40:08.657973   27429 flags.go:52] FLAG: --eviction-hard=\"imagefs.available<15%,memory.available<100Mi,nodefs.available<10%,nodefs.inodesFree<5%\"\r\nI0102 10:40:08.658017   27429 flags.go:52] FLAG: --eviction-max-pod-grace-period=\"0\"\r\nI0102 10:40:08.658032   27429 flags.go:52] FLAG: --eviction-minimum-reclaim=\"\"\r\nI0102 10:40:08.658051   27429 flags.go:52] FLAG: --eviction-pressure-transition-period=\"5m0s\"\r\nI0102 10:40:08.658065   27429 flags.go:52] FLAG: --eviction-soft=\"\"\r\nI0102 10:40:08.658078   27429 flags.go:52] FLAG: --eviction-soft-grace-period=\"\"\r\nI0102 10:40:08.658092   27429 flags.go:52] FLAG: --exit-on-lock-contention=\"false\"\r\nI0102 10:40:08.658120   27429 flags.go:52] FLAG: --experimental-allocatable-ignore-eviction=\"false\"\r\nI0102 10:40:08.658133   27429 flags.go:52] FLAG: --experimental-allowed-unsafe-sysctls=\"[]\"\r\nI0102 10:40:08.658149   27429 flags.go:52] FLAG: --experimental-bootstrap-kubeconfig=\"\"\r\nI0102 10:40:08.658161   27429 flags.go:52] FLAG: --experimental-check-node-capabilities-before-mount=\"false\"\r\nI0102 10:40:08.658175   27429 flags.go:52] FLAG: --experimental-dockershim=\"false\"\r\nI0102 10:40:08.658200   27429 flags.go:52] FLAG: --experimental-dockershim-root-directory=\"/var/lib/dockershim\"\r\nI0102 10:40:08.658214   27429 flags.go:52] FLAG: --experimental-fail-swap-on=\"false\"\r\nI0102 10:40:08.658227   27429 flags.go:52] FLAG: --experimental-kernel-memcg-notification=\"false\"\r\nI0102 10:40:08.658240   27429 flags.go:52] FLAG: --experimental-mounter-path=\"\"\r\nI0102 10:40:08.658252   27429 flags.go:52] FLAG: --experimental-qos-reserved=\"\"\r\nI0102 10:40:08.658266   27429 flags.go:52] FLAG: --fail-swap-on=\"false\"\r\nI0102 10:40:08.658279   27429 flags.go:52] FLAG: --feature-gates=\"StreamingProxyRedirects=true\"\r\nI0102 10:40:08.658302   27429 flags.go:52] FLAG: --file-check-frequency=\"20s\"\r\nI0102 10:40:08.658316   27429 flags.go:52] FLAG: --global-housekeeping-interval=\"1m0s\"\r\nI0102 10:40:08.658330   27429 flags.go:52] FLAG: --google-json-key=\"\"\r\nI0102 10:40:08.658345   27429 flags.go:52] FLAG: --hairpin-mode=\"promiscuous-bridge\"\r\nI0102 10:40:08.658360   27429 flags.go:52] FLAG: --healthz-bind-address=\"127.0.0.1\"\r\nI0102 10:40:08.658373   27429 flags.go:52] FLAG: --healthz-port=\"10248\"\r\nI0102 10:40:08.658386   27429 flags.go:52] FLAG: --host-ipc-sources=\"[*]\"\r\nI0102 10:40:08.658408   27429 flags.go:52] FLAG: --host-network-sources=\"[*]\"\r\nI0102 10:40:08.658424   27429 flags.go:52] FLAG: --host-pid-sources=\"[*]\"\r\nI0102 10:40:08.658445   27429 flags.go:52] FLAG: --hostname-override=\"blade33\"\r\nI0102 10:40:08.658458   27429 flags.go:52] FLAG: --housekeeping-interval=\"10s\"\r\nI0102 10:40:08.658472   27429 flags.go:52] FLAG: --http-check-frequency=\"20s\"\r\nI0102 10:40:08.658486   27429 flags.go:52] FLAG: --image-gc-high-threshold=\"85\"\r\nI0102 10:40:08.658499   27429 flags.go:52] FLAG: --image-gc-low-threshold=\"80\"\r\nI0102 10:40:08.658512   27429 flags.go:52] FLAG: --image-pull-progress-deadline=\"1m0s\"\r\nI0102 10:40:08.658525   27429 flags.go:52] FLAG: --image-service-endpoint=\"\"\r\nI0102 10:40:08.658537   27429 flags.go:52] FLAG: --init-config-dir=\"\"\r\nI0102 10:40:08.658550   27429 flags.go:52] FLAG: --iptables-drop-bit=\"15\"\r\nI0102 10:40:08.658562   27429 flags.go:52] FLAG: --iptables-masquerade-bit=\"14\"\r\nI0102 10:40:08.658575   27429 flags.go:52] FLAG: --keep-terminated-pod-volumes=\"false\"\r\nI0102 10:40:08.658601   27429 flags.go:52] FLAG: --kube-api-burst=\"10\"\r\nI0102 10:40:08.658615   27429 flags.go:52] FLAG: --kube-api-content-type=\"application/vnd.kubernetes.protobuf\"\r\nI0102 10:40:08.658628   27429 flags.go:52] FLAG: --kube-api-qps=\"5\"\r\nI0102 10:40:08.658642   27429 flags.go:52] FLAG: --kube-reserved=\"\"\r\nI0102 10:40:08.658656   27429 flags.go:52] FLAG: --kube-reserved-cgroup=\"\"\r\nI0102 10:40:08.658669   27429 flags.go:52] FLAG: --kubeconfig=\"/etc/kubernetes/master-kubeconfig.yaml\"\r\nI0102 10:40:08.658684   27429 flags.go:52] FLAG: --kubelet-cgroups=\"\"\r\nI0102 10:40:08.658697   27429 flags.go:52] FLAG: --lock-file=\"\"\r\nI0102 10:40:08.658711   27429 flags.go:52] FLAG: --log-backtrace-at=\":0\"\r\nI0102 10:40:08.658727   27429 flags.go:52] FLAG: --log-cadvisor-usage=\"false\"\r\nI0102 10:40:08.658741   27429 flags.go:52] FLAG: --log-dir=\"\"\r\nI0102 10:40:08.658753   27429 flags.go:52] FLAG: --log-flush-frequency=\"5s\"\r\nI0102 10:40:08.658767   27429 flags.go:52] FLAG: --logtostderr=\"true\"\r\nI0102 10:40:08.658781   27429 flags.go:52] FLAG: --machine-id-file=\"/etc/machine-id,/var/lib/dbus/machine-id\"\r\nI0102 10:40:08.658797   27429 flags.go:52] FLAG: --make-iptables-util-chains=\"true\"\r\nI0102 10:40:08.658810   27429 flags.go:52] FLAG: --manifest-url=\"\"\r\nI0102 10:40:08.658822   27429 flags.go:52] FLAG: --manifest-url-header=\"\"\r\nI0102 10:40:08.658873   27429 flags.go:52] FLAG: --master-service-namespace=\"default\"\r\nI0102 10:40:08.658888   27429 flags.go:52] FLAG: --max-open-files=\"1000000\"\r\nI0102 10:40:08.658907   27429 flags.go:52] FLAG: --max-pods=\"300\"\r\nI0102 10:40:08.658920   27429 flags.go:52] FLAG: --maximum-dead-containers=\"-1\"\r\nI0102 10:40:08.658934   27429 flags.go:52] FLAG: --maximum-dead-containers-per-container=\"1\"\r\nI0102 10:40:08.658947   27429 flags.go:52] FLAG: --minimum-container-ttl-duration=\"0s\"\r\nI0102 10:40:08.658961   27429 flags.go:52] FLAG: --minimum-image-ttl-duration=\"2m0s\"\r\nI0102 10:40:08.658974   27429 flags.go:52] FLAG: --network-plugin=\"cni\"\r\nI0102 10:40:08.658986   27429 flags.go:52] FLAG: --network-plugin-mtu=\"0\"\r\nI0102 10:40:08.658999   27429 flags.go:52] FLAG: --node-ip=\"\"\r\nI0102 10:40:08.659011   27429 flags.go:52] FLAG: --node-labels=\"\"\r\nI0102 10:40:08.659029   27429 flags.go:52] FLAG: --node-status-update-frequency=\"10s\"\r\nI0102 10:40:08.659042   27429 flags.go:52] FLAG: --non-masquerade-cidr=\"10.0.0.0/8\"\r\nI0102 10:40:08.659055   27429 flags.go:52] FLAG: --oom-score-adj=\"-999\"\r\nI0102 10:40:08.659068   27429 flags.go:52] FLAG: --pod-cidr=\"\"\r\nI0102 10:40:08.659095   27429 flags.go:52] FLAG: --pod-infra-container-image=\"gcr.io/google_containers/pause-amd64:3.0\"\r\nI0102 10:40:08.659110   27429 flags.go:52] FLAG: --pod-manifest-path=\"/etc/kubernetes/manifests\"\r\nI0102 10:40:08.659123   27429 flags.go:52] FLAG: --pods-per-core=\"0\"\r\nI0102 10:40:08.659136   27429 flags.go:52] FLAG: --port=\"10250\"\r\nI0102 10:40:08.659150   27429 flags.go:52] FLAG: --protect-kernel-defaults=\"false\"\r\nI0102 10:40:08.659163   27429 flags.go:52] FLAG: --provider-id=\"\"\r\nI0102 10:40:08.659176   27429 flags.go:52] FLAG: --read-only-port=\"10255\"\r\nI0102 10:40:08.659189   27429 flags.go:52] FLAG: --really-crash-for-testing=\"false\"\r\nI0102 10:40:08.659202   27429 flags.go:52] FLAG: --register-node=\"true\"\r\nI0102 10:40:08.659215   27429 flags.go:52] FLAG: --register-schedulable=\"false\"\r\nI0102 10:40:08.659228   27429 flags.go:52] FLAG: --register-with-taints=\"\"\r\nI0102 10:40:08.659247   27429 flags.go:52] FLAG: --registry-burst=\"10\"\r\nI0102 10:40:08.659260   27429 flags.go:52] FLAG: --registry-qps=\"5\"\r\nI0102 10:40:08.659273   27429 flags.go:52] FLAG: --require-kubeconfig=\"false\"\r\nI0102 10:40:08.659285   27429 flags.go:52] FLAG: --resolv-conf=\"/etc/resolv.conf\"\r\nI0102 10:40:08.659298   27429 flags.go:52] FLAG: --rkt-api-endpoint=\"localhost:15441\"\r\nI0102 10:40:08.659311   27429 flags.go:52] FLAG: --rkt-path=\"\"\r\nI0102 10:40:08.659323   27429 flags.go:52] FLAG: --rkt-stage1-image=\"\"\r\nI0102 10:40:08.659335   27429 flags.go:52] FLAG: --root-dir=\"/var/lib/kubelet\"\r\nI0102 10:40:08.659348   27429 flags.go:52] FLAG: --rotate-certificates=\"false\"\r\nI0102 10:40:08.659361   27429 flags.go:52] FLAG: --runonce=\"false\"\r\nI0102 10:40:08.659374   27429 flags.go:52] FLAG: --runtime-cgroups=\"\"\r\nI0102 10:40:08.659386   27429 flags.go:52] FLAG: --runtime-request-timeout=\"2m0s\"\r\nI0102 10:40:08.659400   27429 flags.go:52] FLAG: --seccomp-profile-root=\"/var/lib/kubelet/seccomp\"\r\nI0102 10:40:08.659413   27429 flags.go:52] FLAG: --serialize-image-pulls=\"true\"\r\nI0102 10:40:08.659426   27429 flags.go:52] FLAG: --stderrthreshold=\"2\"\r\nI0102 10:40:08.659439   27429 flags.go:52] FLAG: --storage-driver-buffer-duration=\"1m0s\"\r\nI0102 10:40:08.659453   27429 flags.go:52] FLAG: --storage-driver-db=\"cadvisor\"\r\nI0102 10:40:08.659467   27429 flags.go:52] FLAG: --storage-driver-host=\"localhost:8086\"\r\nI0102 10:40:08.659480   27429 flags.go:52] FLAG: --storage-driver-password=\"root\"\r\nI0102 10:40:08.659492   27429 flags.go:52] FLAG: --storage-driver-secure=\"false\"\r\nI0102 10:40:08.659505   27429 flags.go:52] FLAG: --storage-driver-table=\"stats\"\r\nI0102 10:40:08.659533   27429 flags.go:52] FLAG: --storage-driver-user=\"root\"\r\nI0102 10:40:08.659546   27429 flags.go:52] FLAG: --streaming-connection-idle-timeout=\"4h0m0s\"\r\nI0102 10:40:08.659560   27429 flags.go:52] FLAG: --sync-frequency=\"1m0s\"\r\nI0102 10:40:08.659574   27429 flags.go:52] FLAG: --system-cgroups=\"\"\r\nI0102 10:40:08.659587   27429 flags.go:52] FLAG: --system-reserved=\"\"\r\nI0102 10:40:08.659601   27429 flags.go:52] FLAG: --system-reserved-cgroup=\"\"\r\nI0102 10:40:08.659613   27429 flags.go:52] FLAG: --tls-cert-file=\"\"\r\nI0102 10:40:08.659625   27429 flags.go:52] FLAG: --tls-private-key-file=\"\"\r\nI0102 10:40:08.659637   27429 flags.go:52] FLAG: --v=\"5\"\r\nI0102 10:40:08.659649   27429 flags.go:52] FLAG: --version=\"false\"\r\nI0102 10:40:08.659668   27429 flags.go:52] FLAG: --vmodule=\"\"\r\nI0102 10:40:08.659682   27429 flags.go:52] FLAG: --volume-plugin-dir=\"/usr/libexec/kubernetes/kubelet-plugins/volume/exec/\"\r\nI0102 10:40:08.659697   27429 flags.go:52] FLAG: --volume-stats-agg-period=\"1m0s\"\r\nI0102 10:40:08.659763   27429 feature_gate.go:220] feature gates: &{{} map[StreamingProxyRedirects:true]}\r\nI0102 10:40:08.659823   27429 controller.go:114] kubelet config controller: starting controller\r\nI0102 10:40:08.659852   27429 controller.go:118] kubelet config controller: validating combination of defaults and flags\r\nI0102 10:40:08.674475   27429 mount_linux.go:202] Detected OS with systemd\r\nI0102 10:40:08.679003   27429 iptables.go:589] couldn't get iptables-restore version; assuming it doesn't support --wait\r\nI0102 10:40:08.682023   27429 server.go:182] Version: v1.9.0\r\nI0102 10:40:08.682114   27429 feature_gate.go:220] feature gates: &{{} map[StreamingProxyRedirects:true]}\r\nI0102 10:40:08.682353   27429 plugins.go:101] No cloud provider specified.\r\nI0102 10:40:08.682387   27429 server.go:303] No cloud provider specified: \"\" from the config file: \"\"\r\nI0102 10:40:08.687122   27429 manager.go:151] cAdvisor running in container: \"/sys/fs/cgroup/cpu,cpuacct/system.slice/kubelet.service\"\r\nI0102 10:40:08.725627   27429 manager.go:163] Rkt not connected: rkt: cannot tcp Dial rkt api service: dial tcp 127.0.0.1:15441: getsockopt: connection refused\r\nI0102 10:40:08.725933   27429 manager.go:174] CRI-O not connected: Get http://%2Fvar%2Frun%2Fcrio%2Fcrio.sock/info: dial unix /var/run/crio/crio.sock: connect: no such file or directory\r\nI0102 10:40:08.776823   27429 fs.go:139] Filesystem UUIDs: map[0aafd8c1-8cc3-4274-9487-300411d6edd3:/dev/sda9 4059e708-60c5-4677-9959-22bcccf65c44:/dev/sda3 4b2fc952-8015-4483-882a-30f39153e865:/dev/sde1 58e2612b-c282-4681-aeb0-3cd01d7c2279:/dev/sdv1 75e9e027-195e-47ef-9a9d-a0bd303b72cd:/dev/sdl1 85367522-1a8c-45d2-b230-fb2510bd69c5:/dev/sdg1 9c211f3d-fcde-4672-8b85-456e7c37b9d6:/dev/sds1 a6c8bbdb-fa81-483b-bfd2-fc2a6ca2d783:/dev/sdj1 bb3b292f-a93b-4b5d-92d7-34d38dd9b78b:/dev/sdk1 c360b1bb-6870-476b-974d-6e9bf3d4aca8:/dev/sdn1 dc2d8740-d413-45af-968e-ad7610f4de10:/dev/sdd1 0b65e6d4-4128-4fd5-8b5d-aea276f9034e:/dev/dm-0 24c4c4c2-eb3a-471c-b979-c53c6fe0d826:/dev/sdr1 7FA0-0330:/dev/sda1 8a9f86b1-dc6b-49fe-bd77-023716dba052:/dev/sdh1 a51f32ea-fd44-438b-96e2-07408f1b91aa:/dev/sdp1 c9345585-a8df-4d56-aa23-7e8898bf5273:/dev/sdf1 272d1754-405b-4fc2-b39f-f01c6b5bd2fd:/dev/sda6 4581e8ab-affe-460f-a6cb-4a06664f6829:/dev/sdc1 4f90648e-7ffa-4c05-8775-c1de133217ef:/dev/sdb1 6c1f2abf-111d-4797-985b-2a11ebdd76cf:/dev/sdq1 7a9b635b-1ae0-4d0f-8737-86bb190d47de:/dev/sdu1 d12cd494-1671-4f90-9048-96824bde3fda:/dev/sdo1 85b9ca5d-39d4-4836-abcf-e355d013d739:/dev/sdm1 98d38fd0-fcdc-497f-8d02-de38cc8fa78b:/dev/sdt1 c35e9bbf-fd16-4daf-8117-2f94d9f9b4ed:/dev/sdi1]\r\nI0102 10:40:08.777026   27429 fs.go:140] Filesystem partitions: map[/dev/mapper/usr:{mountpoint:/usr major:254 minor:0 fsType:ext4 blockSize:0} none:{mountpoint:/run/torcx/unpack major:0 minor:36 fsType:tmpfs blockSize:0} /dev/sda6:{mountpoint:/usr/share/oem major:8 minor:6 fsType:ext4 blockSize:0} shm:{mountpoint:/var/lib/docker/containers/ac6e4e4b433279771fc651047c6223e2193b094e6a50dd23ac3c8b648a8e78f0/shm major:0 minor:56 fsType:tmpfs blockSize:0} tmpfs:{mountpoint:/dev/shm major:0 minor:19 fsType:tmpfs blockSize:0} /dev/sda9:{mountpoint:/var/lib/docker/overlay2 major:8 minor:9 fsType:ext4 blockSize:0}]\r\nI0102 10:40:12.794808   27429 manager.go:225] Machine: {NumCores:24 CpuFrequency:3000000 MemoryCapacity:67578486784 HugePages:[{PageSize:1048576 NumPages:0} {PageSize:2048 NumPages:0}] MachineID:c5abdafb5f19428caf66bcc1fa8e2a2d SystemUUID:4C4C4544-0032-4810-8034-CAC04F385931 BootID:9b99e13e-0939-4079-a467-89208155a0aa Filesystems:[{Device:none DeviceMajor:0 DeviceMinor:36 Capacity:33789243392 Type:vfs Inodes:8249327 HasInodes:true} {Device:/dev/sda6 DeviceMajor:8 DeviceMinor:6 Capacity:113229824 Type:vfs Inodes:32768 HasInodes:true} {Device:shm DeviceMajor:0 DeviceMinor:56 Capacity:67108864 Type:vfs Inodes:8249327 HasInodes:true} {Device:tmpfs DeviceMajor:0 DeviceMinor:19 Capacity:33789243392 Type:vfs Inodes:8249327 HasInodes:true} {Device:/dev/sda9 DeviceMajor:8 DeviceMinor:9 Capacity:120928075776 Type:vfs Inodes:30328256 HasInodes:true} {Device:/dev/mapper/usr DeviceMajor:254 DeviceMinor:0 Capacity:1031946240 Type:vfs Inodes:260096 HasInodes:true}] DiskMap:map[8:0:{Name:sda Major:8 Minor:0 Size:127372623872 Scheduler:deadline} 8:32:{Name:sdc Major:8 Minor:32 Size:119453777920 Scheduler:deadline} 8:48:{Name:sdd Major:8 Minor:48 Size:119453777920 Scheduler:deadline} 8:80:{Name:sdf Major:8 Minor:80 Size:249510756352 Scheduler:deadline} 8:160:{Name:sdk Major:8 Minor:160 Size:499558383616 Scheduler:deadline} 8:224:{Name:sdo Major:8 Minor:224 Size:146163105792 Scheduler:deadline} 8:240:{Name:sdp Major:8 Minor:240 Size:146163105792 Scheduler:deadline} 65:80:{Name:sdv Major:65 Minor:80 Size:146163105792 Scheduler:deadline} 254:0:{Name:dm-0 Major:254 Minor:0 Size:1065345024 Scheduler:none} 8:16:{Name:sdb Major:8 Minor:16 Size:239444426752 Scheduler:deadline} 8:208:{Name:sdn Major:8 Minor:208 Size:146163105792 Scheduler:deadline} 65:16:{Name:sdr Major:65 Minor:16 Size:146163105792 Scheduler:deadline} 65:64:{Name:sdu Major:65 Minor:64 Size:146163105792 Scheduler:deadline} 8:112:{Name:sdh Major:8 Minor:112 Size:119453777920 Scheduler:deadline} 8:144:{Name:sdj Major:8 Minor:144 Size:249510756352 Scheduler:deadline} 8:176:{N\r\name:sdl Major:8 Minor:176 Size:146163105792 Scheduler:deadline} 8:192:{Name:sdm Major:8 Minor:192 Size:146163105792 Scheduler:deadline} 65:0:{Name:sdq Major:65 Minor:0 Size:146163105792 Scheduler:deadline} 65:48:{Name:sdt Major:65 Minor:48 Size:146163105792 Scheduler:deadline} 8:64:{Name:sde Major:8 Minor:64 Size:239444426752 Scheduler:deadline} 8:96:{Name:sdg Major:8 Minor:96 Size:249510756352 Scheduler:deadline} 8:128:{Name:sdi Major:8 Minor:128 Size:119453777920 Scheduler:deadline} 65:32:{Name:sds Major:65 Minor:32 Size:146163105792 Scheduler:deadline}] NetworkDevices:[{Name:bond0 MacAddress:36:7b:3b:27:3c:ae Speed:40000 Mtu:9000} {Name:bond2 MacAddress:1e:b5:35:d7:07:5a Speed:2000 Mtu:9000} {Name:br-3b4b583e4a33 MacAddress:02:42:da:28:e1:5a Speed:0 Mtu:1500} {Name:eno1 MacAddress:b8:ca:3a:ee:ad:b8 Speed:1000 Mtu:1500} {Name:eno2 MacAddress:1e:b5:35:d7:07:5a Speed:1000 Mtu:9000} {Name:eno3 MacAddress:1e:b5:35:d7:07:5a Speed:1000 Mtu:9000} {Name:eno4 MacAddress:b8:ca:3a:ee:ad:bb Speed:1000 Mtu:1500} {Name:enp4s0f0 MacAddress:36:7b:3b:27:3c:ae Speed:10000 Mtu:9000} {Name:enp4s0f1 MacAddress:36:7b:3b:27:3c:ae Speed:10000 Mtu:9000} {Name:enp66s0f0 MacAddress:36:7b:3b:27:3c:ae Speed:10000 Mtu:9000} {Name:enp66s0f1 MacAddress:36:7b:3b:27:3c:ae Speed:10000 Mtu:9000} {Name:flannel.1 MacAddress:1a:b1:6e:f0:97:96 Speed:0 Mtu:1500}] Topology:[{Id:0 Memory:33759969280 Cores:[{Id:0 Threads:[0 12] Caches:[{Size:32768 Type:Data Level:1} {Size:32768 Type:Instruction Level:1} {Size:262144 Type:Unified Level:2}]} {Id:1 Threads:[2 14] Caches:[{Size:32768 Type:Data Level:1} {Size:32768 Type:Instruction Level:1} {Size:262144 Type:Unified Level:2}]} {Id:2 Threads:[4 16] Caches:[{Size:32768 Type:Data Level:1} {Size:32768 Type:Instruction Level:1} {Size:262144 Type:Unified Level:2}]} {Id:3 Threads:[6 18] Caches:[{Size:32768 Type:Data Level:1} {Size:32768 Type:Instruction Level:1} {Size:262144 Type:Unified Level:2}]} {Id:4 Threads:[8 20] Caches:[{Size:32768 Type:Data Level:1} {Size:32768 Type:Instruction Level:1} {Size:262144 Type:Uni\r\nfied Level:2}]} {Id:5 Threads:[10 22] Caches:[{Size:32768 Type:Data Level:1} {Size:32768 Type:Instruction Level:1} {Size:262144 Type:Unified Level:2}]}] Caches:[{Size:15728640 Type:Unified Level:3}]} {Id:1 Memory:33818517504 Cores:[{Id:0 Threads:[1 13] Caches:[{Size:32768 Type:Data Level:1} {Size:32768 Type:Instruction Level:1} {Size:262144 Type:Unified Level:2}]} {Id:1 Threads:[3 15] Caches:[{Size:32768 Type:Data Level:1} {Size:32768 Type:Instruction Level:1} {Size:262144 Type:Unified Level:2}]} {Id:2 Threads:[5 17] Caches:[{Size:32768 Type:Data Level:1} {Size:32768 Type:Instruction Level:1} {Size:262144 Type:Unified Level:2}]} {Id:3 Threads:[7 19] Caches:[{Size:32768 Type:Data Level:1} {Size:32768 Type:Instruction Level:1} {Size:262144 Type:Unified Level:2}]} {Id:4 Threads:[9 21] Caches:[{Size:32768 Type:Data Level:1} {Size:32768 Type:Instruction Level:1} {Size:262144 Type:Unified Level:2}]} {Id:5 Threads:[11 23] Caches:[{Size:32768 Type:Data Level:1} {Size:32768 Type:Instruction Level:1} {Size:262144 Type:Unified Level:2}]}] Caches:[{Size:15728640 Type:Unified Level:3}]}] CloudProvider:GCE InstanceType:Unknown InstanceID:Unknown}\r\nI0102 10:40:12.797535   27429 manager.go:231] Version: {KernelVersion:4.13.16-coreos-r2 ContainerOsVersion:Container Linux by CoreOS 1576.4.0 (Ladybug) DockerVersion:17.09.0-ce DockerAPIVersion:1.32 CadvisorVersion: CadvisorRevision:}\r\nI0102 10:40:12.799436   27429 server.go:233] Sending events to api server.\r\nI0102 10:40:12.799568   27429 server.go:428] --cgroups-per-qos enabled, but --cgroup-root was not specified.  defaulting to /\r\nI0102 10:40:12.803310   27429 container_manager_linux.go:242] container manager verified user specified cgroup-root exists: /\r\nI0102 10:40:12.803347   27429 container_manager_linux.go:247] Creating Container Manager object based on Node Config: {RuntimeCgroupsName: SystemCgroupsName: KubeletCgroupsName: ContainerRuntime:docker CgroupsPerQOS:true CgroupRoot:/ CgroupDriver:cgroupfs KubeletRootDir:/var/lib/kubelet ProtectKernelDefaults:false NodeAllocatableConfig:{KubeReservedCgroupName: SystemReservedCgroupName: EnforceNodeAllocatable:map[pods:{}] KubeReserved:map[] SystemReserved:map[] HardEvictionThresholds:[{Signal:memory.available Operator:LessThan Value:{Quantity:100Mi Percentage:0} GracePeriod:0s MinReclaim:<nil>} {Signal:nodefs.available Operator:LessThan Value:{Quantity:<nil> Percentage:0.1} GracePeriod:0s MinReclaim:<nil>} {Signal:nodefs.inodesFree Operator:LessThan Value:{Quantity:<nil> Percentage:0.05} GracePeriod:0s MinReclaim:<nil>} {Signal:imagefs.available Operator:LessThan Value:{Quantity:<nil> Percentage:0.15} GracePeriod:0s MinReclaim:<nil>}]} ExperimentalQOSReserved:map[] ExperimentalCPUManagerPolicy:none ExperimentalCPUManagerReconcilePeriod:10s}\r\nI0102 10:40:12.803557   27429 container_manager_linux.go:266] Creating device plugin manager: false\r\nI0102 10:40:12.803612   27429 oom_linux.go:65] attempting to set \"/proc/self/oom_score_adj\" to \"-999\"\r\nI0102 10:40:12.803866   27429 server.go:693] Using root directory: /var/lib/kubelet\r\nI0102 10:40:12.803914   27429 kubelet.go:290] Adding manifest path: /etc/kubernetes/manifests\r\nI0102 10:40:12.803955   27429 file.go:52] Watching path \"/etc/kubernetes/manifests\"\r\nI0102 10:40:12.803980   27429 kubelet.go:313] Watching apiserver\r\nI0102 10:40:12.804170   27429 reflector.go:202] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:47\r\nI0102 10:40:12.804290   27429 reflector.go:202] Starting reflector *v1.Service (0s) from k8s.io/kubernetes/pkg/kubelet/kubelet.go:465\r\nI0102 10:40:12.804256   27429 file.go:161] Reading manifest file \"/etc/kubernetes/manifests/kube-apiserver.yaml\"\r\nI0102 10:40:12.804369   27429 reflector.go:240] Listing and watching *v1.Service from k8s.io/kubernetes/pkg/kubelet/kubelet.go:465\r\nI0102 10:40:12.804379   27429 reflector.go:202] Starting reflector *v1.Node (0s) from k8s.io/kubernetes/pkg/kubelet/kubelet.go:474\r\nI0102 10:40:12.804450   27429 reflector.go:240] Listing and watching *v1.Node from k8s.io/kubernetes/pkg/kubelet/kubelet.go:474\r\nI0102 10:40:12.804298   27429 reflector.go:240] Listing and watching *v1.Pod from k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:47\r\nE0102 10:40:12.805467   27429 reflector.go:205] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:47: Failed to list *v1.Pod: Get http://127.0.0.1:8080/api/v1/pods?fieldSelector=spec.nodeName%3Dblade33&limit=500&resourceVersion=0: dial tcp 127.0.0.1:8080: getsockopt: connection refused\r\nE0102 10:40:12.805526   27429 reflector.go:205] k8s.io/kubernetes/pkg/kubelet/kubelet.go:465: Failed to list *v1.Service: Get http://127.0.0.1:8080/api/v1/services?limit=500&resourceVersion=0: dial tcp 127.0.0.1:8080: getsockopt: connection refused\r\nE0102 10:40:12.805571   27429 reflector.go:205] k8s.io/kubernetes/pkg/kubelet/kubelet.go:474: Failed to list *v1.Node: Get http://127.0.0.1:8080/api/v1/nodes?fieldSelector=metadata.name%3Dblade33&limit=500&resourceVersion=0: dial tcp 127.0.0.1:8080: getsockopt: connection refused\r\nI0102 10:40:12.808369   27429 iptables.go:589] couldn't get iptables-restore version; assuming it doesn't support --wait\r\nW0102 10:40:12.809780   27429 kubelet_network.go:139] Hairpin mode set to \"promiscuous-bridge\" but kubenet is not enabled, falling back to \"hairpin-veth\"\r\nI0102 10:40:12.809830   27429 kubelet.go:571] Hairpin mode set to \"hairpin-veth\"\r\nI0102 10:40:12.810260   27429 plugins.go:190] Loaded network plugin \"cni\"\r\nI0102 10:40:12.810322   27429 client.go:80] Connecting to docker on unix:///var/run/docker.sock\r\nI0102 10:40:12.810371   27429 client.go:109] Start docker client with request timeout=2m0s\r\nI0102 10:40:12.817307   27429 iptables.go:589] couldn't get iptables-restore version; assuming it doesn't support --wait\r\nI0102 10:40:12.818814   27429 plugins.go:190] Loaded network plugin \"cni\"\r\nI0102 10:40:12.818949   27429 docker_service.go:232] Docker cri networking managed by cni\r\nI0102 10:40:12.856321   27429 docker_service.go:237] Docker Info: &{ID:OSKT:R676:3XMT:554K:2HWV:5DHN:WFBN:5IXB:WVO5:V34A:PUS5:M6M7 Containers:25 ContainersRunning:24 ContainersPaused:0 ContainersStopped:1 Images:9 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Native Overlay Diff true]] SystemStatus:[] Plugins:{Volume:[local] Network:[bridge host macvlan null overlay] Authorization:[] Log:[awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6tables:true Debug:false NFd:215 OomKillDisable:true NGoroutines:363 SystemTime:2018-01-02T10:40:12.831429298-05:00 LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:0 KernelVersion:4.13.16-coreos-r2 OperatingSystem:Container Linux by CoreOS 1576.4.0 (Ladybug) OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:0xc420350070 NCPU:24 MemTotal:67578486784 GenericResources:[] DockerRootDir:/var/lib/docker HTTPProxy: HTTPSProxy: NoProxy: Name:blade33 Labels:[] ExperimentalBuild:false ServerVersion:17.09.0-ce ClusterStore: ClusterAdvertise: Runtimes:map[runc:{Path:docker-runc Args:[]}] DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:[] Nodes:0 Managers:0 Cluster:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:06b9cb35161009dcb7123345749fef02f7cea8e0 Expected:06b9cb35161009dcb7123345749fef02f7cea8e0} RuncCommit:{ID:3f2f8b84a77f73d38244dd690525642a72156c64 Expected:3f2f8b84a77f73d38244dd690525642a72156c64} InitCommit:{ID:v0.13.2 Expected:949e6facb77383876aeff8a6944dde66b3089574} SecurityOptions:[name=seccomp,profile=default name=selinux]}\r\nI0102 10:40:12.857178   27429 docker_service.go:250] Setting cgroupDriver to cgroupfs\r\nI0102 10:40:12.857767   27429 kubelet.go:645] RemoteRuntimeEndpoint: \"unix:///var/run/dockershim.sock\", RemoteImageEndpoint: \"unix:///var/run/dockershim.sock\"\r\nI0102 10:40:12.858177   27429 kubelet.go:648] Starting the GRPC server for the docker CRI shim.\r\nI0102 10:40:12.858258   27429 docker_server.go:51] Start dockershim grpc server\r\nI0102 10:40:12.859881   27429 container_manager_linux.go:756] attempting to apply oom_score_adj of -999 to pid 15746\r\nI0102 10:40:12.859935   27429 oom_linux.go:65] attempting to set \"/proc/15746/oom_score_adj\" to \"-999\"\r\nI0102 10:40:12.894861   27429 remote_runtime.go:43] Connecting to runtime service unix:///var/run/dockershim.sock\r\nI0102 10:40:12.895051   27429 remote_image.go:40] Connecting to image service unix:///var/run/dockershim.sock\r\nI0102 10:40:12.898509   27429 metadata.go:212] Failed to Get service accounts from gce metadata server: Get http://metadata.google.internal./computeMetadata/v1/instance/service-accounts/: dial tcp: lookup metadata.google.internal.: no such host\r\nI0102 10:40:12.906175   27429 common.go:61] Generated UID \"ab46c8ff7fc9329d274700bb52b10271\" pod \"kube-apiserver\" from /etc/kubernetes/manifests/kube-apiserver.yaml\r\nI0102 10:40:12.906230   27429 common.go:65] Generated Name \"kube-apiserver-blade33\" for UID \"ab46c8ff7fc9329d274700bb52b10271\" from URL /etc/kubernetes/manifests/kube-apiserver.yaml\r\nI0102 10:40:12.906249   27429 common.go:70] Using namespace \"kube-system\" for pod \"kube-apiserver-blade33\" from /etc/kubernetes/manifests/kube-apiserver.yaml\r\nI0102 10:40:12.906603   27429 file.go:161] Reading manifest file \"/etc/kubernetes/manifests/kube-controller-manager.yaml\"\r\nI0102 10:40:12.907854   27429 common.go:61] Generated UID \"55b5250678593c2bb8ecb21b099122ec\" pod \"kube-controller-manager\" from /etc/kubernetes/manifests/kube-controller-manager.yaml\r\nI0102 10:40:12.907888   27429 common.go:65] Generated Name \"kube-controller-manager-blade33\" for UID \"55b5250678593c2bb8ecb21b099122ec\" from URL /etc/kubernetes/manifests/kube-controller-manager.yaml\r\nI0102 10:40:12.907918   27429 common.go:70] Using namespace \"kube-system\" for pod \"kube-controller-manager-blade33\" from /etc/kubernetes/manifests/kube-controller-manager.yaml\r\nI0102 10:40:12.908084   27429 file.go:161] Reading manifest file \"/etc/kubernetes/manifests/kube-proxy.yaml\"\r\nI0102 10:40:12.908876   27429 common.go:61] Generated UID \"94b66253e8b6eacf62bc9150c9c94b95\" pod \"kube-proxy\" from /etc/kubernetes/manifests/kube-proxy.yaml\r\nI0102 10:40:12.908908   27429 common.go:65] Generated Name \"kube-proxy-blade33\" for UID \"94b66253e8b6eacf62bc9150c9c94b95\" from URL /etc/kubernetes/manifests/kube-proxy.yaml\r\nI0102 10:40:12.908924   27429 common.go:70] Using namespace \"kube-system\" for pod \"kube-proxy-blade33\" from /etc/kubernetes/manifests/kube-proxy.yaml\r\nI0102 10:40:12.909068   27429 file.go:161] Reading manifest file \"/etc/kubernetes/manifests/kube-scheduler.yaml\"\r\nI0102 10:40:12.909851   27429 common.go:61] Generated UID \"5580a82cadf9f5891498c5779588a229\" pod \"kube-scheduler\" from /etc/kubernetes/manifests/kube-scheduler.yaml\r\nI0102 10:40:12.909885   27429 common.go:65] Generated Name \"kube-scheduler-blade33\" for UID \"5580a82cadf9f5891498c5779588a229\" from URL /etc/kubernetes/manifests/kube-scheduler.yaml\r\nI0102 10:40:12.909901   27429 common.go:70] Using namespace \"kube-system\" for pod \"kube-scheduler-blade33\" from /etc/kubernetes/manifests/kube-scheduler.yaml\r\nI0102 10:40:12.910081   27429 config.go:297] Setting pods for source file\r\nI0102 10:40:12.910147   27429 config.go:405] Receiving a new pod \"kube-apiserver-blade33_kube-system(ab46c8ff7fc9329d274700bb52b10271)\"\r\nI0102 10:40:12.910184   27429 config.go:405] Receiving a new pod \"kube-controller-manager-blade33_kube-system(55b5250678593c2bb8ecb21b099122ec)\"\r\nI0102 10:40:12.910207   27429 config.go:405] Receiving a new pod \"kube-proxy-blade33_kube-system(94b66253e8b6eacf62bc9150c9c94b95)\"\r\nI0102 10:40:12.910227   27429 config.go:405] Receiving a new pod \"kube-scheduler-blade33_kube-system(5580a82cadf9f5891498c5779588a229)\"\r\nI0102 10:40:13.000563   27429 metadata.go:212] Failed to Get service accounts from gce metadata server: Get http://metadata.google.internal./computeMetadata/v1/instance/service-accounts/: dial tcp: lookup metadata.google.internal.: no such host\r\nI0102 10:40:13.202510   27429 metadata.go:212] Failed to Get service accounts from gce metadata server: Get http://metadata.google.internal./computeMetadata/v1/instance/service-accounts/: dial tcp: lookup metadata.google.internal.: no such host\r\nI0102 10:40:13.604543   27429 metadata.go:212] Failed to Get service accounts from gce metadata server: Get http://metadata.google.internal./computeMetadata/v1/instance/service-accounts/: dial tcp: lookup metadata.google.internal.: no such host\r\nI0102 10:40:13.805770   27429 reflector.go:240] Listing and watching *v1.Pod from k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:47\r\nE0102 10:40:13.806743   27429 reflector.go:205] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:47: Failed to list *v1.Pod: Get http://127.0.0.1:8080/api/v1/pods?fieldSelector=spec.nodeName%3Dblade33&limit=500&resourceVersion=0: dial tcp 127.0.0.1:8080: getsockopt: connection refused\r\nI0102 10:40:13.806800   27429 reflector.go:240] Listing and watching *v1.Service from k8s.io/kubernetes/pkg/kubelet/kubelet.go:465\r\nE0102 10:40:13.807506   27429 reflector.go:205] k8s.io/kubernetes/pkg/kubelet/kubelet.go:465: Failed to list *v1.Service: Get http://127.0.0.1:8080/api/v1/services?limit=500&resourceVersion=0: dial tcp 127.0.0.1:8080: getsockopt: connection refused\r\n```\r\n\r\nAfter days of debugging, I believe it has to do with these lines in the logs:\r\n```\r\nI0102 10:40:12.857178   27429 docker_service.go:250] Setting cgroupDriver to cgroupfs\r\nI0102 10:40:12.857767   27429 kubelet.go:645] RemoteRuntimeEndpoint: \"unix:///var/run/dockershim.sock\", RemoteImageEndpoint: \"unix:///var/run/dockershim.sock\"\r\nI0102 10:40:12.858177   27429 kubelet.go:648] Starting the GRPC server for the docker CRI shim.\r\nI0102 10:40:12.858258   27429 docker_server.go:51] Start dockershim grpc server\r\nI0102 10:40:12.859881   27429 container_manager_linux.go:756] attempting to apply oom_score_adj of -999 to pid 15746\r\nI0102 10:40:12.859935   27429 oom_linux.go:65] attempting to set \"/proc/15746/oom_score_adj\" to \"-999\"\r\nI0102 10:40:12.894861   27429 remote_runtime.go:43] Connecting to runtime service unix:///var/run/dockershim.sock\r\nI0102 10:40:12.895051   27429 remote_image.go:40] Connecting to image service unix:///var/run/dockershim.sock\r\n```\r\n\r\nWhen it tries to connect to the docker-shim which it creates, on the other machines it looks like this:\r\n```\r\nI0102 03:42:49.267200   30300 docker_legacy.go:151] No legacy containers found, stop performing legacy cleanup.\r\nI0102 03:42:49.267254   30300 kubelet.go:606] Starting the GRPC server for the docker CRI shim.\r\nI0102 03:42:49.267270   30300 docker_server.go:51] Start dockershim grpc server\r\nI0102 03:42:49.283334   30300 remote_runtime.go:43] Connecting to runtime service unix:///var/run/dockershim.sock\r\nI0102 03:42:49.284772   30300 kuberuntime_manager.go:178] Container runtime docker initialized, version: 17.09.0-ce, apiVersion: 1.32.0\r\n```\r\n\r\nThe success message `Container runtime docker initialized, version: 17.09.0-ce, apiVersion: 1.32.0` never gets printed on the failing node. Both `docker info` are identical. Flannel is up and running and can ping other flannel IPs on the network. \r\n\r\n\r\nBoth docker infos are:\r\n```\r\nContainers: 25\r\n Running: 24\r\n Paused: 0\r\n Stopped: 1\r\nImages: 9\r\nServer Version: 17.09.0-ce\r\nStorage Driver: overlay2\r\n Backing Filesystem: extfs\r\n Supports d_type: true\r\n Native Overlay Diff: true\r\nLogging Driver: json-file\r\nCgroup Driver: cgroupfs\r\nPlugins:\r\n Volume: local\r\n Network: bridge host macvlan null overlay\r\n Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog\r\nSwarm: inactive\r\nRuntimes: runc\r\nDefault Runtime: runc\r\nInit Binary: docker-init\r\ncontainerd version: 06b9cb35161009dcb7123345749fef02f7cea8e0\r\nrunc version: 3f2f8b84a77f73d38244dd690525642a72156c64\r\ninit version: v0.13.2 (expected: 949e6facb77383876aeff8a6944dde66b3089574)\r\nSecurity Options:\r\n seccomp\r\n  Profile: default\r\n selinux\r\nKernel Version: 4.13.16-coreos-r2\r\nOperating System: Container Linux by CoreOS 1576.4.0 (Ladybug)\r\nOSType: linux\r\nArchitecture: x86_64\r\nCPUs: 24\r\nTotal Memory: 62.94GiB\r\nName: blade33\r\nID: OSKT:R676:3XMT:554K:2HWV:5DHN:WFBN:5IXB:WVO5:V34A:PUS5:M6M7\r\nDocker Root Dir: /var/lib/docker\r\nDebug Mode (client): false\r\nDebug Mode (server): false\r\nRegistry: https://index.docker.io/v1/\r\nExperimental: false\r\nInsecure Registries:\r\n 127.0.0.0/8\r\nLive Restore Enabled: false\r\n```\r\n\r\nThe running containers are the OSDs.",
  "closed_at": "2018-01-16T15:20:00Z",
  "closed_by": {
    "avatar_url": "https://avatars2.githubusercontent.com/u/669468?v=4",
    "events_url": "https://api.github.com/users/qrpike/events{/privacy}",
    "followers_url": "https://api.github.com/users/qrpike/followers",
    "following_url": "https://api.github.com/users/qrpike/following{/other_user}",
    "gists_url": "https://api.github.com/users/qrpike/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/qrpike",
    "id": 669468,
    "login": "qrpike",
    "node_id": "MDQ6VXNlcjY2OTQ2OA==",
    "organizations_url": "https://api.github.com/users/qrpike/orgs",
    "received_events_url": "https://api.github.com/users/qrpike/received_events",
    "repos_url": "https://api.github.com/users/qrpike/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/qrpike/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/qrpike/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/qrpike"
  },
  "comments": 5,
  "comments_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/57760/comments",
  "created_at": "2018-01-02T19:17:41Z",
  "events_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/57760/events",
  "html_url": "https://github.com/kubernetes/kubernetes/issues/57760",
  "id": 285513517,
  "labels": [
    {
      "color": "e11d21",
      "default": false,
      "description": "Categorizes issue or PR as related to a bug.",
      "id": 105146071,
      "name": "kind/bug",
      "node_id": "MDU6TGFiZWwxMDUxNDYwNzE=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/kind/bug"
    },
    {
      "color": "d2b48c",
      "default": false,
      "description": "Categorizes an issue or PR as relevant to SIG Cluster Lifecycle.",
      "id": 173494222,
      "name": "sig/cluster-lifecycle",
      "node_id": "MDU6TGFiZWwxNzM0OTQyMjI=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/sig/cluster-lifecycle"
    },
    {
      "color": "d2b48c",
      "default": false,
      "description": "Categorizes an issue or PR as relevant to SIG Node.",
      "id": 173493665,
      "name": "sig/node",
      "node_id": "MDU6TGFiZWwxNzM0OTM2NjU=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/sig/node"
    }
  ],
  "labels_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/57760/labels{/name}",
  "locked": false,
  "milestone": null,
  "node_id": "MDU6SXNzdWUyODU1MTM1MTc=",
  "number": 57760,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/kubernetes/kubernetes",
  "state": "closed",
  "title": "Kubelet not connecting to docker-shim CRI",
  "updated_at": "2018-01-16T15:20:00Z",
  "url": "https://api.github.com/repos/kubernetes/kubernetes/issues/57760",
  "user": {
    "avatar_url": "https://avatars2.githubusercontent.com/u/669468?v=4",
    "events_url": "https://api.github.com/users/qrpike/events{/privacy}",
    "followers_url": "https://api.github.com/users/qrpike/followers",
    "following_url": "https://api.github.com/users/qrpike/following{/other_user}",
    "gists_url": "https://api.github.com/users/qrpike/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/qrpike",
    "id": 669468,
    "login": "qrpike",
    "node_id": "MDQ6VXNlcjY2OTQ2OA==",
    "organizations_url": "https://api.github.com/users/qrpike/orgs",
    "received_events_url": "https://api.github.com/users/qrpike/received_events",
    "repos_url": "https://api.github.com/users/qrpike/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/qrpike/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/qrpike/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/qrpike"
  }
}