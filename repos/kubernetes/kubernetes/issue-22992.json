{
  "active_lock_reason": null,
  "assignee": null,
  "assignees": [],
  "author_association": "CONTRIBUTOR",
  "body": "fyi @smarterclayton @pweil @pmorie\nWhen using PV/PVC for Persistent Volume volume mounts, if something goes wrong in the builder, a generic error is surfaced in the 'kubectl describe' with the following event error description *unsupported volume type\":\n\n```\nEvents:\n  FirstSeen LastSeen    Count   From            SubobjectPath   Type        Reason      Message\n  --------- --------    -----   ----            -------------   --------    ------      -------\n  14s       14s     1   {default-scheduler }            Normal      Scheduled   Successfully assigned bb-gluster-pod2 to 127.0.0.1\n  14s       14s     1   {kubelet 127.0.0.1}         Warning     FailedMount Unable to mount volumes for pod \"bb-gluster-pod2_default(3ff651a5-eabf-11e5-b3b1-52540092b5fb)\": unsupported volume type\n  14s       14s     1   {kubelet 127.0.0.1}         Warning     FailedSync  Error syncing pod, skipping: unsupported volume type\n```\n\nThis only occurs when using the PV/PVC abstraction and not directly using a volume plugin.  These type of errors are common when using volume plugins for mounts and would be useful for users to have an easy way to identify the errors rather than searching the logs for root cause.\n\nI think there are two issues:\n1.  Why is the original error surfaced from the volume plugins (glusterfs.go, rbd.go, etc...) getting eaten when they return back to the volumes.go?  I can see in the logs that 2 volume types are processed for any pod - the first is the actual underlying type (i.e. kubernetes.io/glusterfs) and this is where the actual real error is surfaced, then immediately after this the 2nd type is processed which is the general  persistent claim type (i.e. kubernetes.io/persistent-claim) and this when the first type error is eaten\n2.  A simple work around would be to simply add a recorder event in the volumes.go when there is a builder failure.  This ensures the error is recorded and displayed as an event for the describer and will handle all like errors from other volume plugin types.\n\nfull modifed function for reference from volumes.go\n\n```\nfunc (kl *Kubelet) newVolumeBuilderFromPlugins(spec *volume.Spec, pod *api.Pod, opts volume.VolumeOptions) (volume.Builder, error) {\n    plugin, err := kl.volumePluginMgr.FindPluginBySpec(spec)\n    if err != nil {\n        return nil, fmt.Errorf(\"can't use volume plugins for %s: %v\", spec.Name(), err)\n    }\n    if plugin == nil {\n        // Not found but not an error\n        return nil, nil\n    }\n    builder, err := plugin.NewBuilder(spec, pod, opts)\n    if err != nil {\n                // Add kubelet recorder event so the real error shows in the 'kubectl describe <pod>' event list\n        ref, errGetRef := api.GetReference(pod)\n        if errGetRef == nil && ref != nil {\n            kl.recorder.Eventf(ref, api.EventTypeWarning, kubecontainer.FailedMountVolume, \"Unable to mount volumes for pod %q: %v\", format.Pod(pod), err)\n            glog.Errorf(\"Unable to mount volumes for pod %q: %v; skipping pod\", format.Pod(pod), err)\n        }\n        return nil, fmt.Errorf(\"failed to instantiate volume plugin for %s: %v\", spec.Name(), err)\n    }\n\n    glog.V(10).Infof(\"Used volume plugin %q to mount %s\", plugin.Name(), spec.Name())\n    return builder, nil\n}\n```\n\nThis will produce a better user experience when trying to see what went wrong - in this example, I am doing glusterfs PV/PVC but am missing end points which you can clearly see now in the events of the describe:\n\n```\nEvents:\n  FirstSeen LastSeen    Count   From            SubobjectPath   Type        Reason      Message\n  --------- --------    -----   ----            -------------   --------    ------      -------\n  12s       12s     1   {default-scheduler }            Normal      Scheduled   Successfully assigned bb-gluster-pod2 to 127.0.0.1\n  12s       12s     1   {kubelet 127.0.0.1}         Warning     FailedMount Unable to mount volumes for pod \"bb-gluster-pod2_default(2b10a2c3-eac7-11e5-ac70-52540092b5fb)\": endpoints \"glusterfs-cluster\" not found\n  12s       12s     1   {kubelet 127.0.0.1}         Warning     FailedMount Unable to mount volumes for pod \"bb-gluster-pod2_default(2b10a2c3-eac7-11e5-ac70-52540092b5fb)\": unsupported volume type\n  12s       12s     1   {kubelet 127.0.0.1}         Warning     FailedSync  Error syncing pod, skipping: unsupported volume type\n```\n\nrbd example: (Missing or Couldn't get secret)\n\n```\nEvents:\n  FirstSeen LastSeen    Count   From            SubobjectPath   Type        Reason      Message\n  --------- --------    -----   ----            -------------   --------    ------      -------\n  12s       12s     1   {default-scheduler }            Normal      Scheduled   Successfully assigned bb-gluster-pod2 to 127.0.0.1\n  12s       12s     1   {kubelet 127.0.0.1}         Warning     FailedMount Unable to mount volumes for pod \"bb-rbd-pod2_default(2b10a2c3-eac7-11e5-ac70-52540092b5fb)\": Couldn't get secret\n  12s       12s     1   {kubelet 127.0.0.1}         Warning     FailedMount Unable to mount volumes for pod \"bb-rbd-pod2_default(2b10a2c3-eac7-11e5-ac70-52540092b5fb)\": unsupported volume type\n  12s       12s     1   {kubelet 127.0.0.1}         Warning     FailedSync  Error syncing pod, skipping: unsupported volume type\n```\n",
  "closed_at": "2016-04-13T21:20:51Z",
  "closed_by": {
    "avatar_url": "https://avatars0.githubusercontent.com/u/647318?v=4",
    "events_url": "https://api.github.com/users/lavalamp/events{/privacy}",
    "followers_url": "https://api.github.com/users/lavalamp/followers",
    "following_url": "https://api.github.com/users/lavalamp/following{/other_user}",
    "gists_url": "https://api.github.com/users/lavalamp/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/lavalamp",
    "id": 647318,
    "login": "lavalamp",
    "node_id": "MDQ6VXNlcjY0NzMxOA==",
    "organizations_url": "https://api.github.com/users/lavalamp/orgs",
    "received_events_url": "https://api.github.com/users/lavalamp/received_events",
    "repos_url": "https://api.github.com/users/lavalamp/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/lavalamp/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/lavalamp/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/lavalamp"
  },
  "comments": 4,
  "comments_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/22992/comments",
  "created_at": "2016-03-15T16:22:33Z",
  "events_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/22992/events",
  "html_url": "https://github.com/kubernetes/kubernetes/issues/22992",
  "id": 141025641,
  "labels": [],
  "labels_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/22992/labels{/name}",
  "locked": false,
  "milestone": null,
  "node_id": "MDU6SXNzdWUxNDEwMjU2NDE=",
  "number": 22992,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/kubernetes/kubernetes",
  "state": "closed",
  "title": "UXP: kubelet volume mount errors are not surfacing properly for true root cause in 'kubectl describe' leading to confusing generic error message on failed mounts",
  "updated_at": "2016-04-13T21:20:51Z",
  "url": "https://api.github.com/repos/kubernetes/kubernetes/issues/22992",
  "user": {
    "avatar_url": "https://avatars2.githubusercontent.com/u/6773375?v=4",
    "events_url": "https://api.github.com/users/screeley44/events{/privacy}",
    "followers_url": "https://api.github.com/users/screeley44/followers",
    "following_url": "https://api.github.com/users/screeley44/following{/other_user}",
    "gists_url": "https://api.github.com/users/screeley44/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/screeley44",
    "id": 6773375,
    "login": "screeley44",
    "node_id": "MDQ6VXNlcjY3NzMzNzU=",
    "organizations_url": "https://api.github.com/users/screeley44/orgs",
    "received_events_url": "https://api.github.com/users/screeley44/received_events",
    "repos_url": "https://api.github.com/users/screeley44/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/screeley44/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/screeley44/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/screeley44"
  }
}