{
  "active_lock_reason": null,
  "assignee": {
    "avatar_url": "https://avatars1.githubusercontent.com/u/5331316?v=4",
    "events_url": "https://api.github.com/users/tnqn/events{/privacy}",
    "followers_url": "https://api.github.com/users/tnqn/followers",
    "following_url": "https://api.github.com/users/tnqn/following{/other_user}",
    "gists_url": "https://api.github.com/users/tnqn/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/tnqn",
    "id": 5331316,
    "login": "tnqn",
    "node_id": "MDQ6VXNlcjUzMzEzMTY=",
    "organizations_url": "https://api.github.com/users/tnqn/orgs",
    "received_events_url": "https://api.github.com/users/tnqn/received_events",
    "repos_url": "https://api.github.com/users/tnqn/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/tnqn/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/tnqn/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/tnqn"
  },
  "assignees": [
    {
      "avatar_url": "https://avatars1.githubusercontent.com/u/5331316?v=4",
      "events_url": "https://api.github.com/users/tnqn/events{/privacy}",
      "followers_url": "https://api.github.com/users/tnqn/followers",
      "following_url": "https://api.github.com/users/tnqn/following{/other_user}",
      "gists_url": "https://api.github.com/users/tnqn/gists{/gist_id}",
      "gravatar_id": "",
      "html_url": "https://github.com/tnqn",
      "id": 5331316,
      "login": "tnqn",
      "node_id": "MDQ6VXNlcjUzMzEzMTY=",
      "organizations_url": "https://api.github.com/users/tnqn/orgs",
      "received_events_url": "https://api.github.com/users/tnqn/received_events",
      "repos_url": "https://api.github.com/users/tnqn/repos",
      "site_admin": false,
      "starred_url": "https://api.github.com/users/tnqn/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/tnqn/subscriptions",
      "type": "User",
      "url": "https://api.github.com/users/tnqn"
    }
  ],
  "author_association": "MEMBER",
  "body": "<!-- Please use this template while reporting a bug and provide as much info as possible. Not doing so may result in your bug not being addressed in a timely manner. Thanks!\r\n\r\nIf the matter is security related, please disclose it privately via https://kubernetes.io/security/\r\n-->\r\n\r\n\r\n**What happened**:\r\nFor a Pod with `RestartPolicyOnFailure`, kubelet would attempt to create a new sandbox for it even after all container succeeded. Logs as below:\r\n```\r\n# Created the first sandbox and a container\r\nJun 29 10:11:16 k8s-02 kubelet[28625]: I0629 10:11:16.521118   28625 kubelet.go:1907] SyncLoop (ADD, \"api\"): \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\"\r\nJun 29 10:11:16 k8s-02 kubelet[28625]: I0629 10:11:16.549173   28625 kubelet.go:1920] SyncLoop (RECONCILE, \"api\"): \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\"\r\nJun 29 10:11:16 k8s-02 kubelet[28625]: I0629 10:11:16.847022   28625 kuberuntime_manager.go:478] Syncing Pod \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\": &Pod{ObjectMeta:{testpod  default /api/v1/namespaces/default/pods/testpod a724c60f-4f8e-4f16-acd3-d47ff56bd650 3841748 0 2020-06-29 10:11:09 -0700 PDT <nil> <nil> map[] map[kubectl.kubernetes.io/last-applied-configuration:{\"apiVersion\":\"v1\",\"kind\":\"Pod\",\"metadata\":{\"annotations\":{},\"name\":\"testpod\",\"namespace\":\"default\"},\"spec\":{\"containers\":[{\"args\":[\"/bin/sh\",\"-c\",\"echo hello\"],\"image\":\"busybox\",\"name\":\"test\"}],\"restartPolicy\":\"OnFailure\"}}\r\nJun 29 10:11:16 k8s-02 kubelet[28625]: I0629 10:11:16.847281   28625 kuberuntime_manager.go:422] No sandbox for pod \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\" can be found. Need to start a new one\r\nJun 29 10:11:16 k8s-02 kubelet[28625]: I0629 10:11:16.847294   28625 kuberuntime_manager.go:650] computePodActions got {KillPod:true CreateSandbox:true SandboxID: Attempt:0 NextInitContainerToStart:nil ContainersToStart:[0] ContainersToKill:map[] EphemeralContainersToStart:[]} for pod \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\"\r\nJun 29 10:11:16 k8s-02 kubelet[28625]: I0629 10:11:16.847336   28625 kuberuntime_manager.go:659] SyncPod received new pod \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\", will create a sandbox for it\r\nJun 29 10:11:16 k8s-02 kubelet[28625]: I0629 10:11:16.847345   28625 kuberuntime_manager.go:666] Stopping PodSandbox for \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\", will start new one\r\nJun 29 10:11:16 k8s-02 kubelet[28625]: I0629 10:11:16.847370   28625 kuberuntime_manager.go:721] Creating sandbox for pod \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\"\r\nJun 29 10:11:17 k8s-02 kubelet[28625]: I0629 10:11:17.061043   28625 kuberuntime_manager.go:735] Created PodSandbox \"5b006c9a8056ddcfc702f2ccd279741c830bce525b1097ceb22d71dc9090098a\" for pod \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\"\r\nJun 29 10:11:17 k8s-02 kubelet[28625]: I0629 10:11:17.061425   28625 kuberuntime_manager.go:754] Determined the ip [172.30.1.150] for pod \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\" after sandbox changed\r\nJun 29 10:11:17 k8s-02 kubelet[28625]: I0629 10:11:17.061526   28625 kuberuntime_manager.go:791] Creating container &Container{Name:test,Image:busybox,Command:[],Args:[/bin/sh -c echo hello],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-24hfm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:Always,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,} in pod testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\r\n\r\n# The container ran to completion and succeeded, stopping sandbox because all containers are done.\r\nJun 29 10:11:19 k8s-02 kubelet[28625]: I0629 10:11:19.164329   28625 kubelet.go:1952] SyncLoop (PLEG): \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\", event: &pleg.PodLifecycleEvent{ID:\"a724c60f-4f8e-4f16-acd3-d47ff56bd650\", Type:\"ContainerDied\", Data:\"84aba5078b5bfd61b95d01fb65bb98451317c159a8b23efa820eb9d1cc5b323a\"}\r\nJun 29 10:11:19 k8s-02 kubelet[28625]: I0629 10:11:19.164367   28625 kubelet_pods.go:1355] Generating status for \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\"\r\nJun 29 10:11:19 k8s-02 kubelet[28625]: I0629 10:11:19.164467   28625 helpers.go:91] Already successfully ran container \"test\" of pod \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\", do nothing\r\nJun 29 10:11:19 k8s-02 kubelet[28625]: I0629 10:11:19.164555   28625 kubelet_pods.go:1355] Generating status for \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\"\r\nJun 29 10:11:19 k8s-02 kubelet[28625]: I0629 10:11:19.164674   28625 helpers.go:91] Already successfully ran container \"test\" of pod \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\", do nothing\r\nJun 29 10:11:19 k8s-02 kubelet[28625]: I0629 10:11:19.164913   28625 kuberuntime_manager.go:478] Syncing Pod \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\": &Pod{ObjectMeta:{testpod  default /api/v1/namespaces/default/pods/testpod a724c60f-4f8e-4f16-acd3-d47ff56bd650 3841748 0 2020-06-29 10:11:09 -0700 PDT <nil> <nil> map[] map[kubectl.kubernetes.io/last-applied-configuration:{\"apiVersion\":\"v1\",\"kind\":\"Pod\",\"metadata\":{\"annotations\":{},\"name\":\"testpod\",\"namespace\":\"default\"},\"spec\":{\"containers\":[{\"args\":[\"/bin/sh\",\"-c\",\"echo hello\"],\"image\":\"busybox\",\"name\":\"test\"}],\"restartPolicy\":\"OnFailure\"}}\r\nJun 29 10:11:19 k8s-02 kubelet[28625]: I0629 10:11:19.165263   28625 helpers.go:91] Already successfully ran container \"test\" of pod \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\", do nothing\r\nJun 29 10:11:19 k8s-02 kubelet[28625]: I0629 10:11:19.165323   28625 kuberuntime_manager.go:650] computePodActions got {KillPod:true CreateSandbox:false SandboxID:5b006c9a8056ddcfc702f2ccd279741c830bce525b1097ceb22d71dc9090098a Attempt:0 NextInitContainerToStart:nil ContainersToStart:[] ContainersToKill:map[] EphemeralContainersToStart:[]} for pod \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\"\r\nJun 29 10:11:19 k8s-02 kubelet[28625]: I0629 10:11:19.165393   28625 kuberuntime_manager.go:668] Stopping PodSandbox for \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\" because all other containers are dead.\r\n\r\n# Received ContainerDied event of the sandbox, but it then created a new sandbox even there's no container to start \r\nJun 29 10:11:20 k8s-02 kubelet[28625]: I0629 10:11:20.166430   28625 kubelet.go:1952] SyncLoop (PLEG): \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\", event: &pleg.PodLifecycleEvent{ID:\"a724c60f-4f8e-4f16-acd3-d47ff56bd650\", Type:\"ContainerDied\", Data:\"5b006c9a8056ddcfc702f2ccd279741c830bce525b1097ceb22d71dc9090098a\"}\r\nJun 29 10:11:20 k8s-02 kubelet[28625]: I0629 10:11:20.166560   28625 kubelet.go:2016] Pod \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\" has completed, ignoring remaining sync work: sync\r\nJun 29 10:11:20 k8s-02 kubelet[28625]: I0629 10:11:20.166657   28625 kubelet_pods.go:1355] Generating status for \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\"\r\nJun 29 10:11:20 k8s-02 kubelet[28625]: I0629 10:11:20.166757   28625 helpers.go:91] Already successfully ran container \"test\" of pod \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\", do nothing\r\nJun 29 10:11:20 k8s-02 kubelet[28625]: I0629 10:11:20.166542   28625 kubelet_pods.go:1355] Generating status for \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\"\r\nJun 29 10:11:20 k8s-02 kubelet[28625]: I0629 10:11:20.167049   28625 helpers.go:91] Already successfully ran container \"test\" of pod \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\", do nothing\r\nJun 29 10:11:20 k8s-02 kubelet[28625]: I0629 10:11:20.167799   28625 kuberuntime_manager.go:440] No ready sandbox for pod \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\" can be found. Need to start a new one\r\nJun 29 10:11:20 k8s-02 kubelet[28625]: I0629 10:11:20.167896   28625 kuberuntime_manager.go:650] computePodActions got {KillPod:true CreateSandbox:true SandboxID:5b006c9a8056ddcfc702f2ccd279741c830bce525b1097ceb22d71dc9090098a Attempt:1 NextInitContainerToStart:nil ContainersToStart:[] ContainersToKill:map[] EphemeralContainersToStart:[]} for pod \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\"\r\nJun 29 10:11:20 k8s-02 kubelet[28625]: I0629 10:11:20.168010   28625 kuberuntime_manager.go:666] Stopping PodSandbox for \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\", will start new one\r\nJun 29 10:11:20 k8s-02 kubelet[28625]: I0629 10:11:20.231935   28625 kuberuntime_manager.go:721] Creating sandbox for pod \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\"\r\nJun 29 10:11:20 k8s-02 kubelet[28625]: I0629 10:11:20.539335   28625 kuberuntime_manager.go:735] Created PodSandbox \"7b46fbe3c3db623f1e211eba6bf25ace2f53ac083900befdac6c3121bb569a19\" for pod \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\"\r\nJun 29 10:11:20 k8s-02 kubelet[28625]: I0629 10:11:20.539683   28625 kuberuntime_manager.go:754] Determined the ip [172.30.1.151] for pod \"testpod_default(a724c60f-4f8e-4f16-acd3-d47ff56bd650)\" after sandbox changed\r\nJun 29 10:11:20 k8s-02 kubelet[28625]: I0629 10:11:20.843953   28625 kubelet_pods.go:1117] Killing unwanted pod \"testpod\"\r\n```\r\n\r\nThis issue is similar to https://github.com/kubernetes/kubernetes/pull/68980 which fixed the case of pods whose RestartPolicy are Never.\r\n\r\nIt caused unnecessary CRI and CNI calls, confusing logs and conflicts between the routine that creates the new sandbox and the routine that kills the Pod.\r\nIt's likely also the root cause of https://github.com/kubernetes/kubernetes/issues/72044 because sometimes the routine that creates the second sandbox and the routine that kills unwanted pod run concurrently, then the netns would be gone when calling CNI.\r\n\r\n**What you expected to happen**:\r\nkubelet shouldn't create a new sandbox for pod with RestartPolicyOnFailure if all containers succeeded\r\n\r\n**How to reproduce it (as minimally and precisely as possible)**:\r\nCreate a pod like this:\r\n```\r\napiVersion: v1\r\nkind: Pod\r\nmetadata:\r\n  name: testpod\r\nspec:\r\n  restartPolicy: OnFailure\r\n  containers:\r\n  - name: test\r\n    image: busybox\r\n    args:\r\n    - /bin/sh\r\n    - -c\r\n    - echo hello\r\n```\r\n\r\n**Anything else we need to know?**:\r\n\r\n**Environment**:\r\n- Kubernetes version (use `kubectl version`): v1.18.2\r\n- Cloud provider or hardware configuration:\r\n- OS (e.g: `cat /etc/os-release`):\r\n- Kernel (e.g. `uname -a`):\r\n- Install tools:\r\n- Network plugin and version (if this is a network-related bug):\r\n- Others:\r\n",
  "closed_at": "2020-09-03T21:57:41Z",
  "closed_by": {
    "avatar_url": "https://avatars0.githubusercontent.com/u/20407524?v=4",
    "events_url": "https://api.github.com/users/k8s-ci-robot/events{/privacy}",
    "followers_url": "https://api.github.com/users/k8s-ci-robot/followers",
    "following_url": "https://api.github.com/users/k8s-ci-robot/following{/other_user}",
    "gists_url": "https://api.github.com/users/k8s-ci-robot/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/k8s-ci-robot",
    "id": 20407524,
    "login": "k8s-ci-robot",
    "node_id": "MDQ6VXNlcjIwNDA3NTI0",
    "organizations_url": "https://api.github.com/users/k8s-ci-robot/orgs",
    "received_events_url": "https://api.github.com/users/k8s-ci-robot/received_events",
    "repos_url": "https://api.github.com/users/k8s-ci-robot/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/k8s-ci-robot/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/k8s-ci-robot/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/k8s-ci-robot"
  },
  "comments": 3,
  "comments_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/92613/comments",
  "created_at": "2020-06-29T18:14:19Z",
  "events_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/92613/events",
  "html_url": "https://github.com/kubernetes/kubernetes/issues/92613",
  "id": 647570690,
  "labels": [
    {
      "color": "e11d21",
      "default": false,
      "description": "Categorizes issue or PR as related to a bug.",
      "id": 105146071,
      "name": "kind/bug",
      "node_id": "MDU6TGFiZWwxMDUxNDYwNzE=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/kind/bug"
    },
    {
      "color": "d2b48c",
      "default": false,
      "description": "Categorizes an issue or PR as relevant to SIG Node.",
      "id": 173493665,
      "name": "sig/node",
      "node_id": "MDU6TGFiZWwxNzM0OTM2NjU=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/sig/node"
    }
  ],
  "labels_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/92613/labels{/name}",
  "locked": false,
  "milestone": null,
  "node_id": "MDU6SXNzdWU2NDc1NzA2OTA=",
  "number": 92613,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/kubernetes/kubernetes",
  "state": "closed",
  "title": "kubelet always creates sandbox twice for Pods with RestartPolicyOnFailure ",
  "updated_at": "2020-09-03T21:57:41Z",
  "url": "https://api.github.com/repos/kubernetes/kubernetes/issues/92613",
  "user": {
    "avatar_url": "https://avatars1.githubusercontent.com/u/5331316?v=4",
    "events_url": "https://api.github.com/users/tnqn/events{/privacy}",
    "followers_url": "https://api.github.com/users/tnqn/followers",
    "following_url": "https://api.github.com/users/tnqn/following{/other_user}",
    "gists_url": "https://api.github.com/users/tnqn/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/tnqn",
    "id": 5331316,
    "login": "tnqn",
    "node_id": "MDQ6VXNlcjUzMzEzMTY=",
    "organizations_url": "https://api.github.com/users/tnqn/orgs",
    "received_events_url": "https://api.github.com/users/tnqn/received_events",
    "repos_url": "https://api.github.com/users/tnqn/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/tnqn/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/tnqn/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/tnqn"
  }
}