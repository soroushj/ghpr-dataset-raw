{
  "active_lock_reason": null,
  "assignee": null,
  "assignees": [],
  "author_association": "NONE",
  "body": "In our k8s cluster, a node's status is NotReady, and we checked the kubelet's log, that repeated \"skipping pod synchronization\" every 5 minutes:\r\n\r\n```\r\nMay 10 16:20:07 localhost kubelet: I0510 16:20:07.315290   20965 kubelet.go:2237] skipping pod synchronization - [Kubelet failed to get node info.] \r\nMay 10 16:20:12 localhost kubelet: I0510 16:20:12.317233   20965 kubelet.go:2237] skipping pod synchronization - [Kubelet failed to get node info.] \r\nMay 10 16:20:17 localhost kubelet: I0510 16:20:17.317374   20965 kubelet.go:2237] skipping pod synchronization - [Kubelet failed to get node info.] \r\n```\r\n```\r\nfunc (kl *Kubelet) syncLoop(updates <-chan kubetypes.PodUpdate, handler SyncHandler) {\r\n\tglog.Info(\"Starting kubelet main sync loop.\")\r\n\t// The resyncTicker wakes up kubelet to checks if there are any pod workers\r\n\t// that need to be sync'd. A one-second period is sufficient because the\r\n\t// sync interval is defaulted to 10s.\r\n\tsyncTicker := time.NewTicker(time.Second)\r\n\tdefer syncTicker.Stop()\r\n\thousekeepingTicker := time.NewTicker(housekeepingPeriod)\r\n\tdefer housekeepingTicker.Stop()\r\n\tplegCh := kl.pleg.Watch()\r\n\tfor {\r\n\t\tif rs := kl.runtimeState.errors(); len(rs) != 0 {\r\n\t\t\tglog.Infof(\"skipping pod synchronization - %v\", rs)\r\n\t\t\ttime.Sleep(5 * time.Second)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif !kl.syncLoopIteration(updates, handler, syncTicker.C, housekeepingTicker.C, plegCh) {\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n}\r\n```\r\nI found the code where printing those logs, in the syscLoop function. if runtimeState has error, kubelet will get into endless loop, and will print \"skipping pod synchronization\" every five minutes.\r\n\r\nIn our case, the node got an error when startup, in the function initializeModules, which called our cloud provider to get node info, because the call returned an error, kubelet set the error to runtimeState, and ran syscLoop next, going to endless loop.\r\n```\r\nif err := kl.initializeModules(); err != nil {\r\n\t\tkl.recorder.Eventf(kl.nodeRef, api.EventTypeWarning, events.KubeletSetupFailed, err.Error())\r\n\t\tglog.Error(err)\r\n\t\tkl.runtimeState.setInitError(err)\r\n\t}\r\n```\r\n\r\nI think there is a problem here:\r\nStartup function \"initializeModules\" encountered an error like \"failed get node info\", which is rarely, kubelet should exit its process and it will be restarted by systemd successfully.\r\nRestarting kubelet is more reaonable than printing error log in the endless loop, Restarting event can be mornitored easily, but the admin can hardly detect the endless loop.\r\n",
  "closed_at": "2018-01-30T22:56:29Z",
  "closed_by": {
    "avatar_url": "https://avatars0.githubusercontent.com/u/13653959?v=4",
    "events_url": "https://api.github.com/users/k8s-github-robot/events{/privacy}",
    "followers_url": "https://api.github.com/users/k8s-github-robot/followers",
    "following_url": "https://api.github.com/users/k8s-github-robot/following{/other_user}",
    "gists_url": "https://api.github.com/users/k8s-github-robot/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/k8s-github-robot",
    "id": 13653959,
    "login": "k8s-github-robot",
    "node_id": "MDQ6VXNlcjEzNjUzOTU5",
    "organizations_url": "https://api.github.com/users/k8s-github-robot/orgs",
    "received_events_url": "https://api.github.com/users/k8s-github-robot/received_events",
    "repos_url": "https://api.github.com/users/k8s-github-robot/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/k8s-github-robot/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/k8s-github-robot/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/k8s-github-robot"
  },
  "comments": 4,
  "comments_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/46086/comments",
  "created_at": "2017-05-19T08:59:57Z",
  "events_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/46086/events",
  "html_url": "https://github.com/kubernetes/kubernetes/issues/46086",
  "id": 229912747,
  "labels": [
    {
      "color": "d2b48c",
      "default": false,
      "description": "Categorizes an issue or PR as relevant to SIG Node.",
      "id": 173493665,
      "name": "sig/node",
      "node_id": "MDU6TGFiZWwxNzM0OTM2NjU=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/sig/node"
    }
  ],
  "labels_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/46086/labels{/name}",
  "locked": false,
  "milestone": null,
  "node_id": "MDU6SXNzdWUyMjk5MTI3NDc=",
  "number": 46086,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/kubernetes/kubernetes",
  "state": "closed",
  "title": "kubelet gets in an endless loop when initializeModules failed",
  "updated_at": "2018-01-30T22:56:29Z",
  "url": "https://api.github.com/repos/kubernetes/kubernetes/issues/46086",
  "user": {
    "avatar_url": "https://avatars3.githubusercontent.com/u/10137?v=4",
    "events_url": "https://api.github.com/users/ghost/events{/privacy}",
    "followers_url": "https://api.github.com/users/ghost/followers",
    "following_url": "https://api.github.com/users/ghost/following{/other_user}",
    "gists_url": "https://api.github.com/users/ghost/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/ghost",
    "id": 10137,
    "login": "ghost",
    "node_id": "MDQ6VXNlcjEwMTM3",
    "organizations_url": "https://api.github.com/users/ghost/orgs",
    "received_events_url": "https://api.github.com/users/ghost/received_events",
    "repos_url": "https://api.github.com/users/ghost/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/ghost/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/ghost/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/ghost"
  }
}