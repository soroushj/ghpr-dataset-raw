{
  "active_lock_reason": null,
  "assignee": null,
  "assignees": [],
  "author_association": "CONTRIBUTOR",
  "body": "/kind bug\r\n\r\n**What happened**: I was testing HPA before 1.12 release. My test created replication controller with 10 pods, each using 40% CPU and HPA targeting 60% CPU utilization. First scale was random. On different runs the first scale was to 1, 4, 7 pods.\r\n\r\nI expect the same problem will surface if HPA scales up and then gets restarted.\r\n\r\n**What you expected to happen**: Stabilizing at 10 pods.\r\n\r\n**How to reproduce it (as minimally and precisely as possible)**:\r\n- Create deployment with 10 pods, each utilizing 40% CPU, requesting 1 CPU.\r\n- Create HPA with target 60% CPU, min size = 1, max size = 10.\r\n- Observe first scale, repeat a few times.\r\n\r\n**Anything else we need to know?**: \r\n\r\nI think I know cause and have a fix. Initially HPA doesn't make any resizes because it considers pods unready. The problems start when pods start becoming ready. For example if only 1 pod becomes ready HPA will see it as pods using 400 millicores, with 60% CPU utilization target this means recommended size 1.\r\n\r\nIn most cases this is not a problem because scale down stabilization window will prevent HPA from scaling down. However if HPA doesn't have recommendation history (in my test because it was just created, in the wild because controller manager restart) it will act upon the recommendation and scale down.\r\n\r\nThis is somewhat random because it depends how many pods exactly crossed threshold for being concerned ready when HPA calculates the recommendation.\r\n\r\nThe way to fix it is to record initial size as recommendation made (by the one creating deployment or by previous execution of HPA) at  the time HPA first calculates a recommendation for the deployment and stabilize on it just like on any other recommendation.\r\n\r\n**Environment**:\r\n- Kubernetes version (use `kubectl version`): Server Version: version.Info{Major:\"1\", Minor:\"12+\", GitVersion:\"v1.12.0-beta.2.35+e231c3ca1f15fe\", GitCommit:\"e231c3ca1f15fe96f8b73201160e25fc5968f63d\", GitTreeState:\"clean\", BuildDate:\"2018-09-14T10:48:57Z\", GoVersion:\"go1.10.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\r\n- Cloud provider or hardware configuration: GCE\r\n- OS (e.g. from /etc/os-release):\r\n- Kernel (e.g. `uname -a`):\r\n- Install tools:\r\n- Others:\r\n",
  "closed_at": "2018-09-19T16:48:01Z",
  "closed_by": {
    "avatar_url": "https://avatars0.githubusercontent.com/u/20407524?v=4",
    "events_url": "https://api.github.com/users/k8s-ci-robot/events{/privacy}",
    "followers_url": "https://api.github.com/users/k8s-ci-robot/followers",
    "following_url": "https://api.github.com/users/k8s-ci-robot/following{/other_user}",
    "gists_url": "https://api.github.com/users/k8s-ci-robot/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/k8s-ci-robot",
    "id": 20407524,
    "login": "k8s-ci-robot",
    "node_id": "MDQ6VXNlcjIwNDA3NTI0",
    "organizations_url": "https://api.github.com/users/k8s-ci-robot/orgs",
    "received_events_url": "https://api.github.com/users/k8s-ci-robot/received_events",
    "repos_url": "https://api.github.com/users/k8s-ci-robot/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/k8s-ci-robot/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/k8s-ci-robot/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/k8s-ci-robot"
  },
  "comments": 2,
  "comments_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/68826/comments",
  "created_at": "2018-09-19T11:36:53Z",
  "events_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/68826/events",
  "html_url": "https://github.com/kubernetes/kubernetes/issues/68826",
  "id": 361705748,
  "labels": [
    {
      "color": "e11d21",
      "default": false,
      "description": "Categorizes issue or PR as related to a bug.",
      "id": 105146071,
      "name": "kind/bug",
      "node_id": "MDU6TGFiZWwxMDUxNDYwNzE=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/kind/bug"
    },
    {
      "color": "d2b48c",
      "default": false,
      "description": "Categorizes an issue or PR as relevant to SIG Autoscaling.",
      "id": 238245616,
      "name": "sig/autoscaling",
      "node_id": "MDU6TGFiZWwyMzgyNDU2MTY=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/sig/autoscaling"
    }
  ],
  "labels_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/68826/labels{/name}",
  "locked": false,
  "milestone": null,
  "node_id": "MDU6SXNzdWUzNjE3MDU3NDg=",
  "number": 68826,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/kubernetes/kubernetes",
  "state": "closed",
  "title": "Creating or restarting HPA close to pod creation creates race in the first decision it makes",
  "updated_at": "2018-09-19T16:48:01Z",
  "url": "https://api.github.com/repos/kubernetes/kubernetes/issues/68826",
  "user": {
    "avatar_url": "https://avatars3.githubusercontent.com/u/277062?v=4",
    "events_url": "https://api.github.com/users/jbartosik/events{/privacy}",
    "followers_url": "https://api.github.com/users/jbartosik/followers",
    "following_url": "https://api.github.com/users/jbartosik/following{/other_user}",
    "gists_url": "https://api.github.com/users/jbartosik/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/jbartosik",
    "id": 277062,
    "login": "jbartosik",
    "node_id": "MDQ6VXNlcjI3NzA2Mg==",
    "organizations_url": "https://api.github.com/users/jbartosik/orgs",
    "received_events_url": "https://api.github.com/users/jbartosik/received_events",
    "repos_url": "https://api.github.com/users/jbartosik/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/jbartosik/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/jbartosik/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/jbartosik"
  }
}