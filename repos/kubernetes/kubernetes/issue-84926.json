{
  "active_lock_reason": null,
  "assignee": null,
  "assignees": [],
  "author_association": "NONE",
  "body": "**What happened**:\r\n\r\nWe were running a service with LoadBalancer type with AWS cloud provider and after deleting this service, the cleanup process on AWS removed a wrong ingress input rule which provoked that all traffic between nodes was unable to reach out the destination.\r\n\r\nThe service we were running had a configuration similar to:\r\n\r\n```\r\napiVersion: v1\r\nkind: Service\r\nmetadata:\r\n  annotations:\r\n    service.beta.kubernetes.io/aws-load-balancer-additional-resource-tags: Key=Value\r\n    service.beta.kubernetes.io/aws-load-balancer-extra-security-groups: sg-123456\r\n  name: test-service\r\n  namespace: test\r\nspec:\r\n  loadBalancerSourceRanges:\r\n  - 10.0.0.0/8\r\n  ports:\r\n  - name: port-name\r\n    port: 10000\r\n    protocol: TCP\r\n    targetPort: 10000\r\n  selector:\r\n    label: \"true\"\r\n  sessionAffinity: None\r\n  type: LoadBalancer\r\n```\r\n\r\nAfter applying this manfiest on the cluster, the cloud provider created the associated load balancer with two security groups:\r\n- sg-123456 (due to extra security group annotation)\r\n- sg-abcdef (a new SG created by the AWS cloud provider with the rules defined on the `loadBalancerSourceRanges`)\r\n\r\nCloud provider also created a new input rule on the *nodes security group* which allows all traffic from all ports from `sg-abcdef` (which is the sg created for the newly created load balancer in our example).\r\n\r\nOne particularity of our setup is that the security group we added as `service.beta.kubernetes.io/aws-load-balancer-extra-security-groups` was the *nodes security group*. The input rules of this security group after the creation of this service was similar to:\r\n\r\n```\r\nType            Protocol        Port Range        Source        Description\r\nAll traffic     All             All               sg-abcdef     LB security group\r\nAll traffic     All             All               sg-123456     Nodes security group\r\n```\r\n\r\nEverything worked fine with this setup until we deleted this service and the cloud provider started the deletion process of the LoadBalancer on AWS. We've been debugging the deletion code and we found that the first thing it does is cleaning up the security group. To do it, it first removes the input rule from the nodes security group which allows traffic from the load balancer security group (sg-abcdef, on this example) and then, as it's not referenced, it removes the security group.\r\nThe expected output of this process, would be that *nodes security groups* would be:\r\n\r\n```\r\nType            Protocol        Port Range        Source        Description\r\nAll traffic     All             All               sg-123456     Nodes security group\r\n```\r\n\r\nBut, in our case, it ended up as:\r\n\r\n```\r\nType            Protocol        Port Range        Source        Description\r\nAll traffic     All             All               sg-abcdef     LB security group\r\n```\r\n\r\nwhich dropped all the traffic between nodes (as it didn't allow any traffic between them).\r\n\r\nThe cleanup process didn't properly remove the input rule from the *node security group* (the one which allows all traffic from source sg-abcdef) and it also did not remove the sg-abcdef security group.\r\nIn our case, as we were using the *nodes security group* on the extra security groups, this bug provoked a network partition between nodes, but we think that if `service.beta.kubernetes.io/aws-load-balancer-extra-security-groups` is used, the cleanup process may be broken and have unexpected side-effects like those we observed.\r\n\r\nWe've been debugging and we found that the process which removes the input rule from the nodes security groups starts here: https://github.com/kubernetes/kubernetes/blob/release-1.11/pkg/cloudprovider/providers/aws/aws.go#L4021\r\n\r\nThe first thing this function does is this: https://github.com/kubernetes/kubernetes/blob/release-1.11/pkg/cloudprovider/providers/aws/aws.go#L3737-L3748 :\r\n\r\nWhen extra security groups are used, `elb.LoadBalancerDescription.SecurityGroups` will contain the security group created for the LoadBalancer and all the extra security groups. We also found that AWS returns this SecurityGroups list in distinct orders after changing the LoadBalancer configuration. That code is always assuming that latest security group on the list is the `loadBalancerSecurityGroupID`, which may not be true when extra security groups are used.\r\nOn the cases where the load balancer security group is not returned on the latest position, the cleanup process does not remove the security group and the input rule from the *nodes security group* is not removed as expected.\r\n\r\nWe've seen that master branch still contains this code and we think this may be hapenning on newer versions: https://github.com/kubernetes/kubernetes/blob/1c974109b672ade9aae86f2daf1d50c89c36949f/staging/src/k8s.io/legacy-cloud-providers/aws/aws.go#L4092-L4101), so we think that newer versions may be affected by this bug (we didn't try it).\r\n\r\nIn our case, we saw several times this log during the removal process: https://github.com/kubernetes/kubernetes/blob/release-1.11/pkg/cloudprovider/providers/aws/aws.go#L3745\r\n\r\nAdditionally, the code tried to remove the security group (but being unable to do so), after wrongly revoking the rule we have talked about before.\r\n\r\n**What you expected to happen**:\r\n\r\nThe cleanup process should properly detect the load balancer security group, remove the input rule from nodes security group and remove the load balancer security group, regardless of the order in which AWS returns the security group list on `elb.LoadBalancerDescription.SecurityGroups`.\r\n\r\n**How to reproduce it (as minimally and precisely as possible)**:\r\n\r\nWe did not find any consistent process to create the scenario, as it happens randomly (we are not sure if due to AWS or any kind of race condition on AWS cloud provider).\r\n\r\nSetup:\r\n\r\n- Create a Service with `type: LoadBalancer` running controller manager with AWS cloud provider with tha annotation `service.beta.kubernetes.io/aws-load-balancer-extra-security-groups` containing one or more security groups (as the one the `What happened` section)\r\n- Wait until load balancer is created\r\n- Run `aws elb describe-load-balancers --load-balancer-names <balancer_name>`\r\n- Check if `SecurityGroups` does not have the newly created security group for the balancer in the *latest* position.\r\n- Repeat until the balancer does not have the balancer security group on the latest position\r\n\r\nTrigger the bug:\r\n\r\n- `kubectl delete service <service>`\r\n\r\nResult:\r\n\r\n- The log `Multiple security groups for load balancer` will appear multiple times on controller-manager logs\r\n- Load balancer associated security group *is not* removed\r\n- Nodes security group input rule allowing all traffic from load balancer security group *is not* removed\r\n- If the latest security group on the list was the nodes security group, the input rule allowing all traffic on all ports from all the other nodes is removed and no traffic is allowed between nodes on the cluster.\r\n\r\n\r\n**Environment**:\r\n- Kubernetes version (use `kubectl version`): version.Info{Major:\"1\", Minor:\"11\", GitVersion:\"v1.11.10\", GitCommit:\"7a578febe155a7366767abce40d8a16795a96371\", GitTreeState:\"clean\", BuildDate:\"2019-05-01T04:05:01Z\", GoVersion:\"go1.10.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\r\n- Cloud provider or hardware configuration: aws\r\n- OS (e.g: `cat /etc/os-release`):\r\n```\r\nPRETTY_NAME=\"Debian GNU/Linux 9 (stretch)\"\r\nNAME=\"Debian GNU/Linux\"\r\nVERSION_ID=\"9\"\r\nVERSION=\"9 (stretch)\"\r\nID=debian\r\n```\r\n- Kernel (e.g. `uname -a`): Linux ip-10-2-13-67 4.9.0-7-amd64 #1 SMP Debian 4.9.110-3+deb9u2 (2018-08-13) x86_64 GNU/Linux\r\n- Install tools: kops\r\n",
  "closed_at": "2020-06-22T22:02:10Z",
  "closed_by": {
    "avatar_url": "https://avatars0.githubusercontent.com/u/20407524?v=4",
    "events_url": "https://api.github.com/users/k8s-ci-robot/events{/privacy}",
    "followers_url": "https://api.github.com/users/k8s-ci-robot/followers",
    "following_url": "https://api.github.com/users/k8s-ci-robot/following{/other_user}",
    "gists_url": "https://api.github.com/users/k8s-ci-robot/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/k8s-ci-robot",
    "id": 20407524,
    "login": "k8s-ci-robot",
    "node_id": "MDQ6VXNlcjIwNDA3NTI0",
    "organizations_url": "https://api.github.com/users/k8s-ci-robot/orgs",
    "received_events_url": "https://api.github.com/users/k8s-ci-robot/received_events",
    "repos_url": "https://api.github.com/users/k8s-ci-robot/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/k8s-ci-robot/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/k8s-ci-robot/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/k8s-ci-robot"
  },
  "comments": 7,
  "comments_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/84926/comments",
  "created_at": "2019-11-07T14:34:13Z",
  "events_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/84926/events",
  "html_url": "https://github.com/kubernetes/kubernetes/issues/84926",
  "id": 519303862,
  "labels": [
    {
      "color": "0052cc",
      "default": false,
      "description": "Issues or PRs related to aws provider",
      "id": 852130657,
      "name": "area/provider/aws",
      "node_id": "MDU6TGFiZWw4NTIxMzA2NTc=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/area/provider/aws"
    },
    {
      "color": "e11d21",
      "default": false,
      "description": "Categorizes issue or PR as related to a bug.",
      "id": 105146071,
      "name": "kind/bug",
      "node_id": "MDU6TGFiZWwxMDUxNDYwNzE=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/kind/bug"
    },
    {
      "color": "d3e2f0",
      "default": false,
      "description": "Indicates that an issue or PR should not be auto-closed due to staleness.",
      "id": 778118403,
      "name": "lifecycle/frozen",
      "node_id": "MDU6TGFiZWw3NzgxMTg0MDM=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/lifecycle/frozen"
    },
    {
      "color": "d2b48c",
      "default": false,
      "description": "Categorizes an issue or PR as relevant to SIG Cloud Provider.",
      "id": 958178286,
      "name": "sig/cloud-provider",
      "node_id": "MDU6TGFiZWw5NTgxNzgyODY=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/sig/cloud-provider"
    }
  ],
  "labels_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/84926/labels{/name}",
  "locked": false,
  "milestone": null,
  "node_id": "MDU6SXNzdWU1MTkzMDM4NjI=",
  "number": 84926,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/kubernetes/kubernetes",
  "state": "closed",
  "title": "Incorrect security group cleanup after service deletion",
  "updated_at": "2020-06-22T22:02:10Z",
  "url": "https://api.github.com/repos/kubernetes/kubernetes/issues/84926",
  "user": {
    "avatar_url": "https://avatars3.githubusercontent.com/u/4637936?v=4",
    "events_url": "https://api.github.com/users/gnieto/events{/privacy}",
    "followers_url": "https://api.github.com/users/gnieto/followers",
    "following_url": "https://api.github.com/users/gnieto/following{/other_user}",
    "gists_url": "https://api.github.com/users/gnieto/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/gnieto",
    "id": 4637936,
    "login": "gnieto",
    "node_id": "MDQ6VXNlcjQ2Mzc5MzY=",
    "organizations_url": "https://api.github.com/users/gnieto/orgs",
    "received_events_url": "https://api.github.com/users/gnieto/received_events",
    "repos_url": "https://api.github.com/users/gnieto/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/gnieto/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/gnieto/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/gnieto"
  }
}