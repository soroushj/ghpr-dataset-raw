{
  "active_lock_reason": null,
  "assignee": {
    "avatar_url": "https://avatars2.githubusercontent.com/u/7740897?v=4",
    "events_url": "https://api.github.com/users/dchen1107/events{/privacy}",
    "followers_url": "https://api.github.com/users/dchen1107/followers",
    "following_url": "https://api.github.com/users/dchen1107/following{/other_user}",
    "gists_url": "https://api.github.com/users/dchen1107/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/dchen1107",
    "id": 7740897,
    "login": "dchen1107",
    "node_id": "MDQ6VXNlcjc3NDA4OTc=",
    "organizations_url": "https://api.github.com/users/dchen1107/orgs",
    "received_events_url": "https://api.github.com/users/dchen1107/received_events",
    "repos_url": "https://api.github.com/users/dchen1107/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/dchen1107/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/dchen1107/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/dchen1107"
  },
  "assignees": [
    {
      "avatar_url": "https://avatars2.githubusercontent.com/u/7740897?v=4",
      "events_url": "https://api.github.com/users/dchen1107/events{/privacy}",
      "followers_url": "https://api.github.com/users/dchen1107/followers",
      "following_url": "https://api.github.com/users/dchen1107/following{/other_user}",
      "gists_url": "https://api.github.com/users/dchen1107/gists{/gist_id}",
      "gravatar_id": "",
      "html_url": "https://github.com/dchen1107",
      "id": 7740897,
      "login": "dchen1107",
      "node_id": "MDQ6VXNlcjc3NDA4OTc=",
      "organizations_url": "https://api.github.com/users/dchen1107/orgs",
      "received_events_url": "https://api.github.com/users/dchen1107/received_events",
      "repos_url": "https://api.github.com/users/dchen1107/repos",
      "site_admin": false,
      "starred_url": "https://api.github.com/users/dchen1107/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/dchen1107/subscriptions",
      "type": "User",
      "url": "https://api.github.com/users/dchen1107"
    }
  ],
  "author_association": "CONTRIBUTOR",
  "body": "Running kube-up on a clean build of 6afbaf6bf6ac8d1d71307819f21d56d7946c522c, I'm seeing the docker on the master crashing, and kube-apiserver crash with it.\n\nThis is the standard 4-node GCE cluster, I haven't touched any config.\n\n```\nkubernetes\u00b7(6afbaf6...) $ make clean release-skip-tests && kup && kdown\n[...]\nWaiting for cluster initialization.\n\n  This will continually check to see if the API for kubernetes is reachable.\n  This might loop forever if there was some uncaught error during start\n  up.\n\n................................Kubernetes cluster created.\nWrote config for devbox-964_kubernetes to $HOME/.kube/config\n\nKubernetes cluster is running.  The master is running at:\n\n  https://IP\n\nThe user name and password to use is located in $HOME/.kube/config.\n\n... calling validate-cluster\nWaiting for 5 ready nodes. 1 ready nodes, 5 registered. Retrying.\nWaiting for 5 ready nodes. 1 ready nodes, 5 registered. Retrying.\nWaiting for 5 ready nodes. 1 ready nodes, 5 registered. Retrying.\nerror: couldn't read version from server: Get https://IP/api: dial tcp IP:443: connection refused\n```\n\nList of all pods:\n\n```\nkubernetes\u00b7(6afbaf6...) $ k get pods --all-namespaces\nNAMESPACE     NAME                                           READY     STATUS                                                                  RESTARTS   AGE\nkube-system   etcd-server-kubernetes-master                  1/1       Running                                                                 3          16m\nkube-system   fluentd-cloud-logging-kubernetes-master        1/1       Running                                                                 3          16m\nkube-system   fluentd-cloud-logging-kubernetes-minion-5h5s   1/1       Running                                                                 0          15m\nkube-system   fluentd-cloud-logging-kubernetes-minion-e3p1   1/1       Running                                                                 0          15m\nkube-system   fluentd-cloud-logging-kubernetes-minion-k0jp   1/1       Running                                                                 0          15m\nkube-system   fluentd-cloud-logging-kubernetes-minion-ykur   1/1       Running                                                                 0          15m\nkube-system   kube-apiserver-kubernetes-master               1/1       Running                                                                 3          16m\nkube-system   kube-controller-manager-kubernetes-master      1/1       Running                                                                 3          16m\nkube-system   kube-dns-v8-v7svt                              4/4       Running                                                                 0          16m\nkube-system   kube-scheduler-kubernetes-master               1/1       Running                                                                 3          16m\nkube-system   kube-ui-v1-65m9j                               0/1       Image: gcr.io/google_containers/kube-ui:v1.1 is not ready on the node   0          16m\nkube-system   monitoring-heapster-v7-3xn8i                   0/1       InsufficientFreeCPU                                                     0          16m\nkube-system   monitoring-heapster-v7-6h6d2                   0/1       InsufficientFreeCPU                                                     0          16m\nkube-system   monitoring-heapster-v7-79ozz                   0/1       InsufficientFreeCPU                                                     0          16m\nkube-system   monitoring-heapster-v7-8jffe                   0/1       InsufficientFreeCPU                                                     0          16m\nkube-system   monitoring-heapster-v7-95i3o                   0/1       InsufficientFreeCPU                                                     0          16m\nkube-system   monitoring-heapster-v7-aur4k                   0/1       Running                                                                 9          15m\nkube-system   monitoring-heapster-v7-e7wwf                   0/1       InsufficientFreeCPU                                                     0          16m\nkube-system   monitoring-heapster-v7-g1px0                   0/1       InsufficientFreeCPU                                                     0          16m\nkube-system   monitoring-heapster-v7-gbyfh                   0/1       InsufficientFreeCPU                                                     0          16m\nkube-system   monitoring-heapster-v7-mppao                   0/1       InsufficientFreeCPU                                                     0          16m\nkube-system   monitoring-influx-grafana-v1-421pp             0/2       InsufficientFreeCPU                                                     0          16m\nkube-system   monitoring-influx-grafana-v1-qhvpi             2/2       Running                                                                 0          15m\n```\n\nNot sure why so many heapster pods are scheduled.\n\nWatching the status of the apiserver and docker on the master:\n\n```\nuluyol@kubernetes-master:~$ while true; do pgrep kube-apiserver &>/dev/null; kube_up=$?; [[ $(pgrep docker | wc -l) == 2 ]]; docker_up=$?; if [[ $kube_up == 0 ]]; then echo -n apiserver up; else echo -n apiserver down; fi; if [[ $docker_up == 0 ]]; then echo ' docker up'; else echo ' docker down'; fi; sleep 1; done\napiserver down docker down\napiserver down docker down\napiserver down docker down\napiserver down docker down\napiserver down docker down\napiserver down docker down\napiserver down docker down\napiserver down docker up\napiserver down docker down\napiserver up docker up\napiserver up docker up\n[ +35 more ]\napiserver up docker up\napiserver down docker down\napiserver down docker down\napiserver down docker down\n[...]\n```\n\nAfter digging around with @mikedanese on Friday, looks like removing the `kubelet_api_servers` definition in /etc/salt/minion.d/grains.conf fixes this (I followed this by calling `salt-call state.highstate`). I have 25 min of apiserver/docker uptime so far, and the scheduled pods looks more like what it's supposed to\n\n```\nkubernetes\u00b7(6afbaf6...) $ k get pods --all-namespaces\nNAMESPACE     NAME                                           READY     STATUS    RESTARTS   AGE\nkube-system   fluentd-cloud-logging-kubernetes-minion-5h5s   1/1       Running   0          51m\nkube-system   fluentd-cloud-logging-kubernetes-minion-e3p1   1/1       Running   0          51m\nkube-system   fluentd-cloud-logging-kubernetes-minion-k0jp   1/1       Running   0          51m\nkube-system   fluentd-cloud-logging-kubernetes-minion-ykur   1/1       Running   0          51m\nkube-system   kube-dns-v8-v7svt                              4/4       Running   0          52m\nkube-system   kube-ui-v1-kwrq6                               1/1       Running   0          25m\nkube-system   monitoring-heapster-v7-aur4k                   0/1       Running   10         51m\nkube-system   monitoring-influx-grafana-v1-qhvpi             2/2       Running   0          51m\n```\n\nIt seems the 8df33bc1a75ca7e81a07b49c033ae94e04dd66f4 was the commit that changed this. EDIT: For clarification, I mean that this commit is when we started setting kubelet_api_servers on the master.\n",
  "closed_at": "2015-08-18T14:55:38Z",
  "closed_by": {
    "avatar_url": "https://avatars1.githubusercontent.com/u/7751204?v=4",
    "events_url": "https://api.github.com/users/roberthbailey/events{/privacy}",
    "followers_url": "https://api.github.com/users/roberthbailey/followers",
    "following_url": "https://api.github.com/users/roberthbailey/following{/other_user}",
    "gists_url": "https://api.github.com/users/roberthbailey/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/roberthbailey",
    "id": 7751204,
    "login": "roberthbailey",
    "node_id": "MDQ6VXNlcjc3NTEyMDQ=",
    "organizations_url": "https://api.github.com/users/roberthbailey/orgs",
    "received_events_url": "https://api.github.com/users/roberthbailey/received_events",
    "repos_url": "https://api.github.com/users/roberthbailey/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/roberthbailey/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/roberthbailey/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/roberthbailey"
  },
  "comments": 11,
  "comments_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/12776/comments",
  "created_at": "2015-08-17T01:50:14Z",
  "events_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/12776/events",
  "html_url": "https://github.com/kubernetes/kubernetes/issues/12776",
  "id": 101318536,
  "labels": [
    {
      "color": "e11d21",
      "default": false,
      "description": "Highest priority. Must be actively worked on as someone's top priority right now.",
      "id": 114528068,
      "name": "priority/critical-urgent",
      "node_id": "MDU6TGFiZWwxMTQ1MjgwNjg=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/priority/critical-urgent"
    },
    {
      "color": "d2b48c",
      "default": false,
      "description": "Categorizes an issue or PR as relevant to SIG Cluster Lifecycle.",
      "id": 173494222,
      "name": "sig/cluster-lifecycle",
      "node_id": "MDU6TGFiZWwxNzM0OTQyMjI=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/sig/cluster-lifecycle"
    },
    {
      "color": "d2b48c",
      "default": false,
      "description": "Categorizes an issue or PR as relevant to SIG Node.",
      "id": 173493665,
      "name": "sig/node",
      "node_id": "MDU6TGFiZWwxNzM0OTM2NjU=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/sig/node"
    }
  ],
  "labels_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/12776/labels{/name}",
  "locked": false,
  "milestone": null,
  "node_id": "MDU6SXNzdWUxMDEzMTg1MzY=",
  "number": 12776,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/kubernetes/kubernetes",
  "state": "closed",
  "title": "Docker and kube-apiserver crashing on master",
  "updated_at": "2015-08-18T14:55:38Z",
  "url": "https://api.github.com/repos/kubernetes/kubernetes/issues/12776",
  "user": {
    "avatar_url": "https://avatars3.githubusercontent.com/u/4128872?v=4",
    "events_url": "https://api.github.com/users/uluyol/events{/privacy}",
    "followers_url": "https://api.github.com/users/uluyol/followers",
    "following_url": "https://api.github.com/users/uluyol/following{/other_user}",
    "gists_url": "https://api.github.com/users/uluyol/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/uluyol",
    "id": 4128872,
    "login": "uluyol",
    "node_id": "MDQ6VXNlcjQxMjg4NzI=",
    "organizations_url": "https://api.github.com/users/uluyol/orgs",
    "received_events_url": "https://api.github.com/users/uluyol/received_events",
    "repos_url": "https://api.github.com/users/uluyol/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/uluyol/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/uluyol/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/uluyol"
  }
}