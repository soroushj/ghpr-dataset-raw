{
  "active_lock_reason": null,
  "assignee": null,
  "assignees": [],
  "author_association": "MEMBER",
  "body": "<!-- Please use this template while reporting a bug and provide as much info as possible. Not doing so may result in your bug not being addressed in a timely manner. Thanks!\r\n\r\nIf the matter is security related, please disclose it privately via https://kubernetes.io/security/\r\n-->\r\n\r\n\r\n**What happened**:\r\nI checked out the latest `master` branch and tried `hack/local-up-cluster.sh`.  The kube-proxy gave up on trying to lookup the node, 4 second before the node registered itself.\r\n\r\n```\r\nmspreitz@mjs-dev-1:~/go/src/k8s.io/kubernetes$ git status\r\nOn branch master\r\nYour branch is up to date with 'upstream/master'.\r\n\r\nnothing to commit, working tree clean\r\n\r\nmspreitz@mjs-dev-1:~/go/src/k8s.io/kubernetes$ git rev-parse HEAD\r\nd2e2337744072553ae7756ba972607ffb6532a85\r\n\r\nmspreitz@mjs-dev-1:~/go/src/k8s.io/kubernetes$ LOG_LEVEL=7 hack/local-up-cluster.sh\r\nWARNING : The kubelet is configured to not fail even if swap is enabled; production deployments should disable swap.\r\nWARNING : This script MAY be run as root for docker socket / iptables functionality; if failures occur, retry as root.\r\nmake: Entering directory '/home/mspreitz/go/src/k8s.io/kubernetes'\r\nmake[1]: Entering directory '/home/mspreitz/go/src/k8s.io/kubernetes'\r\nmake[1]: Leaving directory '/home/mspreitz/go/src/k8s.io/kubernetes'\r\n+++ [0823 23:55:31] Building go targets for linux/amd64:\r\n    cmd/kubectl\r\n    cmd/hyperkube\r\nmake: Leaving directory '/home/mspreitz/go/src/k8s.io/kubernetes'\r\nWARNING: No swap limit support\r\nKubelet cgroup driver defaulted to use: cgroupfs\r\nAPI SERVER insecure port is free, proceeding...\r\nAPI SERVER secure port is free, proceeding...\r\n\r\n...\r\n\r\nkubelet ( 8040 ) is running.\r\nCreate default storage class for \r\nstorageclass.storage.k8s.io/standard created\r\nLocal Kubernetes cluster is running. Press Ctrl-C to shut it down.\r\n\r\nLogs:\r\n  /tmp/kube-apiserver.log\r\n  /tmp/kube-controller-manager.log\r\n  \r\n  /tmp/kube-proxy.log\r\n  /tmp/kube-scheduler.log\r\n  /tmp/kubelet.log\r\n\r\nTo start using your cluster, you can open up another terminal/tab and run:\r\n\r\n  export KUBECONFIG=/var/run/kubernetes/admin.kubeconfig\r\n  cluster/kubectl.sh\r\n\r\nAlternatively, you can write to the default kubeconfig:\r\n\r\n  export KUBERNETES_PROVIDER=local\r\n\r\n  cluster/kubectl.sh config set-cluster local --server=https://localhost:6443 --certificate-authority=/var/run/kubernetes/server-ca.crt\r\n  cluster/kubectl.sh config set-credentials myself --client-key=/var/run/kubernetes/client-admin.key --client-certificate=/var/run/kubernetes/client-admin.crt\r\n  cluster/kubectl.sh config set-context local --cluster=local --user=myself\r\n  cluster/kubectl.sh config use-context local\r\n  cluster/kubectl.sh\r\nW0823 23:57:06]: kube-proxy terminated unexpectedly, see /tmp/kube-proxy.log\r\n```\r\n\r\nLooking in `/tmp/kube-proxy.log`, I see it makes several failed attempts to GET its node; the last one ends like this:\r\n```\r\nI0823 23:57:05.197907    7905 round_trippers.go:420] GET https://localhost:6443/api/v1/nodes/127.0.0.1\r\nI0823 23:57:05.197947    7905 round_trippers.go:427] Request Headers:\r\nI0823 23:57:05.197957    7905 round_trippers.go:431]     Accept: application/vnd.kubernetes.protobuf, */*\r\nI0823 23:57:05.197967    7905 round_trippers.go:431]     User-Agent: hyperkube/v1.17.0 (linux/amd64) kubernetes/d2e2337\r\nI0823 23:57:05.200494    7905 round_trippers.go:446] Response Status: 404 Not Found in 2 milliseconds\r\nE0823 23:57:05.200641    7905 node.go:124] Failed to retrieve node info: nodes \"127.0.0.1\" not found\r\nF0823 23:57:05.200670    7905 server.go:440] unable to get node IP for hostname 127.0.0.1\r\n```\r\n\r\nIn `kube-apiserver.log`, I see several failed attempts to GET the node.  Here is the last one:\r\n```\r\nI0823 23:57:09.667220    7596 httplog.go:90] GET /api/v1/nodes/127.0.0.1?timeout=10s: (2.315961ms) 404 [hyperkube/v1.17.0 (linux/amd64) kubernetes/d2e2337 127.0.0.1:42586]\r\n```\r\n\r\nVery shortly after that, there is a POST to /nodes:\r\n```\r\nI0823 23:57:09.771850    7596 httplog.go:90] POST /api/v1/nodes: (4.914782ms) 201 [hyperkube/v1.17.0 (linux/amd64) kubernetes/d2e2337 127.0.0.1:42586]\r\n```\r\n\r\nAnd after that the GETs of the node succeed.  Here is the first success:\r\n```\r\nI0823 23:57:09.776273    7596 httplog.go:90] GET /api/v1/nodes/127.0.0.1?resourceVersion=0&timeout=10s: (828.039\u00b5s) 200 [hyperkube/v1.17.0 (linux/amd64) kubernetes/d2e2337 127.0.0.1:42586]\r\n```\r\n\r\n**What you expected to happen**:\r\nI expected `hack/local-up-cluster.sh` in `master` to work.\r\n\r\n**How to reproduce it (as minimally and precisely as possible)**:\r\nCheckout master and try `hack/local-up-cluster.sh`\r\n\r\n**Anything else we need to know?**:\r\nThis might be very easy to fix.  In `pkg/util/node/node.go`, there is a function `GetNodeIP` that makes a limited number attempts to GET the node with an exponential back-off.  I suspect just increasing the number of tries by one will solve this.\r\n\r\n**Environment**:\r\n- Kubernetes version (use `kubectl version`):\r\n- Cloud provider or hardware configuration: Intel VM\r\n- OS (e.g: `cat /etc/os-release`): Ubuntu 18.04.2 LTS\r\n- Kernel (e.g. `uname -a`): Linux mjs-dev-1 4.15.0-48-generic #51-Ubuntu SMP Wed Apr 3 08:28:49 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux\r\n- Install tools: git; `hack/local-up-cluster.sh`\r\n- Network plugin and version (if this is a network-related bug):\r\n- Others:\r\n",
  "closed_at": "2019-10-12T14:48:38Z",
  "closed_by": {
    "avatar_url": "https://avatars0.githubusercontent.com/u/20407524?v=4",
    "events_url": "https://api.github.com/users/k8s-ci-robot/events{/privacy}",
    "followers_url": "https://api.github.com/users/k8s-ci-robot/followers",
    "following_url": "https://api.github.com/users/k8s-ci-robot/following{/other_user}",
    "gists_url": "https://api.github.com/users/k8s-ci-robot/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/k8s-ci-robot",
    "id": 20407524,
    "login": "k8s-ci-robot",
    "node_id": "MDQ6VXNlcjIwNDA3NTI0",
    "organizations_url": "https://api.github.com/users/k8s-ci-robot/orgs",
    "received_events_url": "https://api.github.com/users/k8s-ci-robot/received_events",
    "repos_url": "https://api.github.com/users/k8s-ci-robot/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/k8s-ci-robot/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/k8s-ci-robot/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/k8s-ci-robot"
  },
  "comments": 2,
  "comments_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/81879/comments",
  "created_at": "2019-08-24T01:33:05Z",
  "events_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/81879/events",
  "html_url": "https://github.com/kubernetes/kubernetes/issues/81879",
  "id": 484763903,
  "labels": [
    {
      "color": "e11d21",
      "default": false,
      "description": "Categorizes issue or PR as related to a bug.",
      "id": 105146071,
      "name": "kind/bug",
      "node_id": "MDU6TGFiZWwxMDUxNDYwNzE=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/kind/bug"
    },
    {
      "color": "eb6420",
      "default": false,
      "description": "Must be staffed and worked on either currently, or very soon, ideally in time for the next release.",
      "id": 114528223,
      "name": "priority/important-soon",
      "node_id": "MDU6TGFiZWwxMTQ1MjgyMjM=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/priority/important-soon"
    },
    {
      "color": "d2b48c",
      "default": false,
      "description": "Categorizes an issue or PR as relevant to SIG Node.",
      "id": 173493665,
      "name": "sig/node",
      "node_id": "MDU6TGFiZWwxNzM0OTM2NjU=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/sig/node"
    }
  ],
  "labels_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/81879/labels{/name}",
  "locked": false,
  "milestone": null,
  "node_id": "MDU6SXNzdWU0ODQ3NjM5MDM=",
  "number": 81879,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/kubernetes/kubernetes",
  "state": "closed",
  "title": "kube-proxy gives up too soon waiting for node registration in hack/local-up-cluster.sh",
  "updated_at": "2019-10-12T14:48:38Z",
  "url": "https://api.github.com/repos/kubernetes/kubernetes/issues/81879",
  "user": {
    "avatar_url": "https://avatars2.githubusercontent.com/u/14296719?v=4",
    "events_url": "https://api.github.com/users/MikeSpreitzer/events{/privacy}",
    "followers_url": "https://api.github.com/users/MikeSpreitzer/followers",
    "following_url": "https://api.github.com/users/MikeSpreitzer/following{/other_user}",
    "gists_url": "https://api.github.com/users/MikeSpreitzer/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/MikeSpreitzer",
    "id": 14296719,
    "login": "MikeSpreitzer",
    "node_id": "MDQ6VXNlcjE0Mjk2NzE5",
    "organizations_url": "https://api.github.com/users/MikeSpreitzer/orgs",
    "received_events_url": "https://api.github.com/users/MikeSpreitzer/received_events",
    "repos_url": "https://api.github.com/users/MikeSpreitzer/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/MikeSpreitzer/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/MikeSpreitzer/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/MikeSpreitzer"
  }
}