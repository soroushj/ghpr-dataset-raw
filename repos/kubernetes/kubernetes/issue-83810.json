{
  "active_lock_reason": null,
  "assignee": {
    "avatar_url": "https://avatars3.githubusercontent.com/u/15641246?v=4",
    "events_url": "https://api.github.com/users/matte21/events{/privacy}",
    "followers_url": "https://api.github.com/users/matte21/followers",
    "following_url": "https://api.github.com/users/matte21/following{/other_user}",
    "gists_url": "https://api.github.com/users/matte21/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/matte21",
    "id": 15641246,
    "login": "matte21",
    "node_id": "MDQ6VXNlcjE1NjQxMjQ2",
    "organizations_url": "https://api.github.com/users/matte21/orgs",
    "received_events_url": "https://api.github.com/users/matte21/received_events",
    "repos_url": "https://api.github.com/users/matte21/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/matte21/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/matte21/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/matte21"
  },
  "assignees": [
    {
      "avatar_url": "https://avatars3.githubusercontent.com/u/15641246?v=4",
      "events_url": "https://api.github.com/users/matte21/events{/privacy}",
      "followers_url": "https://api.github.com/users/matte21/followers",
      "following_url": "https://api.github.com/users/matte21/following{/other_user}",
      "gists_url": "https://api.github.com/users/matte21/gists{/gist_id}",
      "gravatar_id": "",
      "html_url": "https://github.com/matte21",
      "id": 15641246,
      "login": "matte21",
      "node_id": "MDQ6VXNlcjE1NjQxMjQ2",
      "organizations_url": "https://api.github.com/users/matte21/orgs",
      "received_events_url": "https://api.github.com/users/matte21/received_events",
      "repos_url": "https://api.github.com/users/matte21/repos",
      "site_admin": false,
      "starred_url": "https://api.github.com/users/matte21/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/matte21/subscriptions",
      "type": "User",
      "url": "https://api.github.com/users/matte21"
    }
  ],
  "author_association": "CONTRIBUTOR",
  "body": "<!-- Please use this template while reporting a bug and provide as much info as possible. Not doing so may result in your bug not being addressed in a timely manner. Thanks!\r\n\r\nIf the matter is security related, please disclose it privately via https://kubernetes.io/security/\r\n-->\r\n\r\n\r\n**What happened**:\r\nI did a review of https://github.com/kubernetes/kubernetes/tree/master/staging/src/k8s.io/client-go/tools/cache and found out a case where a SharedIndexInformer can miss a notification. Follows an example scenario where this could happen.\r\n\r\n1) A SharedIndexInformer is running, and its reflector is WATCHing.\r\n2) A delete notification for an API object _X_ with namespaced name _N1_ and UID _U1_ which was in the informer's cache is received.\r\n3) The reflector [invokes the store's Delete method](https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/client-go/tools/cache/reflector.go#L395-L399) on _X_; the relevant store is a DeltaFIFO and its Delete method is [this](https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/client-go/tools/cache/delta_fifo.go#L191).\r\n4) The DeltaFIFO's Delete method invokes [queueActionLocked](https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/client-go/tools/cache/delta_fifo.go#L219), which [enqueues _N1_ in the DeltaFIFO's queue and adds a delta of type deleted to the map from objects IDs (namespaced names) to deltas](https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/client-go/tools/cache/delta_fifo.go#L320-L328).\r\n\r\nNotice that the store of the reflector, i.e., the DeltaFIFO, is NOT the SharedIndexInformer's store/cache: [the SharedIndexInformer extracts object deltas from the DeltaFIFO and modifies its cache accordingly](https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/client-go/tools/cache/shared_informer.go#L448-L477). Assume that BEFORE _X_'s deletion is popped from the DeltaFIFO and applied to the informer's cache, the following sequence of events take place:\r\n\r\n5) The WATCH is interrupted because of a network partition.\r\n6) While the reflector is not watching, a new API object _Y_ with namespaced name _N1_ (same as _X_) and UID _U2_ is created.\r\n7) The partition disappears and the reflector does a relist against the API server; there's a \"hole\" between the last watch notification and the list results; assume _Y_ is in the LIST results.\r\n8) The reflector will load the LIST results in the store/DeltaFIFO with [syncWith](https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/client-go/tools/cache/reflector.go#L240) which in turn calls the DeltaFIFO's [replace](https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/client-go/tools/cache/reflector.go#L340) method. The DeltaFIFO's replace method attempts to add to the DeltaFIFO a delta of type `Sync` for every object in the LIST results: when processing _Y_ it will [invoke queueActionLocked](https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/client-go/tools/cache/delta_fifo.go#L456-L462) which should [create a delta of type `Sync` for  Y and add it to the DeltaFIFO](https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/client-go/tools/cache/delta_fifo.go#L320-L328). But `queueActionLocked` won't enqueue Y's delta, because it enqueues deltas of type `Sync` only if there's not already a delta of type `Deleted` for the given object ID as the last delta for that object ID (see [here](https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/client-go/tools/cache/delta_fifo.go#L313-L318) and [here](https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/client-go/tools/cache/delta_fifo.go#L298-L303)), to avoid recreating a deleted object during a periodic resync triggered by the SharedIndexInformer resync period. Object IDs are namespaced names,  and remember that the last delta for Y's namespaced name in the DeltaFIFO is _X_'s deletion. The consequence is that _Y_'s creation delta is not added to the DeltaFIFO: Y is not added to the SharedIndexInformer's cache and its creation notification handler does not execute. The SharedIndexInformer missed Y's creation. \r\n\r\n**What you expected to happen**:\r\nI expected SharedIndexInformers to get all notifications from the API server.\r\n\r\n**Anything else we need to know?**\r\nMissed notifications should be rare: for them to occur a `Delete` delta must stay in the DeltaFIFO without being processed for long enough for a new List against the API server to be completed. Also, https://github.com/kubernetes/kubernetes/pull/83520 touches the reflector code that handles list and watches, and it might introduce changes relevant to this bug.\r\n\r\n**Proposed solution**:\r\nThere's a straightforward fix: get rid of the check that skips enqueuing of a `Sync` delta for object ID _X_ if the last delta added to the DeltaFIFO (and still in it) for _X_  is of type  `Delete`;  [this](https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/client-go/tools/cache/delta_fifo.go#L313-L318) is the code to remove. Notice that such check applies to deltas of type `Sync` only. `Sync` deltas are triggered only by relists and periodic resyncs. In the case of relists the check is harmful as it's the cause of this bug. In the case of periodic resyncs, that check is useless because it will either evaluate to `false` or not execute; in fact, during a period resync, [processing of an object with ID _X_ stops if there's already a delta for _X_ in the DeltaFIFO](https://github.com/kubernetes/client-go/blob/master/tools/cache/delta_fifo.go#L560-L562) and this condition is checked before the check that would be removed, OTOH, if this condition is true and processing goes on the check that would be removed can only evaluate to `false` (hence the delta for _X_ is enqueued). If this solution has consensus I'd be happy to open a PR. \r\n",
  "closed_at": "2019-10-16T16:35:00Z",
  "closed_by": {
    "avatar_url": "https://avatars0.githubusercontent.com/u/20407524?v=4",
    "events_url": "https://api.github.com/users/k8s-ci-robot/events{/privacy}",
    "followers_url": "https://api.github.com/users/k8s-ci-robot/followers",
    "following_url": "https://api.github.com/users/k8s-ci-robot/following{/other_user}",
    "gists_url": "https://api.github.com/users/k8s-ci-robot/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/k8s-ci-robot",
    "id": 20407524,
    "login": "k8s-ci-robot",
    "node_id": "MDQ6VXNlcjIwNDA3NTI0",
    "organizations_url": "https://api.github.com/users/k8s-ci-robot/orgs",
    "received_events_url": "https://api.github.com/users/k8s-ci-robot/received_events",
    "repos_url": "https://api.github.com/users/k8s-ci-robot/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/k8s-ci-robot/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/k8s-ci-robot/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/k8s-ci-robot"
  },
  "comments": 33,
  "comments_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/83810/comments",
  "created_at": "2019-10-11T22:15:00Z",
  "events_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/83810/events",
  "html_url": "https://github.com/kubernetes/kubernetes/issues/83810",
  "id": 506079431,
  "labels": [
    {
      "color": "e11d21",
      "default": false,
      "description": "Categorizes issue or PR as related to a bug.",
      "id": 105146071,
      "name": "kind/bug",
      "node_id": "MDU6TGFiZWwxMDUxNDYwNzE=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/kind/bug"
    },
    {
      "color": "e11d21",
      "default": false,
      "description": "Highest priority. Must be actively worked on as someone's top priority right now.",
      "id": 114528068,
      "name": "priority/critical-urgent",
      "node_id": "MDU6TGFiZWwxMTQ1MjgwNjg=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/priority/critical-urgent"
    },
    {
      "color": "d2b48c",
      "default": false,
      "description": "Categorizes an issue or PR as relevant to SIG API Machinery.",
      "id": 173493835,
      "name": "sig/api-machinery",
      "node_id": "MDU6TGFiZWwxNzM0OTM4MzU=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/sig/api-machinery"
    }
  ],
  "labels_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/83810/labels{/name}",
  "locked": false,
  "milestone": null,
  "node_id": "MDU6SXNzdWU1MDYwNzk0MzE=",
  "number": 83810,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/kubernetes/kubernetes",
  "state": "closed",
  "title": "SharedIndexInformers can miss create notifications",
  "updated_at": "2020-01-03T15:20:52Z",
  "url": "https://api.github.com/repos/kubernetes/kubernetes/issues/83810",
  "user": {
    "avatar_url": "https://avatars3.githubusercontent.com/u/15641246?v=4",
    "events_url": "https://api.github.com/users/matte21/events{/privacy}",
    "followers_url": "https://api.github.com/users/matte21/followers",
    "following_url": "https://api.github.com/users/matte21/following{/other_user}",
    "gists_url": "https://api.github.com/users/matte21/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/matte21",
    "id": 15641246,
    "login": "matte21",
    "node_id": "MDQ6VXNlcjE1NjQxMjQ2",
    "organizations_url": "https://api.github.com/users/matte21/orgs",
    "received_events_url": "https://api.github.com/users/matte21/received_events",
    "repos_url": "https://api.github.com/users/matte21/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/matte21/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/matte21/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/matte21"
  }
}