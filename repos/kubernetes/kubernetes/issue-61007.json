{
  "active_lock_reason": null,
  "assignee": null,
  "assignees": [],
  "author_association": "CONTRIBUTOR",
  "body": "> /kind bug\r\n\r\n**What happened**:\r\n\r\nI setup custom metrics based autoscaling with multiple metrics.  One of those metrics was not available.  HPA reports all metrics as \"unknown\" (even the ones that are still available) and refuses to operate.\r\n\r\n```\r\nMetrics:                                               ( current / target )\r\n  \"sockjs_sessions_current\" on pods:                   <unknown> / 500\r\n  \"ddp_method_calls\" on pods:                          <unknown> / 25\r\n  \"http_requests\" on pods:                             <unknown> / 25\r\n  resource cpu on pods  (as a percentage of request):  <unknown> / 60%\r\nConditions:\r\n  Type           Status  Reason               Message\r\n  ----           ------  ------               -------\r\n  AbleToScale    True    SucceededGetScale    the HPA controller was able to get the target's current scale\r\n  ScalingActive  False   FailedGetPodsMetric  the HPA was unable to compute the replica count: unable to get metric ddp_method_calls: no metrics returned from custom metrics API\r\nEvents:\r\n  Type     Reason               Age                  From                       Message\r\n  ----     ------               ----                 ----                       -------\r\n  Warning  FailedGetPodsMetric  1m (x1052 over 17h)  horizontal-pod-autoscaler  unable to get metric ddp_method_calls: no metrics returned from custom metrics API\r\n```\r\n\r\n**What you expected to happen**:\r\n\r\nPods would be automatically scaled based on metrics that were available, ignoring missing metrics (treating them as zero).\r\n\r\nA partial failure in the metrics system should not prevent auto-scaling from proceeding with the data that it has.  For example, CPU % metrics come from the k8s metrics server whereas the other metrics come from the prometheus adapter.  If the prometheus adapter goes away we can still use the CPU metric as a lower bound on the number of replicas.\r\n\r\nIf you consider, e.g. https://github.com/kubernetes/kubernetes/blob/e99ec245958f82acb2404f8597844d62b8f459c9/pkg/controller/podautoscaler/horizontal.go#L242 , instead of aborting the whole metric gathering process there, it could have stored a placeholder or zero metric value when it fails to fetch the metric.\r\n\r\n**How to reproduce it (as minimally and precisely as possible)**:\r\n\r\nSetup a custom metrics server and tell HPA to scale based on several metrics, one of which is not actually available.\r\n\r\n**Environment**:\r\n\r\nkops 1.8 on AWS\r\nClient Version: version.Info{Major:\"1\", Minor:\"9\", GitVersion:\"v1.9.2\", GitCommit:\"5fa2db2bd46ac79e5e00a4e6ed24191080aa463b\", GitTreeState:\"clean\", BuildDate:\"2018-01-18T10:09:24Z\", GoVersion:\"go1.9.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\r\nServer Version: version.Info{Major:\"1\", Minor:\"8\", GitVersion:\"v1.8.8\", GitCommit:\"2f73858c9e6ede659d6828fe5a1862a48034a0fd\", GitTreeState:\"clean\", BuildDate:\"2018-02-09T21:23:25Z\", GoVersion:\"go1.8.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\r\n",
  "closed_at": "2019-06-04T02:35:00Z",
  "closed_by": {
    "avatar_url": "https://avatars0.githubusercontent.com/u/20407524?v=4",
    "events_url": "https://api.github.com/users/k8s-ci-robot/events{/privacy}",
    "followers_url": "https://api.github.com/users/k8s-ci-robot/followers",
    "following_url": "https://api.github.com/users/k8s-ci-robot/following{/other_user}",
    "gists_url": "https://api.github.com/users/k8s-ci-robot/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/k8s-ci-robot",
    "id": 20407524,
    "login": "k8s-ci-robot",
    "node_id": "MDQ6VXNlcjIwNDA3NTI0",
    "organizations_url": "https://api.github.com/users/k8s-ci-robot/orgs",
    "received_events_url": "https://api.github.com/users/k8s-ci-robot/received_events",
    "repos_url": "https://api.github.com/users/k8s-ci-robot/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/k8s-ci-robot/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/k8s-ci-robot/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/k8s-ci-robot"
  },
  "comments": 24,
  "comments_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/61007/comments",
  "created_at": "2018-03-10T19:27:31Z",
  "events_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/61007/events",
  "html_url": "https://github.com/kubernetes/kubernetes/issues/61007",
  "id": 304097299,
  "labels": [
    {
      "color": "e11d21",
      "default": false,
      "description": "Categorizes issue or PR as related to a bug.",
      "id": 105146071,
      "name": "kind/bug",
      "node_id": "MDU6TGFiZWwxMDUxNDYwNzE=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/kind/bug"
    },
    {
      "color": "d3e2f0",
      "default": false,
      "description": "Indicates that an issue or PR should not be auto-closed due to staleness.",
      "id": 778118403,
      "name": "lifecycle/frozen",
      "node_id": "MDU6TGFiZWw3NzgxMTg0MDM=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/lifecycle/frozen"
    },
    {
      "color": "fbca04",
      "default": false,
      "description": "Higher priority than priority/awaiting-more-evidence.",
      "id": 114528273,
      "name": "priority/backlog",
      "node_id": "MDU6TGFiZWwxMTQ1MjgyNzM=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/priority/backlog"
    },
    {
      "color": "eb6420",
      "default": false,
      "description": "Important over the long term, but may not be staffed and/or may need multiple releases to complete.",
      "id": 496752236,
      "name": "priority/important-longterm",
      "node_id": "MDU6TGFiZWw0OTY3NTIyMzY=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/priority/important-longterm"
    },
    {
      "color": "d2b48c",
      "default": false,
      "description": "Categorizes an issue or PR as relevant to SIG Autoscaling.",
      "id": 238245616,
      "name": "sig/autoscaling",
      "node_id": "MDU6TGFiZWwyMzgyNDU2MTY=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/sig/autoscaling"
    }
  ],
  "labels_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/61007/labels{/name}",
  "locked": false,
  "milestone": null,
  "node_id": "MDU6SXNzdWUzMDQwOTcyOTk=",
  "number": 61007,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/kubernetes/kubernetes",
  "state": "closed",
  "title": "HPA refuses to scale if any custom metric is missing",
  "updated_at": "2019-06-04T02:35:00Z",
  "url": "https://api.github.com/repos/kubernetes/kubernetes/issues/61007",
  "user": {
    "avatar_url": "https://avatars2.githubusercontent.com/u/327833?v=4",
    "events_url": "https://api.github.com/users/dobesv/events{/privacy}",
    "followers_url": "https://api.github.com/users/dobesv/followers",
    "following_url": "https://api.github.com/users/dobesv/following{/other_user}",
    "gists_url": "https://api.github.com/users/dobesv/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/dobesv",
    "id": 327833,
    "login": "dobesv",
    "node_id": "MDQ6VXNlcjMyNzgzMw==",
    "organizations_url": "https://api.github.com/users/dobesv/orgs",
    "received_events_url": "https://api.github.com/users/dobesv/received_events",
    "repos_url": "https://api.github.com/users/dobesv/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/dobesv/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/dobesv/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/dobesv"
  }
}