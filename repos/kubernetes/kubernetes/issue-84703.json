{
  "active_lock_reason": null,
  "assignee": null,
  "assignees": [],
  "author_association": "CONTRIBUTOR",
  "body": "<!-- Please use this template while reporting a bug and provide as much info as possible. Not doing so may result in your bug not being addressed in a timely manner. Thanks!\r\n\r\nIf the matter is security related, please disclose it privately via https://kubernetes.io/security/\r\n-->\r\n\r\n\r\n**What happened**:\r\n\r\nWhen static policy is enabled, cpu manager do validate state between checkpoint (`/var/lib/kubelet/cpu_manager_state`) and current node cpu topology before kubelet fully started. If the validation is failed (sometimes occurred after node or kubelet crash), cpu manager will panic immediately. However, this panic is handled and ignored by upper wait.Util(). This causes kubelet continue to start (PLEG, syncLoop) normally although other modules in container manager (like qosContainerManager, in setupNode method) doesn't start successfully. Then, kubelet sync pod with a uninitialized qosContainerManager. And it will leads to unexpected results such as:\r\n\r\n1. panic when call UpdateQoSCgroups in syncPod.\r\n3. all pods/containers on node will be killed\r\n3. all cgroup path (like kubepods.slice) recursively in each cgroup will be housekept.\r\n2. node status is still ready, kubelet process is still running (doesn't work, panic continuously but not exit)\r\n\r\npanic log of `1`:\r\n\r\n```\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]: E1104 14:48:31.406568    5461 runtime.go:78] Observed a panic: \"invalid memory address or nil pointer dereference\" (runtime error: invalid memory address or nil pointer dereference)\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]: goroutine 788 [running]:\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]: k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/util/runtime.logPanic(0x3ad3360, 0x7a8efc0)\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]:         /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/util/runtime/runtime.go:74 +0xa3\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]: k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/util/runtime.HandleCrash(0x0, 0x0, 0x0)\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]:         /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/util/runtime/runtime.go:48 +0x82\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]: panic(0x3ad3360, 0x7a8efc0)\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]:         /snap/go/4765/src/runtime/panic.go:522 +0x1b5\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]: k8s.io/kubernetes/pkg/kubelet/cm.(*qosContainerManagerImpl).setCPUCgroupConfig(0xc0008170e0, 0xc0010beee8, 0x42f4e55, 0xa)\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]:         /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/pkg/kubelet/cm/qos_container_manager_linux.go:169 +0x3b\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]: k8s.io/kubernetes/pkg/kubelet/cm.(*qosContainerManagerImpl).UpdateCgroups(0xc0008170e0, 0x0, 0x0)\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]:         /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/pkg/kubelet/cm/qos_container_manager_linux.go:285 +0x25a\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]: k8s.io/kubernetes/pkg/kubelet/cm.(*containerManagerImpl).UpdateQOSCgroups(0xc000435d40, 0xc000a86c00, 0xc00071d680)\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]:         /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/pkg/kubelet/cm/container_manager_linux.go:559 +0x3a\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]: k8s.io/kubernetes/pkg/kubelet.(*Kubelet).killPod(0xc0001be400, 0xc000a86c00, 0x0, 0xc000928680, 0x0, 0x4, 0x4)\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]:         /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/pkg/kubelet/kubelet_pods.go:822 +0x118\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]: k8s.io/kubernetes/pkg/kubelet.(*Kubelet).syncPod(0xc0001be400, 0x0, 0xc000a86c00, 0x2, 0xc000928680, 0x0, 0xc00127aa80, 0xc00071bbc0)\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]:         /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/pkg/kubelet/kubelet.go:1615 +0x25d3\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]: k8s.io/kubernetes/pkg/kubelet.(*podWorkers).managePodLoop.func1(0xc0009e9ed8, 0xc0001521c0, 0xc0010bfec0, 0x100c000f346c0, 0x0)\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]:         /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/pkg/kubelet/pod_workers.go:175 +0x25d\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]: k8s.io/kubernetes/pkg/kubelet.(*podWorkers).managePodLoop(0xc0001521c0, 0xc001196a20)\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]:         /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/pkg/kubelet/pod_workers.go:184 +0x13f\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]: k8s.io/kubernetes/pkg/kubelet.(*podWorkers).UpdatePod.func1(0xc0001521c0, 0xc001196a20)\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]:         /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/pkg/kubelet/pod_workers.go:222 +0x62\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]: created by k8s.io/kubernetes/pkg/kubelet.(*podWorkers).UpdatePod\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]:         /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/pkg/kubelet/pod_workers.go:220 +0x395\r\n```\r\n\r\n`docker ps` of `2`:\r\n```\r\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\r\n```\r\n\r\nhousekeeping log for `3`:\r\n```\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]: I1104 14:48:31.055186    5461 manager.go:1005] Destroyed container: \"/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-poda5eaa6a7_ad37_4aea_a70a_77f040f45692.slice/docker-34533e2e609a61548e6fd687ca8e908fa99edd367abeeda826debfb659829b9c.scope\" (aliases: [k8s_calico-node_calico-node-96wk8_kube-system_a5eaa6a7-ad37-4aea-a70a-77f040f45692_5 34533e2e609a61548e6fd687ca8e908fa99edd367abeeda826debfb659829b9c], namespace: \"docker\")\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]: I1104 14:48:31.067184    5461 manager.go:1005] Destroyed container: \"/kubepods.slice/kubepods-besteffort.slice/kubepods-besteffort-pod65f7c408_6c1e_48f8_aa97_827c25b6e795.slice/docker-4acf276ec577147740809dddc8337d38ded9e962e976d216b9257ffda1a693e2.scope\" (aliases: [k8s_kube-proxy_kube-proxy-vfm8b_kube-system_65f7c408-6c1e-48f8-aa97-827c25b6e795_5 4acf276ec577147740809dddc8337d38ded9e962e976d216b9257ffda1a693e2], namespace: \"docker\")\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]: I1104 14:48:31.108097    5461 manager.go:1005] Destroyed container: \"/kubepods.slice/kubepods-besteffort.slice/kubepods-besteffort-pod3052785d_b13d_48ef_96e9_8ef240eda996.slice/docker-4fbfb36132d99091f73e4c96802eb79d3b5b9393d837ce1b2775e5e07a361d80.scope\" (aliases: [k8s_nginx_nginx-1-0-4sc6l_default_3052785d-b13d-48ef-96e9-8ef240eda996_4 4fbfb36132d99091f73e4c96802eb79d3b5b9393d837ce1b2775e5e07a361d80], namespace: \"docker\")\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]: I1104 14:48:31.117912    5461 manager.go:1005] Destroyed container: \"/kubepods.slice/kubepods-besteffort.slice/kubepods-besteffort-pod53e366df_e1f6_486c_9d74_ba88b2f0d8ad.slice/docker-e632915f5b56a522b414c09abe42832cc12fa1aa38b05f835b4a4cd47952010d.scope\" (aliases: [k8s_nginx_nginx-1-1-bzm7n_default_53e366df-e1f6-486c-9d74-ba88b2f0d8ad_4 e632915f5b56a522b414c09abe42832cc12fa1aa38b05f835b4a4cd47952010d], namespace: \"docker\")\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]: I1104 14:48:31.265379    5461 manager.go:1005] Destroyed container: \"/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-poda5eaa6a7_ad37_4aea_a70a_77f040f45692.slice/docker-0932b5cb8aa4bd9e5eddad8448d15bf9ff4e2fdb987aaac56b78d4f999b9ad89.scope\" (aliases: [k8s_POD_calico-node-96wk8_kube-system_a5eaa6a7-ad37-4aea-a70a-77f040f45692_5 0932b5cb8aa4bd9e5eddad8448d15bf9ff4e2fdb987aaac56b78d4f999b9ad89], namespace: \"docker\")\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]: I1104 14:48:31.273375    5461 manager.go:1005] Destroyed container: \"/kubepods.slice/kubepods-besteffort.slice/kubepods-besteffort-pod65f7c408_6c1e_48f8_aa97_827c25b6e795.slice/docker-96baff62f92fc4c2cfe2c5d8eb8b19f6d235f7902f128b5f4da90168ae18ca1e.scope\" (aliases: [k8s_POD_kube-proxy-vfm8b_kube-system_65f7c408-6c1e-48f8-aa97-827c25b6e795_5 96baff62f92fc4c2cfe2c5d8eb8b19f6d235f7902f128b5f4da90168ae18ca1e], namespace: \"docker\")\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]: I1104 14:48:31.540306    5461 manager.go:1005] Destroyed container: \"/kubepods.slice/kubepods-besteffort.slice/kubepods-besteffort-pod3052785d_b13d_48ef_96e9_8ef240eda996.slice/docker-815160ce8abf28485e6ef1533520f7ee0d3f39ffc8a4f8eab7697f778365cd51.scope\" (aliases: [k8s_POD_nginx-1-0-4sc6l_default_3052785d-b13d-48ef-96e9-8ef240eda996_4 815160ce8abf28485e6ef1533520f7ee0d3f39ffc8a4f8eab7697f778365cd51], namespace: \"docker\")\r\nNov 04 14:48:31 k8s-a-2 kubelet[5461]: I1104 14:48:31.577601    5461 manager.go:1005] Destroyed container: \"/kubepods.slice/kubepods-besteffort.slice/kubepods-besteffort-pod53e366df_e1f6_486c_9d74_ba88b2f0d8ad.slice/docker-f262358e244971f26d73bb03ac43d788f9b0634da414bfd2cc4668d6c5edb574.scope\" (aliases: [k8s_POD_nginx-1-1-bzm7n_default_53e366df-e1f6-486c-9d74-ba88b2f0d8ad_4 f262358e244971f26d73bb03ac43d788f9b0634da414bfd2cc4668d6c5edb574], namespace: \"docker\")\r\nNov 04 14:48:32 k8s-a-2 kubelet[5461]: I1104 14:48:32.610904    5461 manager.go:1005] Destroyed container: \"/kubepods.slice/kubepods-besteffort.slice/kubepods-besteffort-pod65f7c408_6c1e_48f8_aa97_827c25b6e795.slice\" (aliases: [], namespace: \"\")\r\nNov 04 14:48:32 k8s-a-2 kubelet[5461]: I1104 14:48:32.611025    5461 manager.go:1005] Destroyed container: \"/kubepods.slice/kubepods-besteffort.slice/kubepods-besteffort-pod53e366df_e1f6_486c_9d74_ba88b2f0d8ad.slice\" (aliases: [], namespace: \"\")\r\nNov 04 14:48:32 k8s-a-2 kubelet[5461]: I1104 14:48:32.611654    5461 manager.go:1005] Destroyed container: \"/kubepods.slice/kubepods-besteffort.slice/kubepods-besteffort-pod3052785d_b13d_48ef_96e9_8ef240eda996.slice\" (aliases: [], namespace: \"\")\r\nNov 04 14:48:32 k8s-a-2 kubelet[5461]: I1104 14:48:32.611687    5461 manager.go:1005] Destroyed container: \"/kubepods.slice/kubepods-besteffort.slice\" (aliases: [], namespace: \"\")\r\nNov 04 14:48:32 k8s-a-2 kubelet[5461]: I1104 14:48:32.611785    5461 manager.go:1005] Destroyed container: \"/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-poda5eaa6a7_ad37_4aea_a70a_77f040f45692.slice\" (aliases: [], namespace: \"\")\r\nNov 04 14:48:32 k8s-a-2 kubelet[5461]: I1104 14:48:32.611807    5461 manager.go:1005] Destroyed container: \"/kubepods.slice/kubepods-burstable.slice\" (aliases: [], namespace: \"\")\r\nNov 04 14:48:32 k8s-a-2 kubelet[5461]: I1104 14:48:32.611857    5461 manager.go:1005] Destroyed container: \"/kubepods.slice\" (aliases: [], namespace: \"\")\r\n``` \r\n\r\nnode status of `4`:\r\n```\r\nk8s-a-2   Ready    <none>   3d2h   v1.16.2\r\n```\r\n\r\n**What you expected to happen**:\r\n\r\nIMHO, It may not be a good idea that panics in new/start code logic. We shoud use `return err` instead, so the caller is able to check the err and exit immediately.\r\n\r\nkubelet should log fatal error and exit when some modules create or start failed.\r\n\r\n**How to reproduce it (as minimally and precisely as possible)**:\r\n\r\n1. enable cpu manager static policy\r\n\r\nmodify `/var/lib/kubelet/config.yaml` to enable cpu manager static policy:\r\n\r\n```\r\ncpuManagerPolicy: static\r\nsystemReserved:\r\n  cpu: 500m\r\n  memory: 200M\r\n```\r\n\r\nremove `/var/lib/kubelet/cpu_manager_state` and restart kubelet\r\n\r\n\r\n2. modify /var/lib/kubelet/cpu_manager_state by a invalid value to simulate node crash situation.\r\n\r\nfor example, change valid checkpoint from:\r\n```\r\n{\"policyName\":\"static\",\"defaultCpuSet\":\"0-3\",\"checksum\":2479968155}\r\n```\r\nto:\r\n```\r\n{\"policyName\":\"static\",\"defaultCpuSet\":\"0,2-3\",\"checksum\":1104188325}\r\n```\r\n\r\n3. restart kubelet again\r\n\r\n**Anything else we need to know?**:\r\n\r\nRef: \r\n1. container manager start and panic:\r\n\r\n- container manager start: https://github.com/kubernetes/kubernetes/blob/08410cbf06f1c8649157407c660b1c5cb528947b/pkg/kubelet/cm/container_manager_linux.go#L576\r\n\r\n- cpu manager start: https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/cm/cpumanager/cpu_manager.go#L180\r\n\r\n- static policy panic: https://github.com/kubernetes/kubernetes/blob/08410cbf06f1c8649157407c660b1c5cb528947b/pkg/kubelet/cm/cpumanager/policy_static.go#L122\r\n\r\n2. it can neither catch the error nor exit immediately here:\r\nhttps://github.com/kubernetes/kubernetes/blob/08410cbf06f1c8649157407c660b1c5cb528947b/pkg/kubelet/kubelet.go#L1375\r\n\r\nThis PR would Fix it, PLTA: https://github.com/kubernetes/kubernetes/pull/84705\r\n\r\n3. it would be happen when node crash or kubelet down:\r\nhttps://github.com/kubernetes/kubernetes/issues/84783\r\n\r\n**Environment**:\r\n- Kubernetes version (use `kubectl version`):\r\n```\r\nClient Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.2\", GitCommit:\"c97fe5036ef3df2967d086711e6c0c405941e14b\", GitTreeState:\"clean\", BuildDate:\"2019-10-15T19:18:23Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\r\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.2\", GitCommit:\"c97fe5036ef3df2967d086711e6c0c405941e14b\", GitTreeState:\"clean\", BuildDate:\"2019-10-15T19:09:08Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\r\n```\r\n- Cloud provider or hardware configuration:\r\n```\r\nkvm\r\n```\r\n- OS (e.g: `cat /etc/os-release`):\r\n```\r\nDISTRIB_ID=Ubuntu\r\nDISTRIB_RELEASE=16.04\r\nDISTRIB_CODENAME=xenial\r\nDISTRIB_DESCRIPTION=\"Ubuntu 16.04.6 LTS\r\n```\r\n- Kernel (e.g. `uname -a`):\r\n```\r\nLinux ubuntu 4.4.0-165-generic #193-Ubuntu SMP Tue Sep 17 17:42:52 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux\r\n```\r\n- Install tools:\r\n- Network plugin and version (if this is a network-related bug):\r\n- Others:\r\n```\r\n# lscpu | egrep 'Model name|Socket|Thread|NUMA|CPU\\(s\\)'\r\nCPU(s):                4\r\nOn-line CPU(s) list:   0-3\r\nThread(s) per core:    1\r\nSocket(s):             4\r\nNUMA node(s):          1\r\nModel name:            QEMU Virtual CPU version 2.5+\r\nNUMA node0 CPU(s):     0-3\r\n```\r\n",
  "closed_at": "2020-01-20T15:25:38Z",
  "closed_by": {
    "avatar_url": "https://avatars0.githubusercontent.com/u/20407524?v=4",
    "events_url": "https://api.github.com/users/k8s-ci-robot/events{/privacy}",
    "followers_url": "https://api.github.com/users/k8s-ci-robot/followers",
    "following_url": "https://api.github.com/users/k8s-ci-robot/following{/other_user}",
    "gists_url": "https://api.github.com/users/k8s-ci-robot/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/k8s-ci-robot",
    "id": 20407524,
    "login": "k8s-ci-robot",
    "node_id": "MDQ6VXNlcjIwNDA3NTI0",
    "organizations_url": "https://api.github.com/users/k8s-ci-robot/orgs",
    "received_events_url": "https://api.github.com/users/k8s-ci-robot/received_events",
    "repos_url": "https://api.github.com/users/k8s-ci-robot/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/k8s-ci-robot/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/k8s-ci-robot/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/k8s-ci-robot"
  },
  "comments": 1,
  "comments_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/84703/comments",
  "created_at": "2019-11-04T09:08:44Z",
  "events_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/84703/events",
  "html_url": "https://github.com/kubernetes/kubernetes/issues/84703",
  "id": 517025655,
  "labels": [
    {
      "color": "e11d21",
      "default": false,
      "description": "Categorizes issue or PR as related to a bug.",
      "id": 105146071,
      "name": "kind/bug",
      "node_id": "MDU6TGFiZWwxMDUxNDYwNzE=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/kind/bug"
    },
    {
      "color": "d2b48c",
      "default": false,
      "description": "Categorizes an issue or PR as relevant to SIG Node.",
      "id": 173493665,
      "name": "sig/node",
      "node_id": "MDU6TGFiZWwxNzM0OTM2NjU=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/sig/node"
    }
  ],
  "labels_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/84703/labels{/name}",
  "locked": false,
  "milestone": null,
  "node_id": "MDU6SXNzdWU1MTcwMjU2NTU=",
  "number": 84703,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/kubernetes/kubernetes",
  "state": "closed",
  "title": "cpumanager: kubelet should log fatal error and exit rather than panic when cpu manager fails on startup",
  "updated_at": "2020-01-20T15:25:38Z",
  "url": "https://api.github.com/repos/kubernetes/kubernetes/issues/84703",
  "user": {
    "avatar_url": "https://avatars3.githubusercontent.com/u/2081494?v=4",
    "events_url": "https://api.github.com/users/whypro/events{/privacy}",
    "followers_url": "https://api.github.com/users/whypro/followers",
    "following_url": "https://api.github.com/users/whypro/following{/other_user}",
    "gists_url": "https://api.github.com/users/whypro/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/whypro",
    "id": 2081494,
    "login": "whypro",
    "node_id": "MDQ6VXNlcjIwODE0OTQ=",
    "organizations_url": "https://api.github.com/users/whypro/orgs",
    "received_events_url": "https://api.github.com/users/whypro/received_events",
    "repos_url": "https://api.github.com/users/whypro/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/whypro/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/whypro/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/whypro"
  }
}