{
  "active_lock_reason": null,
  "assignee": null,
  "assignees": [],
  "author_association": "MEMBER",
  "body": "<!-- Please use this template while reporting a bug and provide as much info as possible. Not doing so may result in your bug not being addressed in a timely manner. Thanks!-->\r\n\r\n\r\n**What happened**:\r\n\r\nSometimes, scheduler doesn't preempt pods in an \"exact\" correct way/path. But good thing is the final state is accurate - pods which should be preempted are finally preempted.\r\n\r\n**What you expected to happen**:\r\n\r\nThe internal preemption process should also be exactly correct to avoid producing unnecessary preemptions.\r\n\r\n**How to reproduce it (as minimally and precisely as possible)**:\r\n\r\n> Following test are performed on a 8-core cpu worker node. You might need to adjust the cpu request/limit to reproduce.\r\n\r\nStep 0: to make it a clean env that no pods has occupied cpu, I edited all workloads to remove their cpu request/limits, so the node has 0 usage on cpu:\r\n\r\n```console\r\nAllocated resources:\r\n  (Total limits may be over 100 percent, i.e., overcommitted.)\r\n  Resource  Requests  Limits\r\n  --------  --------  ------\r\n  cpu       0 (0%)    0 (0%)\r\n  memory    0 (0%)    0 (0%)\r\n```\r\n\r\n<details><summary>Step 1: Create 4 priority classes</summary>\r\n<p>\r\n\r\n```yaml\r\napiVersion: scheduling.k8s.io/v1beta1\r\nkind: PriorityClass\r\nmetadata:\r\n  name: p1\r\nvalue: 1\r\nglobalDefault: false\r\ndescription: \"Priority p1 of value 1.\"\r\n---\r\napiVersion: scheduling.k8s.io/v1beta1\r\nkind: PriorityClass\r\nmetadata:\r\n  name: p2\r\nvalue: 2\r\nglobalDefault: false\r\ndescription: \"Priority p2 of value 2.\"\r\n---\r\napiVersion: scheduling.k8s.io/v1beta1\r\nkind: PriorityClass\r\nmetadata:\r\n  name: p3\r\nvalue: 3\r\nglobalDefault: false\r\ndescription: \"Priority p3 of value 3.\"\r\n---\r\napiVersion: scheduling.k8s.io/v1beta1\r\nkind: PriorityClass\r\nmetadata:\r\n  name: p4\r\nvalue: 4\r\nglobalDefault: false\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n<details><summary>Step 2: Create priority{1,2,3}.yaml</summary>\r\n<p>\r\n\r\n```yaml\r\napiVersion: apps/v1\r\nkind: Deployment\r\nmetadata:\r\n  name: lab1-1\r\nspec:\r\n  replicas: 5\r\n  selector:\r\n    matchLabels:\r\n      app: pause1\r\n  template:\r\n    metadata:\r\n      labels:\r\n        app: pause1\r\n    spec:\r\n      priorityClassName: p1\r\n      containers:\r\n      - name: pause\r\n        image: k8s.gcr.io/pause\r\n        resources:\r\n          requests:\r\n            cpu: 400m\r\n          limits:\r\n            cpu: 400m\r\n---\r\napiVersion: apps/v1\r\nkind: Deployment\r\nmetadata:\r\n  name: lab1-2\r\nspec:\r\n  replicas: 4\r\n  selector:\r\n    matchLabels:\r\n      app: pause2\r\n  template:\r\n    metadata:\r\n      labels:\r\n        app: pause2\r\n    spec:\r\n      priorityClassName: p2\r\n      containers:\r\n      - name: pause\r\n        image: k8s.gcr.io/pause\r\n        resources:\r\n          requests:\r\n            cpu: 500m\r\n          limits:\r\n            cpu: 500m\r\n---\r\napiVersion: apps/v1\r\nkind: Deployment\r\nmetadata:\r\n  name: lab1-3\r\nspec:\r\n  replicas: 4\r\n  selector:\r\n    matchLabels:\r\n      app: pause3\r\n  template:\r\n    metadata:\r\n      labels:\r\n        app: pause3\r\n    spec:\r\n      priorityClassName: p3\r\n      containers:\r\n      - name: pause\r\n        image: k8s.gcr.io/pause\r\n        resources:\r\n          requests:\r\n            cpu: 950m\r\n          limits:\r\n            cpu: 950m\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\nBy now, deploy1, deploy2, deploy3 occupied 7800m cpu:\r\n\r\n```console\r\nAllocated resources:\r\n  (Total limits may be over 100 percent, i.e., overcommitted.)\r\n  Resource  Requests     Limits\r\n  --------  --------     ------\r\n  cpu       7800m (97%)  7800m (97%)\r\n```\r\n\r\n<details><summary>Step 3: Create a high priority deployment4 to see how preemption works</summary>\r\n<p>\r\n\r\n```yaml\r\napiVersion: apps/v1\r\nkind: Deployment\r\nmetadata:\r\n  name: lab1-4\r\nspec:\r\n  replicas: 1\r\n  selector:\r\n    matchLabels:\r\n      app: pause4\r\n  template:\r\n    metadata:\r\n      labels:\r\n        app: pause4\r\n    spec:\r\n      priorityClassName: p4\r\n      containers:\r\n      - name: pause\r\n        image: k8s.gcr.io/pause\r\n        resources:\r\n          requests:\r\n            cpu: 4000m\r\n          limits:\r\n            cpu: 4000m\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\nExpected result is that pods in deploy1 and deploy2 are pending, and pods in deploy3 should NOT be touched. And finally pods in deploy3 and deploy4 are running.\r\n\r\nBut it turns out it's not the case, see detailed [log](https://github.com/kubernetes/kubernetes/files/2545626/70622.log)\r\n.\r\n\r\n**Anything else we need to know?**:\r\n\r\nIt's easy to reproduce in a multiple nodes env (kubeadm), but not that easy to repro in a single node env (hack/local-up-cluster.sh).\r\n\r\n**Environment**:\r\n- Kubernetes version (use `kubectl version`): v1.11.3, v1.12.1, and master branch\r\n- Cloud provider or hardware configuration:\r\n- OS (e.g. from /etc/os-release): Ubuntu\r\n- Kernel (e.g. `uname -a`):\r\n- Install tools: kubeadm, or hack/local-up-cluster.sh\r\n- Others:\r\n\r\n<!-- DO NOT EDIT BELOW THIS LINE -->\r\n/kind bug\r\n/sig scheduling",
  "closed_at": "2018-11-17T04:27:35Z",
  "closed_by": {
    "avatar_url": "https://avatars0.githubusercontent.com/u/20407524?v=4",
    "events_url": "https://api.github.com/users/k8s-ci-robot/events{/privacy}",
    "followers_url": "https://api.github.com/users/k8s-ci-robot/followers",
    "following_url": "https://api.github.com/users/k8s-ci-robot/following{/other_user}",
    "gists_url": "https://api.github.com/users/k8s-ci-robot/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/k8s-ci-robot",
    "id": 20407524,
    "login": "k8s-ci-robot",
    "node_id": "MDQ6VXNlcjIwNDA3NTI0",
    "organizations_url": "https://api.github.com/users/k8s-ci-robot/orgs",
    "received_events_url": "https://api.github.com/users/k8s-ci-robot/received_events",
    "repos_url": "https://api.github.com/users/k8s-ci-robot/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/k8s-ci-robot/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/k8s-ci-robot/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/k8s-ci-robot"
  },
  "comments": 7,
  "comments_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/70622/comments",
  "created_at": "2018-11-04T06:54:56Z",
  "events_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/70622/events",
  "html_url": "https://github.com/kubernetes/kubernetes/issues/70622",
  "id": 377127015,
  "labels": [
    {
      "color": "e11d21",
      "default": false,
      "description": "Categorizes issue or PR as related to a bug.",
      "id": 105146071,
      "name": "kind/bug",
      "node_id": "MDU6TGFiZWwxMDUxNDYwNzE=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/kind/bug"
    },
    {
      "color": "d2b48c",
      "default": false,
      "description": "Categorizes an issue or PR as relevant to SIG Scheduling.",
      "id": 125550211,
      "name": "sig/scheduling",
      "node_id": "MDU6TGFiZWwxMjU1NTAyMTE=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/sig/scheduling"
    }
  ],
  "labels_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/70622/labels{/name}",
  "locked": false,
  "milestone": null,
  "node_id": "MDU6SXNzdWUzNzcxMjcwMTU=",
  "number": 70622,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/kubernetes/kubernetes",
  "state": "closed",
  "title": "Scheduler sometimes preempts unnecessary pods",
  "updated_at": "2018-11-17T04:27:35Z",
  "url": "https://api.github.com/repos/kubernetes/kubernetes/issues/70622",
  "user": {
    "avatar_url": "https://avatars0.githubusercontent.com/u/1425903?v=4",
    "events_url": "https://api.github.com/users/Huang-Wei/events{/privacy}",
    "followers_url": "https://api.github.com/users/Huang-Wei/followers",
    "following_url": "https://api.github.com/users/Huang-Wei/following{/other_user}",
    "gists_url": "https://api.github.com/users/Huang-Wei/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/Huang-Wei",
    "id": 1425903,
    "login": "Huang-Wei",
    "node_id": "MDQ6VXNlcjE0MjU5MDM=",
    "organizations_url": "https://api.github.com/users/Huang-Wei/orgs",
    "received_events_url": "https://api.github.com/users/Huang-Wei/received_events",
    "repos_url": "https://api.github.com/users/Huang-Wei/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/Huang-Wei/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/Huang-Wei/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/Huang-Wei"
  }
}