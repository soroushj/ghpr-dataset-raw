{
  "active_lock_reason": null,
  "assignee": null,
  "assignees": [],
  "author_association": "NONE",
  "body": "/kind bug\r\n\r\n**What happened**:\r\nSince upgrading to Kube 1.7.6, I'm seeing my HPAs scale above it's maxReplicas.  Because of this, it's rapidly creating pods, then terminating them, and repeat.\r\n\r\n**What you expected to happen**:\r\nI expected the HPA to never exceed maxReplicas.\r\n\r\n**How to reproduce it (as minimally and precisely as possible)**:\r\n```\r\napiVersion: autoscaling/v1\r\nkind: HorizontalPodAutoscaler\r\nmetadata:\r\n  name: monolith-mq-remotefileops\r\n  namespace: na-prod\r\nspec:\r\n  maxReplicas: 4\r\n  minReplicas: 2\r\n  targetCPUUtilizationPercentage: 50\r\n  scaleTargetRef:\r\n    apiVersion: extensions/v1beta1\r\n    kind: Deployment\r\n    name: monolith-mq-remotefileops\r\n```\r\n\r\nThe HPA is logging:\r\n```\r\n2017-10-10T18:46:22Z: the desired replica count is increasing faster than the maximum scale rate\r\n2017-10-10T18:46:22Z: the HPA was able to succesfully calculate a replica count from cpu resource utilization (percentage of request)\r\n2017-10-10T18:46:22Z: the HPA controller was able to update the target scale to 8\r\n2017-10-10T18:47:22Z: the desired replica count was more than the maximum replica count\r\n2017-10-10T18:50:52Z: the time since the previous scale is still within both the downscale and upscale forbidden windows\r\n2017-10-10T18:52:23Z: the HPA controller was able to update the target scale to 4\r\n```\r\n\r\nThis seems to happen with the deployment's spec.resources.request.cpu is low, and the HPA shows the deployment using more than 175% of it's spec.resource.requests.cpu.  If I increase \r\n the deployment's spec.resources.request.cpu to better match actual usage (so that the deployment is using 120% or less), it occurs much less often.\r\n\r\nI deliberately set the spec.resources.request.cpu low, to ensure services were over provisioned during the first roll out of HPA.\r\n\r\nI think the switch in pkg/controller/podautoscaler/horizontal.go after ```scaleUpLimit := calculateScaleUpLimit(currentReplicas)``` should be converted to individual if() statements.\r\n\r\n**Anything else we need to know?**:\r\nI am only setting spec.resource.requests.cpu on the deployment, not spec.resource.limits.cpu\r\n\r\nLooking at the code in pkg/controller/podautoscaler/horizontal.go, the version that worked (1.6.2) would only scale up and down by 1.  The 1.7.6+ code is attempting to scale up by a larger amount.\r\n\r\nThe new code seems appropriate in large clusters, where maxReplicas is in the tens or hundreds.  It doesn't seem appropriate for clusters where maxReplicas is in the single digits.\r\n\r\n\r\n**Environment**:\r\n- Kubernetes version (use `kubectl version`):\r\nClient Version: version.Info{Major:\"1\", Minor:\"7\", GitVersion:\"v1.7.2\", GitCommit:\"922a86cfcd65915a9b2f69f3f193b8907d741d9c\", GitTreeState:\"clean\", BuildDate:\"2017-07-21T19:06:19Z\", GoVersion:\"go1.8.3\", Compiler:\"gc\", Platform:\"darwin/amd64\"}\r\nServer Version: version.Info{Major:\"1\", Minor:\"7\", GitVersion:\"v1.7.6\", GitCommit:\"4bc5e7f9a6c25dc4c03d4d656f2cefd21540e28c\", GitTreeState:\"clean\", BuildDate:\"2017-09-14T06:36:08Z\", GoVersion:\"go1.8.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\r\n\r\n- Cloud provider or hardware configuration**:\r\nAWS m4.2xlarge, 5 nodes\r\n\r\n- OS (e.g. from /etc/os-release):\r\n```\r\nNAME=\"Ubuntu\"\r\nVERSION=\"16.04.2 LTS (Xenial Xerus)\"\r\nID=ubuntu\r\nID_LIKE=debian\r\nPRETTY_NAME=\"Ubuntu 16.04.2 LTS\"\r\nVERSION_ID=\"16.04\"\r\nHOME_URL=\"http://www.ubuntu.com/\"\r\nSUPPORT_URL=\"http://help.ubuntu.com/\"\r\nBUG_REPORT_URL=\"http://bugs.launchpad.net/ubuntu/\"\r\nVERSION_CODENAME=xenial\r\nUBUNTU_CODENAME=xenial\r\n```\r\n\r\n- Kernel (e.g. `uname -a`):\r\n```\r\nLinux ip-10-66-46-241 4.4.0-72-generic #93-Ubuntu SMP Fri Mar 31 14:07:41 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n```\r\n\r\n- Install tools:\r\nkops Version 1.7.0\r\n\r\n- Others:\r\n",
  "closed_at": "2017-10-11T15:53:01Z",
  "closed_by": {
    "avatar_url": "https://avatars0.githubusercontent.com/u/13653959?v=4",
    "events_url": "https://api.github.com/users/k8s-github-robot/events{/privacy}",
    "followers_url": "https://api.github.com/users/k8s-github-robot/followers",
    "following_url": "https://api.github.com/users/k8s-github-robot/following{/other_user}",
    "gists_url": "https://api.github.com/users/k8s-github-robot/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/k8s-github-robot",
    "id": 13653959,
    "login": "k8s-github-robot",
    "node_id": "MDQ6VXNlcjEzNjUzOTU5",
    "organizations_url": "https://api.github.com/users/k8s-github-robot/orgs",
    "received_events_url": "https://api.github.com/users/k8s-github-robot/received_events",
    "repos_url": "https://api.github.com/users/k8s-github-robot/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/k8s-github-robot/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/k8s-github-robot/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/k8s-github-robot"
  },
  "comments": 4,
  "comments_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/53670/comments",
  "created_at": "2017-10-10T18:57:13Z",
  "events_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/53670/events",
  "html_url": "https://github.com/kubernetes/kubernetes/issues/53670",
  "id": 264338881,
  "labels": [
    {
      "color": "e11d21",
      "default": false,
      "description": "Categorizes issue or PR as related to a bug.",
      "id": 105146071,
      "name": "kind/bug",
      "node_id": "MDU6TGFiZWwxMDUxNDYwNzE=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/kind/bug"
    },
    {
      "color": "d2b48c",
      "default": false,
      "description": "Categorizes an issue or PR as relevant to SIG Autoscaling.",
      "id": 238245616,
      "name": "sig/autoscaling",
      "node_id": "MDU6TGFiZWwyMzgyNDU2MTY=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/sig/autoscaling"
    }
  ],
  "labels_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/53670/labels{/name}",
  "locked": false,
  "milestone": null,
  "node_id": "MDU6SXNzdWUyNjQzMzg4ODE=",
  "number": 53670,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/kubernetes/kubernetes",
  "state": "closed",
  "title": "HPA scaling above spec.maxReplicas",
  "updated_at": "2017-10-11T15:53:01Z",
  "url": "https://api.github.com/repos/kubernetes/kubernetes/issues/53670",
  "user": {
    "avatar_url": "https://avatars2.githubusercontent.com/u/62150?v=4",
    "events_url": "https://api.github.com/users/clewis/events{/privacy}",
    "followers_url": "https://api.github.com/users/clewis/followers",
    "following_url": "https://api.github.com/users/clewis/following{/other_user}",
    "gists_url": "https://api.github.com/users/clewis/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/clewis",
    "id": 62150,
    "login": "clewis",
    "node_id": "MDQ6VXNlcjYyMTUw",
    "organizations_url": "https://api.github.com/users/clewis/orgs",
    "received_events_url": "https://api.github.com/users/clewis/received_events",
    "repos_url": "https://api.github.com/users/clewis/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/clewis/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/clewis/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/clewis"
  }
}