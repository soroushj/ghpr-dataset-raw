{
  "active_lock_reason": null,
  "assignee": null,
  "assignees": [],
  "author_association": "MEMBER",
  "body": "For https://gubernator.k8s.io/build/kubernetes-jenkins/logs/ci-kubernetes-e2e-gce-new-master-upgrade-cluster/2572?log#log the cluster upgrade failed.\r\n\r\nLooking at the failure, it seems to be an inopportune restart of apiserver.  The new master comes up, apiserver starts, but then it restarts.  The upgrade test hits it during the restart, it looks like.  Logs: https://storage.googleapis.com/kubernetes-jenkins/logs/ci-kubernetes-e2e-gce-new-master-upgrade-cluster/2572/artifacts/bootstrap-e2e-master/kube-apiserver.log-20181024-1540382414.gz\r\n\r\nThe reason for the apiserver restart was that kube-apiserver failed its liveness probe https://storage.googleapis.com/kubernetes-jenkins/logs/ci-kubernetes-e2e-gce-new-master-upgrade-cluster/2572/artifacts/bootstrap-e2e-master/kubelet.log:\r\n`I1024 05:18:39.900870    1569 kuberuntime_manager.go:565] Container \"kube-apiserver\" ({\"docker\" \"2a1b78c8c811fe0939404eacf2eb815ff787ea636e1b6920fa9186c4b181eb1e\"}) of pod kube-apiserver-bootstrap-e2e-master_kube-system(b13798debb0d0cb04a19e77831d7cf26): Container failed liveness probe.. Container will be killed and recreated.`\r\n\r\nThe liveness probe for api server is hitting :8080, and indeed it was failing its health check (apiserver log again):\r\n\r\n```\r\nI1024 05:18:28.000676       1 wrap.go:42] GET /healthz: (36.143742ms) 500\r\ngoroutine 5739 [running]:\r\nk8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/httplog.(*respLogger).recordStatus(0xc006619180, 0x1f4)\r\n        /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/httplog/httplog.go:204 +0xd2\r\nk8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/httplog.(*respLogger).WriteHeader(0xc006619180, 0x1f4)\r\n        /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/httplog/httplog.go:183 +0x35\r\nk8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/filters.(*baseTimeoutWriter).WriteHeader(0xc0029ef840, 0x1f4)\r\n        /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/filters/timeout.go:197 +0xaf\r\nnet/http.Error(0x7feed9dd2ce8, 0xc0070ebc98, 0xc00cea4000, 0x338, 0x1f4)\r\n        /usr/local/go/src/net/http/server.go:1976 +0xda\r\nk8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/healthz.handleRootHealthz.func1(0x7feed9dd2ce8, 0xc0070ebc98, 0xc00d23fc00)\r\n        /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/healthz/healthz.go:162 +0x3fe\r\nnet/http.HandlerFunc.ServeHTTP(0xc014103880, 0x7feed9dd2ce8, 0xc0070ebc98, 0xc00d23fc00)\r\n        /usr/local/go/src/net/http/server.go:1964 +0x44\r\nk8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/mux.(*pathHandler).ServeHTTP(0xc006eb0d80, 0x7feed9dd2ce8, 0xc0070ebc98, 0xc00d23fc00)\r\n        /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/mux/pathrecorder.go:241 +0x510\r\nk8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/mux.(*PathRecorderMux).ServeHTTP(0xc00a8cef50, 0x7feed9dd2ce8, 0xc0070ebc98, 0xc00d23fc00)\r\n        /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/mux/pathrecorder.go:234 +0x8a\r\nk8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server.director.ServeHTTP(0x3e7a8de, 0xf, 0xc008697170, 0xc00a8cef50, 0x7feed9dd2ce8, 0xc0070ebc98, 0xc00d23fc00)\r\n        /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/handler.go:154 +0x661\r\nk8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filters.WithAuthorization.func1(0x7feed9dd2ce8, 0xc0070ebc98, 0xc00d23fc00)\r\n        /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filters/authorization.go:64 +0x4b4\r\nnet/http.HandlerFunc.ServeHTTP(0xc00a8d3240, 0x7feed9dd2ce8, 0xc0070ebc98, 0xc00d23fc00)\r\n        /usr/local/go/src/net/http/server.go:1964 +0x44\r\nk8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/filters.WithMaxInFlightLimit.func1(0x7feed9dd2ce8, 0xc0070ebc98, 0xc00d23fc00)\r\n        /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/filters/maxinflight.go:160 +0x3ff\r\nnet/http.HandlerFunc.ServeHTTP(0xc0060e7a40, 0x7feed9dd2ce8, 0xc0070ebc98, 0xc00d23fc00)\r\n        /usr/local/go/src/net/http/server.go:1964 +0x44\r\nk8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filters.WithImpersonation.func1(0x7feed9dd2ce8, 0xc0070ebc98, 0xc00d23fc00)\r\n        /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filters/impersonation.go:50 +0x1ed9\r\nnet/http.HandlerFunc.ServeHTTP(0xc00a8d3280, 0x7feed9dd2ce8, 0xc0070ebc98, 0xc00d23fc00)\r\n        /usr/local/go/src/net/http/server.go:1964 +0x44\r\nk8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filters.WithAudit.func1(0x7feed9dd2ce8, 0xc0070ebc98, 0xc00d23fc00)\r\n        /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filters/audit.go:54 +0x645\r\nnet/http.HandlerFunc.ServeHTTP(0xc00a8d32c0, 0x7feed9dd2ce8, 0xc0070ebc98, 0xc00d23fc00)\r\n        /usr/local/go/src/net/http/server.go:1964 +0x44\r\nk8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filters.WithAuthentication.func1(0x7feed9dd2ce8, 0xc0070ebc98, 0xc00d23fb00)\r\n        /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filters/authentication.go:81 +0x456\r\nnet/http.HandlerFunc.ServeHTTP(0xc0042099f0, 0x7feed9dd2ce8, 0xc0070ebc98, 0xc00d23fb00)\r\n        /usr/local/go/src/net/http/server.go:1964 +0x44\r\nk8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/filters.(*timeoutHandler).ServeHTTP.func1(0xc00f040540, 0xc00a91cbe0, 0x5cb0580, 0xc0070ebc98, 0xc00d23fb00)\r\n        /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/filters/timeout.go:100 +0xb3\r\ncreated by k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/filters.(*timeoutHandler).ServeHTTP\r\n        /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/filters/timeout.go:96 +0x1b0\r\n\r\nlogging error output: \"[+]ping ok\\n[+]log ok\\n[+]etcd ok\\n[+]poststarthook/generic-apiserver-start-informers ok\\n[+]poststarthook/start-apiextensions-informers ok\\n[+]poststarthook/start-apiextensions-controllers ok\\n[+]poststarthook/bootstrap-controller ok\\n[-]poststarthook/rbac/bootstrap-roles failed: reason withheld\\n[+]poststarthook/scheduling/bootstrap-system-priority-classes ok\\n[+]poststarthook/ca-registration ok\\n[+]poststarthook/start-kube-apiserver-informers ok\\n[+]poststarthook/start-kube-apiserver-admission-initializer ok\\n[+]poststarthook/start-kube-aggregator-informers ok\\n[+]poststarthook/apiservice-registration-controller ok\\n[+]poststarthook/apiservice-status-available-controller ok\\n[+]poststarthook/apiservice-openapi-controller ok\\n[+]poststarthook/kube-apiserver-autoregistration ok\\n[+]autoregister-completion ok\\nhealthz check failed\\n\"\r\n [curl/7.38.0 35.232.52.86:34956]\r\n```\r\n\r\nI'm guessing this is due to `poststarthook/rbac/bootstrap-roles failed: reason withheld`\r\n\r\nLooking at the next run, I'm hypothesizing that RBAC updates just take too long, and so it's marginal as to whether the bootstrap roles complete in time.\r\n\r\n/sig api-machinery\r\n/kind failing-test\r\n\r\ncc @jberkus ",
  "closed_at": "2018-11-16T11:56:43Z",
  "closed_by": {
    "avatar_url": "https://avatars0.githubusercontent.com/u/20407524?v=4",
    "events_url": "https://api.github.com/users/k8s-ci-robot/events{/privacy}",
    "followers_url": "https://api.github.com/users/k8s-ci-robot/followers",
    "following_url": "https://api.github.com/users/k8s-ci-robot/following{/other_user}",
    "gists_url": "https://api.github.com/users/k8s-ci-robot/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/k8s-ci-robot",
    "id": 20407524,
    "login": "k8s-ci-robot",
    "node_id": "MDQ6VXNlcjIwNDA3NTI0",
    "organizations_url": "https://api.github.com/users/k8s-ci-robot/orgs",
    "received_events_url": "https://api.github.com/users/k8s-ci-robot/received_events",
    "repos_url": "https://api.github.com/users/k8s-ci-robot/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/k8s-ci-robot/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/k8s-ci-robot/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/k8s-ci-robot"
  },
  "comments": 17,
  "comments_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/70305/comments",
  "created_at": "2018-10-26T21:00:27Z",
  "events_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/70305/events",
  "html_url": "https://github.com/kubernetes/kubernetes/issues/70305",
  "id": 374545967,
  "labels": [
    {
      "color": "e11d21",
      "default": false,
      "description": "Categorizes issue or PR as related to a consistently or frequently failing test.",
      "id": 496752468,
      "name": "kind/failing-test",
      "node_id": "MDU6TGFiZWw0OTY3NTI0Njg=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/kind/failing-test"
    },
    {
      "color": "eb6420",
      "default": false,
      "description": "Must be staffed and worked on either currently, or very soon, ideally in time for the next release.",
      "id": 114528223,
      "name": "priority/important-soon",
      "node_id": "MDU6TGFiZWwxMTQ1MjgyMjM=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/priority/important-soon"
    },
    {
      "color": "d2b48c",
      "default": false,
      "description": "Categorizes an issue or PR as relevant to SIG API Machinery.",
      "id": 173493835,
      "name": "sig/api-machinery",
      "node_id": "MDU6TGFiZWwxNzM0OTM4MzU=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/sig/api-machinery"
    }
  ],
  "labels_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/70305/labels{/name}",
  "locked": false,
  "milestone": {
    "closed_at": "2020-08-23T05:01:14Z",
    "closed_issues": 462,
    "created_at": "2017-11-15T06:32:59Z",
    "creator": {
      "avatar_url": "https://avatars0.githubusercontent.com/u/5595220?v=4",
      "events_url": "https://api.github.com/users/thockin/events{/privacy}",
      "followers_url": "https://api.github.com/users/thockin/followers",
      "following_url": "https://api.github.com/users/thockin/following{/other_user}",
      "gists_url": "https://api.github.com/users/thockin/gists{/gist_id}",
      "gravatar_id": "",
      "html_url": "https://github.com/thockin",
      "id": 5595220,
      "login": "thockin",
      "node_id": "MDQ6VXNlcjU1OTUyMjA=",
      "organizations_url": "https://api.github.com/users/thockin/orgs",
      "received_events_url": "https://api.github.com/users/thockin/received_events",
      "repos_url": "https://api.github.com/users/thockin/repos",
      "site_admin": false,
      "starred_url": "https://api.github.com/users/thockin/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/thockin/subscriptions",
      "type": "User",
      "url": "https://api.github.com/users/thockin"
    },
    "description": "",
    "due_on": null,
    "html_url": "https://github.com/kubernetes/kubernetes/milestone/40",
    "id": 2913713,
    "labels_url": "https://api.github.com/repos/kubernetes/kubernetes/milestones/40/labels",
    "node_id": "MDk6TWlsZXN0b25lMjkxMzcxMw==",
    "number": 40,
    "open_issues": 0,
    "state": "closed",
    "title": "v1.13",
    "updated_at": "2020-08-23T05:01:14Z",
    "url": "https://api.github.com/repos/kubernetes/kubernetes/milestones/40"
  },
  "node_id": "MDU6SXNzdWUzNzQ1NDU5Njc=",
  "number": 70305,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/kubernetes/kubernetes",
  "state": "closed",
  "title": "kube-apiserver restarted on boot, caused flake",
  "updated_at": "2018-11-16T11:56:43Z",
  "url": "https://api.github.com/repos/kubernetes/kubernetes/issues/70305",
  "user": {
    "avatar_url": "https://avatars2.githubusercontent.com/u/100893?v=4",
    "events_url": "https://api.github.com/users/justinsb/events{/privacy}",
    "followers_url": "https://api.github.com/users/justinsb/followers",
    "following_url": "https://api.github.com/users/justinsb/following{/other_user}",
    "gists_url": "https://api.github.com/users/justinsb/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/justinsb",
    "id": 100893,
    "login": "justinsb",
    "node_id": "MDQ6VXNlcjEwMDg5Mw==",
    "organizations_url": "https://api.github.com/users/justinsb/orgs",
    "received_events_url": "https://api.github.com/users/justinsb/received_events",
    "repos_url": "https://api.github.com/users/justinsb/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/justinsb/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/justinsb/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/justinsb"
  }
}