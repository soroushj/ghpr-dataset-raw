{
  "active_lock_reason": null,
  "assignee": null,
  "assignees": [],
  "author_association": "MEMBER",
  "body": "**Is this a BUG REPORT or FEATURE REQUEST?**:\r\n\r\n/kind bug\r\n\r\n**What happened**:\r\n\r\nRan Kubernetes 1.8 apiserver for 3 days and the memory usage kept going up.\r\n\r\n![screenshot from 2017-10-05 10-12-19](https://user-images.githubusercontent.com/4546722/31216977-bb57bd00-a9b5-11e7-989f-0b4ee9b53133.png)\r\n\r\nLooking at a heap profile showed, that the majority of this memory is coming from the [`cache.NewNamedReflector`](https://github.com/kubernetes/client-go/blob/82aa063804cf055e16e8911250f888bc216e8b61/tools/cache/reflector.go#L107) function, or more specifically, the [metrics being instantiated in it](https://github.com/kubernetes/client-go/blob/82aa063804cf055e16e8911250f888bc216e8b61/tools/cache/reflector.go#L112).\r\n\r\n[pprof.hyperkube.alloc_objects.alloc_space.inuse_objects.inuse_space.003.pb.gz](https://github.com/kubernetes/kubernetes/files/1358504/pprof.hyperkube.alloc_objects.alloc_space.inuse_objects.inuse_space.003.pb.gz)\r\n\r\nI validated that this is indeed coming from metrics by checking the amount of metrics exposed by the `/metrics` endpoint.\r\n\r\n```\r\n$ curl localhost:8001/metrics | wc -l\r\n49966\r\n```\r\n\r\nIn an equivalent workload cluster running Kubernetes `v1.7.5`, this number is round `3000`.\r\n\r\nSo I took a look and noticed, that the majority of these metrics are actually coming from reflectors of CRD resources. Around 15000 of those metrics are each related to one of the three CRDs installed in the cluster. The total number of metrics increases by ~50 every few minutes.\r\n\r\nI feel this might be happening whenever the cache in the Prometheus Operator (the controller for the CRDs existing in this cluster) is hitting its resync interval for a particular resource, so this might be happening on either opening a watch and or listing the resources, but this is just a wild guess.\r\n\r\nThe metrics in the `NewNamedReflector` function should be injected instead of re-created and registered on the global metrics registry, but the fact that the apiserver keeps creating new reflectors for these resources is likely also a problem.\r\n\r\nAnother problem I've been noticing, starting approximately at the same time as this, is that the apiserver API latencies have increased significantly.\r\n\r\n**What you expected to happen**:\r\n\r\nUnique metrics for each type of reflector, not causing a memory leak.\r\n\r\n**How to reproduce it (as minimally and precisely as possible)**:\r\n\r\nThe cluster was setup using bootkube, but recently upgraded to 1.8 (3 days ago), and the Prometheus Operator running on it with the [`kube-prometheus`](https://github.com/coreos/prometheus-operator/tree/master/contrib/kube-prometheus) stack deployed.\r\n\r\n**Anything else we need to know?**:\r\n\r\n**Environment**: bootkube / bare metal\r\n- Kubernetes version (use `kubectl version`): 1.8\r\n- Cloud provider or hardware configuration**:\r\n- OS (e.g. from /etc/os-release): CoreOS Container Linux\r\n- Kernel (e.g. `uname -a`): Linux sd-99796 4.12.14-coreos #1 SMP Wed Sep 20 22:20:05 UTC 2017 x86_64\r\n- Install tools: bootkube\r\n- Others:\r\n\r\n@sig-instrumentation-bugs @kubernetes/sig-api-machinery-bugs \r\n\r\n/cc @sttts @nikhita I know you recently worked on the CRD code, so you may know why there are new reflectors being created constantly.",
  "closed_at": "2017-10-13T12:09:43Z",
  "closed_by": {
    "avatar_url": "https://avatars0.githubusercontent.com/u/13653959?v=4",
    "events_url": "https://api.github.com/users/k8s-github-robot/events{/privacy}",
    "followers_url": "https://api.github.com/users/k8s-github-robot/followers",
    "following_url": "https://api.github.com/users/k8s-github-robot/following{/other_user}",
    "gists_url": "https://api.github.com/users/k8s-github-robot/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/k8s-github-robot",
    "id": 13653959,
    "login": "k8s-github-robot",
    "node_id": "MDQ6VXNlcjEzNjUzOTU5",
    "organizations_url": "https://api.github.com/users/k8s-github-robot/orgs",
    "received_events_url": "https://api.github.com/users/k8s-github-robot/received_events",
    "repos_url": "https://api.github.com/users/k8s-github-robot/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/k8s-github-robot/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/k8s-github-robot/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/k8s-github-robot"
  },
  "comments": 12,
  "comments_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/53485/comments",
  "created_at": "2017-10-05T08:40:42Z",
  "events_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/53485/events",
  "html_url": "https://github.com/kubernetes/kubernetes/issues/53485",
  "id": 263045456,
  "labels": [
    {
      "color": "e11d21",
      "default": false,
      "description": "Categorizes issue or PR as related to a bug.",
      "id": 105146071,
      "name": "kind/bug",
      "node_id": "MDU6TGFiZWwxMDUxNDYwNzE=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/kind/bug"
    },
    {
      "color": "eb6420",
      "default": false,
      "description": "Must be staffed and worked on either currently, or very soon, ideally in time for the next release.",
      "id": 114528223,
      "name": "priority/important-soon",
      "node_id": "MDU6TGFiZWwxMTQ1MjgyMjM=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/priority/important-soon"
    },
    {
      "color": "d2b48c",
      "default": false,
      "description": "Categorizes an issue or PR as relevant to SIG API Machinery.",
      "id": 173493835,
      "name": "sig/api-machinery",
      "node_id": "MDU6TGFiZWwxNzM0OTM4MzU=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/sig/api-machinery"
    },
    {
      "color": "d2b48c",
      "default": false,
      "description": "Categorizes an issue or PR as relevant to SIG Scalability.",
      "id": 125010198,
      "name": "sig/scalability",
      "node_id": "MDU6TGFiZWwxMjUwMTAxOTg=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/sig/scalability"
    }
  ],
  "labels_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/53485/labels{/name}",
  "locked": false,
  "milestone": null,
  "node_id": "MDU6SXNzdWUyNjMwNDU0NTY=",
  "number": 53485,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/kubernetes/kubernetes",
  "state": "closed",
  "title": "Leaking reflector metrics in 1.8",
  "updated_at": "2017-10-31T11:36:58Z",
  "url": "https://api.github.com/repos/kubernetes/kubernetes/issues/53485",
  "user": {
    "avatar_url": "https://avatars3.githubusercontent.com/u/4546722?v=4",
    "events_url": "https://api.github.com/users/brancz/events{/privacy}",
    "followers_url": "https://api.github.com/users/brancz/followers",
    "following_url": "https://api.github.com/users/brancz/following{/other_user}",
    "gists_url": "https://api.github.com/users/brancz/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/brancz",
    "id": 4546722,
    "login": "brancz",
    "node_id": "MDQ6VXNlcjQ1NDY3MjI=",
    "organizations_url": "https://api.github.com/users/brancz/orgs",
    "received_events_url": "https://api.github.com/users/brancz/received_events",
    "repos_url": "https://api.github.com/users/brancz/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/brancz/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/brancz/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/brancz"
  }
}