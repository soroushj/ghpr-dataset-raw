{
  "active_lock_reason": null,
  "assignee": null,
  "assignees": [],
  "author_association": "CONTRIBUTOR",
  "body": "**What keywords did you search in Kubernetes issues before filing this one?** \r\nrkt netns\r\n\r\n---\r\n\r\n**Is this a BUG REPORT**\r\n\r\n<!--\r\nIf this is a BUG REPORT, please:\r\n  - Fill in as much of the template below as you can.  If you leave out\r\n    information, we can't help you as well.\r\n\r\n-->\r\n\r\n**Kubernetes version**:\r\n1.5, 1.6, master\r\n\r\n**Environment**:\r\n- **OS** (e.g. from /etc/os-release):\r\n```\r\ncat /etc/os-release \r\nNAME=\"Container Linux by CoreOS\"\r\nID=coreos\r\nVERSION=1298.6.0\r\nVERSION_ID=1298.6.0\r\nBUILD_ID=2017-03-14-2119\r\n```\r\n- **Kernel** (e.g. `uname -a`):\r\n```\r\nuname -a\r\nLinux no-1-172-20-0-13 4.9.9-coreos-r1 #1 SMP Tue Mar 14 21:09:42 UTC 2017 x86_64 Westmere E56xx/L56xx/X56xx (Nehalem-C) GenuineIntel GNU/Linux\r\n```\r\n- **Install tools**:\r\n```\r\n/opt/bin/rkt version\r\nrkt Version: 1.25.0\r\nappc Version: 0.8.10\r\nGo Version: go1.7.4\r\nGo OS/Arch: linux/amd64\r\nFeatures: -TPM +SDJOURNAL\r\n```\r\nCNI 0.5.2\r\n- **Others**:\r\n\r\nKubelet setup:\r\n```\r\nsystemctl cat kubelet\r\n# /etc/systemd/system/kubelet.service\r\n[Unit]\r\nAfter=rkt-api.service\r\nRequires=rkt-api.service\r\nAfter=kube-apiserver.service\r\n[Service]\r\nExecStartPre=/bin/ls -l \\\r\n  /etc/vault.d/kubernetes/kubelet.certificate \\\r\n  /etc/vault.d/kubernetes/kubelet.private_key \\\r\n  /etc/vault.d/kubernetes/kubelet.issuing_ca\r\nExecStartPre=/bin/mkdir -pv /var/lib/kubelet/kubeconfig\r\nExecStart=/opt/rootfs/hyperkube kubelet \\\r\n  --hairpin-mode=none \\\r\n  --network-plugin=cni \\\r\n  --cni-bin-dir=/opt/rootfs/usr/bin \\\r\n  --cni-conf-dir=/etc/rkt/net.d \\\r\n  --hostname-override=172.20.0.13 \\\r\n  --node-ip=172.20.0.13 \\\r\n  --register-schedulable=false \\\r\n  --allow-privileged=true \\\r\n  --enable-custom-metrics \\\r\n  --api-servers=http://127.0.0.1:8080 \\\r\n  --node-labels=node=true \\\r\n  --cloud-provider=\"\" \\\r\n  --container-runtime=rkt \\\r\n  --rkt-path=/opt/rootfs/usr/bin/rkt \\\r\n  --v=2 \\\r\n  --enable-cri=false \\\r\n  --tls-cert-file=/etc/vault.d/kubernetes/kubelet.certificate \\\r\n  --tls-private-key-file=/etc/vault.d/kubernetes/kubelet.private_key \\\r\n  --client-ca-file=/etc/vault.d/kubernetes/kubelet.issuing_ca\r\nRestart=always\r\nRestartSec=5s\r\n[Install]\r\nWantedBy=multi-user.target\r\n```\r\nThe CNI configuration:\r\n```\r\ncat /etc/rkt/net.d/10-k8s.conf \r\n{\r\n  \"name\": \"bond0\",\r\n  \"type\": \"macvlan\",\r\n  \"master\": \"bond0\",\r\n  \"ipam\": {\"dataDir\": \"/run/cni-ipam\", \"gateway\": \"172.20.0.1\", \"rangeEnd\": \"172.20.13.254\", \"rangeStart\": \"172.20.13.1\", \"routes\": [{\"dst\": \"0.0.0.0/0\"}], \"subnet\": \"172.20.0.0/16\", \"type\": \"host-local\"}\r\n}\r\n```\r\n\r\n**What happened**:\r\n\r\nIf running Pod with `hostNetwork: false` is failing, the pod restarts immediatly and looses its IP address after the garbage collection.\r\n\r\n\r\n**What you expected to happen**:\r\nThe Pod keeps the new IP address\r\n\r\n**How to reproduce it** (as minimally and precisely as possible):\r\nStart a rkt api-service and a kubelet without kube-apiserver like:\r\n```\r\ngo/src/k8s.io/kubernetes/_output/bin/kubelet \\\r\n--network-plugin=cni \\\r\n--cni-bin-dir=/opt/bin/cni \\\r\n--cni-conf-dir=/etc/rkt/net.d \\\r\n--pod-manifest-path=$PATHTO/kube-sandbox/manifests \\\r\n--register-schedulable=false \\\r\n--enable-server=false \\\r\n--register-node=false \\\r\n--cloud-provider=\"\" \\\r\n--enable-cri=false  \\\r\n--container-runtime=rkt \\\r\n--rkt-path=/usr/bin/rkt \\\r\n--v=4\r\n```\r\nWith a simple Pod in the `$PATHTO/kube-sandbox/manifests`:\r\n```\r\ncat manifests/debian.yaml \r\napiVersion: v1\r\nkind: Pod\r\nmetadata:\r\n  name: debian\r\n  namespace: default\r\nspec:\r\n  containers:\r\n  - name: debian\r\n    image: enjoliver.local/debian:latest\r\n    imagePullPolicy: IfNotPresent\r\n    command:\r\n    - /dgr/bin/busybox\r\n    - httpd\r\n    - -fv\r\n\r\n```\r\nLeads you to the following scenario:\r\n```\r\n# rkt l\r\nUUID\t\tAPP\tIMAGE NAME\t\t\tSTATE\tCREATED\t\tSTARTED\t\tNETWORKS\r\n29b7d7e3\tdebian\tenjoliver.local/debian:latest\trunning\t6 seconds ago\t5 seconds ago\t\r\n# rkt l\r\nUUID\t\tAPP\tIMAGE NAME\t\t\tSTATE\tCREATED\t\tSTARTED\t\tNETWORKS\r\n29b7d7e3\tdebian\tenjoliver.local/debian:latest\trunning\t18 seconds ago\t17 seconds ago\t\r\n# rkt enter 29b7d7e3 /dgr/bin/busybox ip a\r\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue qlen 1\r\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\r\n    inet 127.0.0.1/8 scope host lo\r\n       valid_lft forever preferred_lft forever\r\n    inet6 ::1/128 scope host \r\n       valid_lft forever preferred_lft forever\r\n3: eth0@if51: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue \r\n    link/ether 0a:58:ac:14:00:4e brd ff:ff:ff:ff:ff:ff\r\n    inet 172.20.0.78/16 scope global eth0\r\n       valid_lft forever preferred_lft forever\r\n    inet6 fe80::b46f:3ff:fe06:933b/64 scope link \r\n       valid_lft forever preferred_lft forever\r\n# ping -c 1 172.20.0.78\r\nPING 172.20.0.78 (172.20.0.78) 56(84) bytes of data.\r\n64 bytes from 172.20.0.78: icmp_seq=1 ttl=64 time=0.110 ms\r\n\r\n--- 172.20.0.78 ping statistics ---\r\n1 packets transmitted, 1 received, 0% packet loss, time 0ms\r\nrtt min/avg/max/mdev = 0.110/0.110/0.110/0.000 ms\r\n# rkt stop 29b7d7e3 ; sleep 1 ; rkt l\r\n\"29b7d7e3-eb8f-42b4-9962-56610e2380cc\"\r\nUUID\t\tAPP\tIMAGE NAME\t\t\tSTATE\tCREATED\t\tSTARTED\t\tNETWORKS\r\n29b7d7e3\tdebian\tenjoliver.local/debian:latest\texited\t1 minute ago\t1 minute ago\t\r\n2f8b2db0\tdebian\tenjoliver.local/debian:latest\trunning\tnow\t\tnow\t\t\r\n# rkt enter 2f8b2db0 /dgr/bin/busybox ip a\r\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue qlen 1\r\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\r\n    inet 127.0.0.1/8 scope host lo\r\n       valid_lft forever preferred_lft forever\r\n    inet6 ::1/128 scope host \r\n       valid_lft forever preferred_lft forever\r\n3: eth0@if52: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue \r\n    link/ether 0a:58:ac:14:00:4f brd ff:ff:ff:ff:ff:ff\r\n    inet 172.20.0.79/16 scope global eth0\r\n       valid_lft forever preferred_lft forever\r\n    inet6 fe80::fc41:21ff:fe76:d567/64 scope link \r\n       valid_lft forever preferred_lft forever\r\n# rkt l\r\nUUID\t\tAPP\tIMAGE NAME\t\t\tSTATE\tCREATED\t\tSTARTED\t\tNETWORKS\r\n2f8b2db0\tdebian\tenjoliver.local/debian:latest\trunning\t1 minute ago\t1 minute ago\t\r\n# rkt enter 2f8b2db0 /dgr/bin/busybox ip a\r\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue qlen 1\r\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\r\n    inet 127.0.0.1/8 scope host lo\r\n       valid_lft forever preferred_lft forever\r\n    inet6 ::1/128 scope host \r\n       valid_lft forever preferred_lft forever\r\n# ip netns list | wc -l\r\n0\r\n```\r\n\r\n\r\n**Anything else we need to know**:\r\nThis is because the Kubernetes Pod with rkt is running inside an unique [netns](https://github.com/kubernetes/kubernetes/blob/a8e940041e242a67ab976e8f464bb6fb61c251fe/pkg/kubelet/rkt/rkt.go#L1290) linked to the `Pod.id`, also documented [here](https://github.com/kubernetes/kubernetes/blob/a8e940041e242a67ab976e8f464bb6fb61c251fe/pkg/kubelet/rkt/rkt.go#L1851-L1855)\r\n\r\nWhen a Pod restarts, it keeps the same network namespace so the garbage collection will clean the old network ressources and the current ones.\r\nIf you setup a Kubernetes Probe like a httpGet, you'll get an endless restarting Pod.\r\n\r\nI'm working on it and want to refer this issue in code comments / PR.\r\n",
  "closed_at": "2017-05-09T22:07:34Z",
  "closed_by": {
    "avatar_url": "https://avatars0.githubusercontent.com/u/13653959?v=4",
    "events_url": "https://api.github.com/users/k8s-github-robot/events{/privacy}",
    "followers_url": "https://api.github.com/users/k8s-github-robot/followers",
    "following_url": "https://api.github.com/users/k8s-github-robot/following{/other_user}",
    "gists_url": "https://api.github.com/users/k8s-github-robot/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/k8s-github-robot",
    "id": 13653959,
    "login": "k8s-github-robot",
    "node_id": "MDQ6VXNlcjEzNjUzOTU5",
    "organizations_url": "https://api.github.com/users/k8s-github-robot/orgs",
    "received_events_url": "https://api.github.com/users/k8s-github-robot/received_events",
    "repos_url": "https://api.github.com/users/k8s-github-robot/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/k8s-github-robot/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/k8s-github-robot/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/k8s-github-robot"
  },
  "comments": 0,
  "comments_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/45149/comments",
  "created_at": "2017-04-29T19:10:04Z",
  "events_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/45149/events",
  "html_url": "https://github.com/kubernetes/kubernetes/issues/45149",
  "id": 225278502,
  "labels": [
    {
      "color": "0052cc",
      "default": false,
      "description": null,
      "id": 203010486,
      "name": "area/rkt",
      "node_id": "MDU6TGFiZWwyMDMwMTA0ODY=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/area/rkt"
    }
  ],
  "labels_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/45149/labels{/name}",
  "locked": false,
  "milestone": null,
  "node_id": "MDU6SXNzdWUyMjUyNzg1MDI=",
  "number": 45149,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/kubernetes/kubernetes",
  "state": "closed",
  "title": "rkt Pod looses the network",
  "updated_at": "2017-05-09T22:07:34Z",
  "url": "https://api.github.com/repos/kubernetes/kubernetes/issues/45149",
  "user": {
    "avatar_url": "https://avatars2.githubusercontent.com/u/8077192?v=4",
    "events_url": "https://api.github.com/users/JulienBalestra/events{/privacy}",
    "followers_url": "https://api.github.com/users/JulienBalestra/followers",
    "following_url": "https://api.github.com/users/JulienBalestra/following{/other_user}",
    "gists_url": "https://api.github.com/users/JulienBalestra/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/JulienBalestra",
    "id": 8077192,
    "login": "JulienBalestra",
    "node_id": "MDQ6VXNlcjgwNzcxOTI=",
    "organizations_url": "https://api.github.com/users/JulienBalestra/orgs",
    "received_events_url": "https://api.github.com/users/JulienBalestra/received_events",
    "repos_url": "https://api.github.com/users/JulienBalestra/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/JulienBalestra/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/JulienBalestra/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/JulienBalestra"
  }
}