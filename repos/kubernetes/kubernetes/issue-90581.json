{
  "active_lock_reason": null,
  "assignee": null,
  "assignees": [],
  "author_association": "CONTRIBUTOR",
  "body": "<!-- Please use this template while reporting a bug and provide as much info as possible. Not doing so may result in your bug not being addressed in a timely manner. Thanks!\r\n\r\nIf the matter is security related, please disclose it privately via https://kubernetes.io/security/\r\n-->\r\n\r\n\r\n**What happened**:\r\nRace conditions found on 2 usages of sync.Cond in client-go/tools/cache.DeltaFIFO and client-go/tools/watch/eventProcessor.  I don't know how harmful they are since the buggy interleaving is hard to trigger. They may lead to goroutine leaks to my understanding. They have similar causes and I put them in one issue here for ease of triage. \r\n\r\n1. DeltaFIFO\r\n\r\nWhen `(*DeltaFIFO).Pop()` and `(*DeltaFIFO).Close()` are invoked concurrently on an empty queue, the `f.cond.Wait()` in `(*DeltaFIFO).Pop()` may miss the signal from `(*DeltaFIFO).Close()`.\r\n\r\nThe `f.cond.Wait()` is guarded by the for-loop below. It appears that `f.cond.Wait()` should not be called if the FIFO queue is already closed, hence the `f.IsClosed()` check at line 475.\r\n\r\nhttps://github.com/kubernetes/kubernetes/blob/961a5ed144cf0f2f4e2d858beb8cc0cfdd822c1b/staging/src/k8s.io/client-go/tools/cache/delta_fifo.go#L467-L480\r\n\r\nHowever, the `f.IsClosed()` check above may race with `f.Close()`:\r\n\r\nhttps://github.com/kubernetes/kubernetes/blob/961a5ed144cf0f2f4e2d858beb8cc0cfdd822c1b/staging/src/k8s.io/client-go/tools/cache/delta_fifo.go#L206-L211\r\n\r\nSpecifically, when the queue is empty and not closed, `f.Pop()` will reach the `f.cond.Wait()`. Between the `f.IsClosed()` check and `f.cond.Wait()`, another goroutine can call `f.Close()` and the broadcast on `f.cond` will be missed. Consequently, `f.cond.Wait()` may block indefinintely and miss the broadcast on `f.cond` from `f.Close()`.\r\n\r\nNote that `f.Pop()` holds `f.lock` while `f.Close()` and `f.IsClosed()` hold `f.closedLock`. So `f.Close()` can interleave with `f.Pop()`.\r\n\r\nHere is a stack trace found by our tool while running `TestMetadataSharedInformerFactory`. The tool is based on the Go race detector.\r\n```\r\n(*sync.Cond).Broadcast/Signal() at 0x00c00009c028 by goroutine 17:\r\n  k8s.io/client-go/tools/cache.(*DeltaFIFO).Close()\r\n      /Users/yahuis/lab/go-exp/kubernetes/staging/src/k8s.io/client-go/tools/cache/delta_fifo.go:210 +0xa8\r\n  k8s.io/client-go/tools/cache.(*controller).Run.func1()\r\n      /Users/yahuis/lab/go-exp/kubernetes/staging/src/k8s.io/client-go/tools/cache/controller.go:128 +0x67\r\n\r\n(*sync.Cond).Wait() at 0x00c00009c028 by goroutine 10:\r\n  k8s.io/client-go/tools/cache.(*DeltaFIFO).Pop()\r\n      /Users/yahuis/lab/go-exp/kubernetes/staging/src/k8s.io/client-go/tools/cache/delta_fifo.go:479 +0xbc\r\n  k8s.io/client-go/tools/cache.(*controller).processLoop()\r\n      /Users/yahuis/lab/go-exp/kubernetes/staging/src/k8s.io/client-go/tools/cache/controller.go:179 +0x83\r\n  k8s.io/client-go/tools/cache.(*controller).processLoop-fm()\r\n      /Users/yahuis/lab/go-exp/kubernetes/staging/src/k8s.io/client-go/tools/cache/controller.go:177 +0x41\r\n  k8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1()\r\n      /Users/yahuis/lab/go-exp/kubernetes/staging/src/k8s.io/apimachinery/pkg/util/wait/wait.go:155 +0x75\r\n  k8s.io/apimachinery/pkg/util/wait.BackoffUntil()\r\n      /Users/yahuis/lab/go-exp/kubernetes/staging/src/k8s.io/apimachinery/pkg/util/wait/wait.go:156 +0xb3\r\n  k8s.io/apimachinery/pkg/util/wait.JitterUntil()\r\n      /Users/yahuis/lab/go-exp/kubernetes/staging/src/k8s.io/apimachinery/pkg/util/wait/wait.go:133 +0x10d\r\n  k8s.io/apimachinery/pkg/util/wait.Until()\r\n      /Users/yahuis/lab/go-exp/kubernetes/staging/src/k8s.io/apimachinery/pkg/util/wait/wait.go:90 +0x4cc\r\n  k8s.io/client-go/tools/cache.(*sharedIndexInformer).Run()\r\n      /Users/yahuis/lab/go-exp/kubernetes/staging/src/k8s.io/client-go/tools/cache/shared_informer.go:410 +0x7b1\r\n\r\nGoroutine 17 (running) created at:\r\n  k8s.io/client-go/tools/cache.(*controller).Run()\r\n      /Users/yahuis/lab/go-exp/kubernetes/staging/src/k8s.io/client-go/tools/cache/controller.go:126 +0xbe\r\n  k8s.io/client-go/tools/cache.(*sharedIndexInformer).Run()\r\n      /Users/yahuis/lab/go-exp/kubernetes/staging/src/k8s.io/client-go/tools/cache/shared_informer.go:410 +0x7b1\r\n\r\nGoroutine 10 (running) created at:\r\n  k8s.io/client-go/metadata/metadatainformer.(*metadataSharedInformerFactory).Start()\r\n      /Users/yahuis/lab/go-exp/kubernetes/staging/src/k8s.io/client-go/metadata/metadatainformer/informer.go:90 +0x282\r\n  k8s.io/client-go/metadata/metadatainformer.TestMetadataSharedInformerFactory.func7()\r\n      /Users/yahuis/lab/go-exp/kubernetes/staging/src/k8s.io/client-go/metadata/metadatainformer/informer_test.go:141 +0x718\r\n  testing.tRunner()\r\n      /Users/yahuis/lab/go-exp/go/src/testing/testing.go:954 +0x1eb\r\n```\r\n\r\nI did some research and found #37137 introduced the bug while trying to fix exactly the issue: \"stop controller when the stop channel is closed and the queue is empty\". The fix doesn't appear to solve the issue completely.\r\n\r\nOne suggested fix: use `f.lock` in `f.Close()` and `f.IsClosed()` instead of `f.closedLock`. This would enforce atomicity between the `f.IsClosed()` check and `f.cond.Wait()` in `f.Pop()`.\r\n\r\n2. eventProcessor\r\n\r\nThis is similar to DeltaFIFO. In between `!e.stopped()` and `e.cond.Wait()`:\r\n\r\nhttps://github.com/kubernetes/kubernetes/blob/961a5ed144cf0f2f4e2d858beb8cc0cfdd822c1b/staging/src/k8s.io/client-go/tools/watch/informerwatcher.go#L59-L65\r\n\r\nAnother goroutine can call `e.stop()`:\r\n\r\nhttps://github.com/kubernetes/kubernetes/blob/961a5ed144cf0f2f4e2d858beb8cc0cfdd822c1b/staging/src/k8s.io/client-go/tools/watch/informerwatcher.go#L98-L101\r\n\r\nThis would cause the signal on `e.cond` to be missed by the above `e.cond.Wait()`, leading to the goroutine being blocked unexpectedly.\r\n\r\nStack trace from `TestRotateCertWaitingForResultError`:\r\n```\r\n(*sync.Cond).Broadcast/Signal() at 0x00c000355410 by goroutine 33:\r\n  k8s.io/client-go/tools/watch.(*eventProcessor).stop()\r\n      /Users/yahuis/lab/go-exp/kubernetes/staging/src/k8s.io/client-go/tools/watch/informerwatcher.go:100 +0x74\r\n  k8s.io/client-go/tools/watch.NewIndexerInformerWatcher.func4()\r\n      /Users/yahuis/lab/go-exp/kubernetes/staging/src/k8s.io/client-go/tools/watch/informerwatcher.go:147 +0xef\r\n\r\n(*sync.Cond).Wait() at 0x00c000355410 by goroutine 32:\r\n  k8s.io/client-go/tools/watch.(*eventProcessor).takeBatch()\r\n      /Users/yahuis/lab/go-exp/kubernetes/staging/src/k8s.io/client-go/tools/watch/informerwatcher.go:64 +0x142\r\n  k8s.io/client-go/tools/watch.(*eventProcessor).run()\r\n      /Users/yahuis/lab/go-exp/kubernetes/staging/src/k8s.io/client-go/tools/watch/informerwatcher.go:51 +0x38\r\n\r\nGoroutine 33 (running) created at:\r\n  k8s.io/client-go/tools/watch.NewIndexerInformerWatcher()\r\n      /Users/yahuis/lab/go-exp/kubernetes/staging/src/k8s.io/client-go/tools/watch/informerwatcher.go:143 +0x5ec\r\n  k8s.io/client-go/tools/watch.UntilWithSync()\r\n      /Users/yahuis/lab/go-exp/kubernetes/staging/src/k8s.io/client-go/tools/watch/until.go:130 +0x91\r\n  k8s.io/client-go/util/certificate/csr.WaitForCertificate()\r\n      /Users/yahuis/lab/go-exp/kubernetes/staging/src/k8s.io/client-go/util/certificate/csr/csr.go:98 +0x462\r\n  k8s.io/client-go/util/certificate.(*manager).rotateCerts()\r\n      /Users/yahuis/lab/go-exp/kubernetes/staging/src/k8s.io/client-go/util/certificate/certificate_manager.go:449 +0x73d\r\n  k8s.io/client-go/util/certificate.TestRotateCertWaitingForResultError()\r\n      /Users/yahuis/lab/go-exp/kubernetes/staging/src/k8s.io/client-go/util/certificate/certificate_manager_test.go:501 +0x4a0\r\n  testing.tRunner()\r\n      /Users/yahuis/lab/go-exp/go/src/testing/testing.go:954 +0x1eb\r\n\r\nGoroutine 32 (running) created at:\r\n  k8s.io/client-go/tools/watch.NewIndexerInformerWatcher()\r\n      /Users/yahuis/lab/go-exp/kubernetes/staging/src/k8s.io/client-go/tools/watch/informerwatcher.go:140 +0x580\r\n  k8s.io/client-go/tools/watch.UntilWithSync()\r\n      /Users/yahuis/lab/go-exp/kubernetes/staging/src/k8s.io/client-go/tools/watch/until.go:130 +0x91\r\n  k8s.io/client-go/util/certificate/csr.WaitForCertificate()\r\n      /Users/yahuis/lab/go-exp/kubernetes/staging/src/k8s.io/client-go/util/certificate/csr/csr.go:98 +0x462\r\n  k8s.io/client-go/util/certificate.(*manager).rotateCerts()\r\n      /Users/yahuis/lab/go-exp/kubernetes/staging/src/k8s.io/client-go/util/certificate/certificate_manager.go:449 +0x73d\r\n  k8s.io/client-go/util/certificate.TestRotateCertWaitingForResultError()\r\n      /Users/yahuis/lab/go-exp/kubernetes/staging/src/k8s.io/client-go/util/certificate/certificate_manager_test.go:501 +0x4a0\r\n  testing.tRunner()\r\n      /Users/yahuis/lab/go-exp/go/src/testing/testing.go:954 +0x1eb\r\n```\r\n\r\nOne suggested fix: use mutex to protect `close(e.done)` in `(*eventProcessor).stop()`.\r\n\r\n**What you expected to happen**:\r\n\r\nNo race condition.\r\n\r\n**How to reproduce it (as minimally and precisely as possible)**:\r\n\r\n**Anything else we need to know?**:\r\n\r\n**Environment**:\r\n- Kubernetes version (use `kubectl version`):\r\n- Cloud provider or hardware configuration:\r\n- OS (e.g: `cat /etc/os-release`): MacOS\r\n- Kernel (e.g. `uname -a`): Darwin\r\n- Install tools:\r\n- Network plugin and version (if this is a network-related bug):\r\n- Others:\r\n\r\nThis is my first issue filed. Please let me know if I can provide further information.",
  "closed_at": "2020-05-20T06:40:33Z",
  "closed_by": {
    "avatar_url": "https://avatars0.githubusercontent.com/u/20407524?v=4",
    "events_url": "https://api.github.com/users/k8s-ci-robot/events{/privacy}",
    "followers_url": "https://api.github.com/users/k8s-ci-robot/followers",
    "following_url": "https://api.github.com/users/k8s-ci-robot/following{/other_user}",
    "gists_url": "https://api.github.com/users/k8s-ci-robot/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/k8s-ci-robot",
    "id": 20407524,
    "login": "k8s-ci-robot",
    "node_id": "MDQ6VXNlcjIwNDA3NTI0",
    "organizations_url": "https://api.github.com/users/k8s-ci-robot/orgs",
    "received_events_url": "https://api.github.com/users/k8s-ci-robot/received_events",
    "repos_url": "https://api.github.com/users/k8s-ci-robot/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/k8s-ci-robot/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/k8s-ci-robot/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/k8s-ci-robot"
  },
  "comments": 5,
  "comments_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/90581/comments",
  "created_at": "2020-04-29T03:48:28Z",
  "events_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/90581/events",
  "html_url": "https://github.com/kubernetes/kubernetes/issues/90581",
  "id": 608757589,
  "labels": [
    {
      "color": "e11d21",
      "default": false,
      "description": "Categorizes issue or PR as related to a bug.",
      "id": 105146071,
      "name": "kind/bug",
      "node_id": "MDU6TGFiZWwxMDUxNDYwNzE=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/kind/bug"
    },
    {
      "color": "d2b48c",
      "default": false,
      "description": "Categorizes an issue or PR as relevant to SIG API Machinery.",
      "id": 173493835,
      "name": "sig/api-machinery",
      "node_id": "MDU6TGFiZWwxNzM0OTM4MzU=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/sig/api-machinery"
    }
  ],
  "labels_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/90581/labels{/name}",
  "locked": false,
  "milestone": null,
  "node_id": "MDU6SXNzdWU2MDg3NTc1ODk=",
  "number": 90581,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/kubernetes/kubernetes",
  "state": "closed",
  "title": "Racy usage of sync.Cond in client-go/tools may cause goroutine leaks",
  "updated_at": "2020-05-20T06:40:33Z",
  "url": "https://api.github.com/repos/kubernetes/kubernetes/issues/90581",
  "user": {
    "avatar_url": "https://avatars1.githubusercontent.com/u/9282819?v=4",
    "events_url": "https://api.github.com/users/dopelsunce/events{/privacy}",
    "followers_url": "https://api.github.com/users/dopelsunce/followers",
    "following_url": "https://api.github.com/users/dopelsunce/following{/other_user}",
    "gists_url": "https://api.github.com/users/dopelsunce/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/dopelsunce",
    "id": 9282819,
    "login": "dopelsunce",
    "node_id": "MDQ6VXNlcjkyODI4MTk=",
    "organizations_url": "https://api.github.com/users/dopelsunce/orgs",
    "received_events_url": "https://api.github.com/users/dopelsunce/received_events",
    "repos_url": "https://api.github.com/users/dopelsunce/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/dopelsunce/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/dopelsunce/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/dopelsunce"
  }
}