{
  "active_lock_reason": null,
  "assignee": {
    "avatar_url": "https://avatars2.githubusercontent.com/u/5751682?v=4",
    "events_url": "https://api.github.com/users/brendandburns/events{/privacy}",
    "followers_url": "https://api.github.com/users/brendandburns/followers",
    "following_url": "https://api.github.com/users/brendandburns/following{/other_user}",
    "gists_url": "https://api.github.com/users/brendandburns/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/brendandburns",
    "id": 5751682,
    "login": "brendandburns",
    "node_id": "MDQ6VXNlcjU3NTE2ODI=",
    "organizations_url": "https://api.github.com/users/brendandburns/orgs",
    "received_events_url": "https://api.github.com/users/brendandburns/received_events",
    "repos_url": "https://api.github.com/users/brendandburns/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/brendandburns/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/brendandburns/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/brendandburns"
  },
  "assignees": [
    {
      "avatar_url": "https://avatars2.githubusercontent.com/u/5751682?v=4",
      "events_url": "https://api.github.com/users/brendandburns/events{/privacy}",
      "followers_url": "https://api.github.com/users/brendandburns/followers",
      "following_url": "https://api.github.com/users/brendandburns/following{/other_user}",
      "gists_url": "https://api.github.com/users/brendandburns/gists{/gist_id}",
      "gravatar_id": "",
      "html_url": "https://github.com/brendandburns",
      "id": 5751682,
      "login": "brendandburns",
      "node_id": "MDQ6VXNlcjU3NTE2ODI=",
      "organizations_url": "https://api.github.com/users/brendandburns/orgs",
      "received_events_url": "https://api.github.com/users/brendandburns/received_events",
      "repos_url": "https://api.github.com/users/brendandburns/repos",
      "site_admin": false,
      "starred_url": "https://api.github.com/users/brendandburns/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/brendandburns/subscriptions",
      "type": "User",
      "url": "https://api.github.com/users/brendandburns"
    }
  ],
  "author_association": "MEMBER",
  "body": "```\nW0921 21:05:38.642280   11417 docker.go:265] found a container with the \"k8s\" prefix, but too few fields (2): \"k8s_unidentified\"\nI0921 21:05:38.642486   11417 container_gc.go:140] Removing unidentified dead container \"/k8s_unidentified\" with ID \"2876\"\nI0921 21:05:38.642860   11417 disk_manager.go:114] Running out of space on disk for \"root\": available 0 MB, threshold 250 MB\nI0921 21:05:38.642971   11417 disk_manager.go:114] Running out of space on disk for \"docker\": available 1 MB, threshold 250 MB\nI0921 21:05:38.643086   11417 disk_manager.go:114] Running out of space on disk for \"root\": available 9 MB, threshold 10 MB\nI0921 21:05:38.643267   11417 disk_manager.go:114] Running out of space on disk for \"root\": available 9 MB, threshold 10 MB\nI0921 21:05:38.643675   11417 image_manager.go:255] [ImageManager]: Removing image \"image-0\" to free 1024 bytes\nI0921 21:05:38.643804   11417 image_manager.go:255] [ImageManager]: Removing image \"image-0\" to free 1024 bytes\nI0921 21:05:38.643927   11417 image_manager.go:255] [ImageManager]: Removing image \"image-0\" to free 1024 bytes\nI0921 21:05:38.644042   11417 image_manager.go:255] [ImageManager]: Removing image \"image-0\" to free 1024 bytes\nI0921 21:05:38.644185   11417 image_manager.go:203] [ImageManager]: Disk usage on \"\" () is at 95% which is over the high threshold (90%). Trying to free 150 bytes\nI0921 21:05:38.644229   11417 image_manager.go:255] [ImageManager]: Removing image \"image-0\" to free 450 bytes\nI0921 21:05:38.644305   11417 image_manager.go:203] [ImageManager]: Disk usage on \"\" () is at 95% which is over the high threshold (90%). Trying to free 150 bytes\nI0921 21:05:38.644337   11417 image_manager.go:255] [ImageManager]: Removing image \"image-0\" to free 50 bytes\nW0921 21:05:38.646950   11417 kubelet.go:586] Data dir for pod \"bothpod\" exists in both old and new form, using new\nW0921 21:05:38.647292   11417 kubelet.go:637] Data dir for pod \"newpod\", container \"bothctr\" exists in both old and new form, using new\n--- FAIL: TestSyncLoopAbort-2 (0.00s)\n    kubelet_test.go:346: expected syncLoopIteration to return !ok since update chan was closed\nE0921 21:05:38.663308   11417 kubelet.go:1609] Pod \"_\": HostPort is already allocated, ignoring: [[0].port: duplicate value '81/']\nE0921 21:05:38.664016   11417 kubelet.go:1609] Pod \"newpod_foo\": HostPort is already allocated, ignoring: [[0].port: duplicate value '80/']\nE0921 21:05:38.667189   11417 kubelet.go:1609] Pod \"pod2_\": HostPort is already allocated, ignoring: [[0].port: duplicate value '80/']\nE0921 21:05:38.669280   11417 kubelet.go:1201] Deleting mirror pod \"foo_ns\" because it is outdated\nW0921 21:05:38.673735   11417 kubelet.go:781] Port name conflicted, \"fooContainer-foo\" is defined more than once\nW0921 21:05:38.673801   11417 kubelet.go:781] Port name conflicted, \"fooContainer-TCP:80\" is defined more than once\nE0921 21:05:38.684049   11417 node_manager.go:478] Error updating node status, will retry: error getting node \"127.0.0.1\": Node \"127.0.0.1\" not found\nE0921 21:05:38.684109   11417 node_manager.go:478] Error updating node status, will retry: error getting node \"127.0.0.1\": Node \"127.0.0.1\" not found\nE0921 21:05:38.684211   11417 node_manager.go:478] Error updating node status, will retry: error getting node \"127.0.0.1\": Node \"127.0.0.1\" not found\nE0921 21:05:38.684248   11417 node_manager.go:478] Error updating node status, will retry: error getting node \"127.0.0.1\": Node \"127.0.0.1\" not found\nE0921 21:05:38.684286   11417 node_manager.go:478] Error updating node status, will retry: error getting node \"127.0.0.1\": Node \"127.0.0.1\" not found\nI0921 21:05:38.784666   11417 node_manager.go:279] Node 127.0.0.1 was previously registered\nI0921 21:05:38.784849   11417 plugins.go:56] Registering credential provider: .dockercfg\nI0921 21:05:38.835534   11417 plugins.go:56] Registering credential provider: .dockercfg\nI0921 21:05:38.835691   11417 plugins.go:56] Registering credential provider: .dockercfg\nI0921 21:05:38.886180   11417 plugins.go:56] Registering credential provider: .dockercfg\nW0921 21:05:38.886326   11417 docker.go:275] invalid container hash \"hash123\" in container \"k8s_bar.hash123_foo_new_12345678_0\"\nW0921 21:05:38.886347   11417 docker.go:275] invalid container hash \"hash123\" in container \"k8s_bar.hash123_foo_new_12345678_0\"\nW0921 21:05:38.886361   11417 docker.go:275] invalid container hash \"hash123\" in container \"k8s_POD.hash123_foo_new_12345678_0\"\nW0921 21:05:38.886374   11417 docker.go:275] invalid container hash \"hash123\" in container \"k8s_POD.hash123_foo_new_12345678_0\"\nW0921 21:05:38.886413   11417 docker.go:275] invalid container hash \"hash123\" in container \"k8s_bar.hash123_foo_new_12345678_0\"\nW0921 21:05:38.886453   11417 docker.go:275] invalid container hash \"hash123\" in container \"k8s_bar.hash123_foo_new_12345678_0\"\nW0921 21:05:38.886467   11417 docker.go:275] invalid container hash \"hash123\" in container \"k8s_POD.hash123_foo_new_12345678_0\"\nW0921 21:05:38.886479   11417 docker.go:275] invalid container hash \"hash123\" in container \"k8s_POD.hash123_foo_new_12345678_0\"\nW0921 21:05:38.886524   11417 docker.go:275] invalid container hash \"hash123\" in container \"k8s_bar.hash123_bar_new_98765_0\"\nW0921 21:05:38.886539   11417 docker.go:275] invalid container hash \"hash123\" in container \"k8s_bar.hash123_bar_new_98765_0\"\nW0921 21:05:38.886553   11417 docker.go:275] invalid container hash \"hash123\" in container \"k8s_POD.hash123_foo_new_12345678_0\"\nW0921 21:05:38.886564   11417 docker.go:275] invalid container hash \"hash123\" in container \"k8s_POD.hash123_foo_new_12345678_0\"\nW0921 21:05:38.886594   11417 docker.go:275] invalid container hash \"hash123\" in container \"k8s_POD.hash123_foo_new_12345678_0\"\nW0921 21:05:38.886631   11417 docker.go:275] invalid container hash \"hash123\" in container \"k8s_POD.hash123_foo_new_12345678_0\"\nW0921 21:05:38.886644   11417 docker.go:275] invalid container hash \"hash123\" in container \"k8s_bar.hash123_bar_new_98765_0\"\nW0921 21:05:38.886655   11417 docker.go:275] invalid container hash \"hash123\" in container \"k8s_bar.hash123_bar_new_98765_0\"\nW0921 21:05:38.886693   11417 docker.go:275] invalid container hash \"hash123\" in container \"k8s_bar.hash123_bar_new_12345678_0\"\nW0921 21:05:38.886707   11417 docker.go:275] invalid container hash \"hash123\" in container \"k8s_bar.hash123_bar_new_12345678_0\"\nW0921 21:05:38.886718   11417 docker.go:275] invalid container hash \"hash123\" in container \"k8s_POD.hash123_foo_new_12345678_0\"\nW0921 21:05:38.886729   11417 docker.go:275] invalid container hash \"hash123\" in container \"k8s_POD.hash123_foo_new_12345678_0\"\nW0921 21:05:38.886749   11417 docker.go:275] invalid container hash \"hash123\" in container \"k8s_bar.hash123_bar_new_12345678_0\"\nW0921 21:05:38.886760   11417 docker.go:275] invalid container hash \"hash123\" in container \"k8s_bar.hash123_bar_new_12345678_0\"\nW0921 21:05:38.886772   11417 docker.go:275] invalid container hash \"hash123\" in container \"k8s_POD.hash123_foo_new_12345678_0\"\nW0921 21:05:38.886782   11417 docker.go:275] invalid container hash \"hash123\" in container \"k8s_POD.hash123_foo_new_12345678_0\"\nI0921 21:05:38.887038   11417 plugins.go:56] Registering credential provider: .dockercfg\nI0921 21:05:38.887099   11417 runonce.go:71] waiting for 1 pods\nI0921 21:05:38.887227   11417 runonce.go:135] Container \"bar\" not running: api.ContainerState{Waiting:(*api.ContainerStateWaiting)(0xc2081e9f80), Running:(*api.ContainerStateRunning)(nil), Terminated:(*api.ContainerStateTerminated)(nil)}\nI0921 21:05:38.887250   11417 runonce.go:109] pod \"foo\" containers not running: syncing\nE0921 21:05:38.887882   11417 manager.go:1491] DNS ResolvConfPath is empty.\nI0921 21:05:38.888079   11417 hairpin.go:49] Unable to find pair interface, setting up all interfaces: exec: \"nsenter\": executable file not found in $PATH\nW0921 21:05:38.891155   11417 docker.go:265] found a container with the \"k8s\" prefix, but too few fields (5): \"k8s_net_foo.new.test_abcdefgh_42\"\nI0921 21:05:38.891249   11417 runonce.go:119] pod \"foo\" containers synced, waiting for 1ms\nW0921 21:05:38.892523   11417 docker.go:265] found a container with the \"k8s\" prefix, but too few fields (5): \"k8s_net_foo.new.test_abcdefgh_42\"\nE0921 21:05:38.892555   11417 manager.go:859] Error examining the container: parse docker container name \"/k8s_net_foo.new.test_abcdefgh_42\" error: Docker container name \"k8s_net_foo.new.test_abcdefgh_42\" has less parts than expected [k8s net foo.new.test abcdefgh 42]\nW0921 21:05:38.892673   11417 docker.go:265] found a container with the \"k8s\" prefix, but too few fields (5): \"k8s_net_foo.new.test_abcdefgh_42\"\nI0921 21:05:38.892701   11417 runonce.go:106] pod \"foo\" containers running\nI0921 21:05:38.892717   11417 runonce.go:81] started pod \"foo\"\nI0921 21:05:38.892753   11417 runonce.go:87] 1 pods started\nW0921 21:05:39.253084   11417 connection.go:126] Stream rejected: Unable to parse '' as a port: strconv.ParseUint: parsing \"\": invalid syntax\nW0921 21:05:39.257265   11417 connection.go:126] Stream rejected: Unable to parse 'abc' as a port: strconv.ParseUint: parsing \"abc\": invalid syntax\nW0921 21:05:39.273529   11417 connection.go:126] Stream rejected: Unable to parse '-1' as a port: strconv.ParseUint: parsing \"-1\": invalid syntax\nW0921 21:05:39.277341   11417 connection.go:126] Stream rejected: Unable to parse '65536' as a port: strconv.ParseUint: parsing \"65536\": value out of range\nW0921 21:05:39.281039   11417 connection.go:126] Stream rejected: Port '0' must be greater than 0\nFAIL\n```\n",
  "closed_at": "2015-09-22T20:36:22Z",
  "closed_by": {
    "avatar_url": "https://avatars3.githubusercontent.com/u/8105590?v=4",
    "events_url": "https://api.github.com/users/erictune/events{/privacy}",
    "followers_url": "https://api.github.com/users/erictune/followers",
    "following_url": "https://api.github.com/users/erictune/following{/other_user}",
    "gists_url": "https://api.github.com/users/erictune/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/erictune",
    "id": 8105590,
    "login": "erictune",
    "node_id": "MDQ6VXNlcjgxMDU1OTA=",
    "organizations_url": "https://api.github.com/users/erictune/orgs",
    "received_events_url": "https://api.github.com/users/erictune/received_events",
    "repos_url": "https://api.github.com/users/erictune/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/erictune/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/erictune/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/erictune"
  },
  "comments": 1,
  "comments_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/14309/comments",
  "created_at": "2015-09-21T21:21:57Z",
  "events_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/14309/events",
  "html_url": "https://github.com/kubernetes/kubernetes/issues/14309",
  "id": 107600984,
  "labels": [
    {
      "color": "0052cc",
      "default": false,
      "description": null,
      "id": 178071252,
      "name": "area/test-infra",
      "node_id": "MDU6TGFiZWwxNzgwNzEyNTI=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/area/test-infra"
    },
    {
      "color": "f7c6c7",
      "default": false,
      "description": "Categorizes issue or PR as related to a flaky test.",
      "id": 264749912,
      "name": "kind/flake",
      "node_id": "MDU6TGFiZWwyNjQ3NDk5MTI=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/kind/flake"
    },
    {
      "color": "e11d21",
      "default": false,
      "description": "Highest priority. Must be actively worked on as someone's top priority right now.",
      "id": 114528068,
      "name": "priority/critical-urgent",
      "node_id": "MDU6TGFiZWwxMTQ1MjgwNjg=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/priority/critical-urgent"
    },
    {
      "color": "d2b48c",
      "default": false,
      "description": "Categorizes an issue or PR as relevant to SIG Node.",
      "id": 173493665,
      "name": "sig/node",
      "node_id": "MDU6TGFiZWwxNzM0OTM2NjU=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/sig/node"
    }
  ],
  "labels_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/14309/labels{/name}",
  "locked": false,
  "milestone": null,
  "node_id": "MDU6SXNzdWUxMDc2MDA5ODQ=",
  "number": 14309,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/kubernetes/kubernetes",
  "state": "closed",
  "title": "TestSyncLoopAbort-2  is flaky",
  "updated_at": "2015-09-29T20:50:14Z",
  "url": "https://api.github.com/repos/kubernetes/kubernetes/issues/14309",
  "user": {
    "avatar_url": "https://avatars2.githubusercontent.com/u/7740897?v=4",
    "events_url": "https://api.github.com/users/dchen1107/events{/privacy}",
    "followers_url": "https://api.github.com/users/dchen1107/followers",
    "following_url": "https://api.github.com/users/dchen1107/following{/other_user}",
    "gists_url": "https://api.github.com/users/dchen1107/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/dchen1107",
    "id": 7740897,
    "login": "dchen1107",
    "node_id": "MDQ6VXNlcjc3NDA4OTc=",
    "organizations_url": "https://api.github.com/users/dchen1107/orgs",
    "received_events_url": "https://api.github.com/users/dchen1107/received_events",
    "repos_url": "https://api.github.com/users/dchen1107/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/dchen1107/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/dchen1107/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/dchen1107"
  }
}