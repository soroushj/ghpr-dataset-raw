{
  "active_lock_reason": null,
  "assignee": null,
  "assignees": [],
  "author_association": "CONTRIBUTOR",
  "body": "<!-- Please use this template while reporting a bug and provide as much info as possible. Not doing so may result in your bug not being addressed in a timely manner. Thanks!\r\n\r\nIf the matter is security related, please disclose it privately via https://kubernetes.io/security/\r\n-->\r\n\r\n\r\n**What happened**: Using a pod like the nginx-ing-cntlr with an AWS Network Load Balancer (NLB), and then draining the node its running on to force a migration to another node pool, does not reliably deregister the drained nodes from the NLB Target group. This causes the nodeport used by the NLB to remain open, and the drained node ends up continuing to funnel traffic for other pods cause of `externalTrafficPolicy: Cluster` being used. This leads to connection timeouts for clients, and downtime on migrations.\r\n\r\nSwitching to a Classic ELB, instead of an NLB, with connection draining enabled does work, and the instances that are drained are practically removed immediately from the instances targeted by the ELB, as expected. There seems to be some sort of issue with NLB's as this is not happening, or happening rarely (only saw it once in many tests but couldn't recreate it).\r\n\r\nThe node + LB [sync](https://github.com/kubernetes/kubernetes/blob/master/pkg/controller/service/service_controller.go#L643) set seems to be working as I see in the controller-mgr logs that the nodes are updated as I went from 11 nodes to 8, after attempting to drain + migrate a nodepool of 3 nodes with nginx-ing-cntlr all running on them:\r\n\r\n```\r\nI0630 22:08:34.548236 7 service_controller.go:639] Detected change in list of current cluster nodes. New node set: map[ip-172-16-153-92.us-east-2.compute.internal:\r\n{}\r\nip-172-16-107-18.us-east-2.compute.internal:\r\n{}\r\nip-172-16-131-114.us-east-2.compute.internal:\r\n{}\r\nip-172-16-175-60.us-east-2.compute.internal:\r\n{}\r\nip-172-16-100-188.us-east-2.compute.internal:\r\n{}\r\nip-172-16-110-179.us-east-2.compute.internal:\r\n{}\r\nip-172-16-173-181.us-east-2.compute.internal:\r\n{}\r\nip-172-16-183-203.us-east-2.compute.internal:\r\n{}\r\n]\r\n\uf13f\r\n22:08:34\r\nI0630 22:08:34.845543 7 service_controller.go:647] Successfully updated 6 out of 6 load balancers to direct traffic to the updated set of nodes\r\nI0630 22:08:34.845543 7 service_controller.go:647] Successfully updated 6 out of 6 load balancers to direct traffic to the updated set of nodes\r\n```\r\n\r\nHowever, this update does not seem to be translating into deregistering instances from the NLB. And i've waited minutes & hours in case timeouts were playing a hand, but that didn't seem to help.\r\n\r\n**What you expected to happen**: On node draining, with `externalTrafficPolicy: Cluster` being used, that the NLB would deregister the instances as expected.\r\n\r\n**How to reproduce it (as minimally and precisely as possible)**: Launch a Deployment + NLB service on a node and drain it to force it over to another node pool. Watch the instances in the AWS NLB Target group never get out of \"healthy\" status or be drained + removed.\r\n\r\n**Anything else we need to know?**:\r\n\r\n**Environment**: AWS EKS\r\n- Kubernetes version (use `kubectl version`): 1.12 & 1.13\r\n- Cloud provider or hardware configuration: AWS\r\n- OS (e.g: `cat /etc/os-release`): AWS Linux 2\r\n- Kernel (e.g. `uname -a`): 4.14.123-111.109.amzn2.x86_64\r\n- Install tools:\r\n- Network plugin and version (if this is a network-related bug): core-dns v1.2.6\r\n- Others:\r\n",
  "closed_at": "2020-01-03T15:18:14Z",
  "closed_by": {
    "avatar_url": "https://avatars0.githubusercontent.com/u/20407524?v=4",
    "events_url": "https://api.github.com/users/k8s-ci-robot/events{/privacy}",
    "followers_url": "https://api.github.com/users/k8s-ci-robot/followers",
    "following_url": "https://api.github.com/users/k8s-ci-robot/following{/other_user}",
    "gists_url": "https://api.github.com/users/k8s-ci-robot/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/k8s-ci-robot",
    "id": 20407524,
    "login": "k8s-ci-robot",
    "node_id": "MDQ6VXNlcjIwNDA3NTI0",
    "organizations_url": "https://api.github.com/users/k8s-ci-robot/orgs",
    "received_events_url": "https://api.github.com/users/k8s-ci-robot/received_events",
    "repos_url": "https://api.github.com/users/k8s-ci-robot/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/k8s-ci-robot/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/k8s-ci-robot/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/k8s-ci-robot"
  },
  "comments": 7,
  "comments_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/79581/comments",
  "created_at": "2019-07-01T03:20:22Z",
  "events_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/79581/events",
  "html_url": "https://github.com/kubernetes/kubernetes/issues/79581",
  "id": 462491647,
  "labels": [
    {
      "color": "0052cc",
      "default": false,
      "description": "Issues or PRs related to aws provider",
      "id": 852130657,
      "name": "area/provider/aws",
      "node_id": "MDU6TGFiZWw4NTIxMzA2NTc=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/area/provider/aws"
    },
    {
      "color": "e11d21",
      "default": false,
      "description": "Categorizes issue or PR as related to a bug.",
      "id": 105146071,
      "name": "kind/bug",
      "node_id": "MDU6TGFiZWwxMDUxNDYwNzE=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/kind/bug"
    },
    {
      "color": "604460",
      "default": false,
      "description": "Denotes an issue or PR that has aged beyond stale and will be auto-closed.",
      "id": 778118402,
      "name": "lifecycle/rotten",
      "node_id": "MDU6TGFiZWw3NzgxMTg0MDI=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/lifecycle/rotten"
    },
    {
      "color": "d2b48c",
      "default": false,
      "description": "Categorizes an issue or PR as relevant to SIG Cloud Provider.",
      "id": 958178286,
      "name": "sig/cloud-provider",
      "node_id": "MDU6TGFiZWw5NTgxNzgyODY=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/sig/cloud-provider"
    }
  ],
  "labels_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/79581/labels{/name}",
  "locked": false,
  "milestone": null,
  "node_id": "MDU6SXNzdWU0NjI0OTE2NDc=",
  "number": 79581,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/kubernetes/kubernetes",
  "state": "closed",
  "title": "Draining a node with a pod that uses an AWS NLB does not deregister instances or close the nodeports on said node",
  "updated_at": "2020-09-22T18:46:12Z",
  "url": "https://api.github.com/repos/kubernetes/kubernetes/issues/79581",
  "user": {
    "avatar_url": "https://avatars1.githubusercontent.com/u/1112768?v=4",
    "events_url": "https://api.github.com/users/metral/events{/privacy}",
    "followers_url": "https://api.github.com/users/metral/followers",
    "following_url": "https://api.github.com/users/metral/following{/other_user}",
    "gists_url": "https://api.github.com/users/metral/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/metral",
    "id": 1112768,
    "login": "metral",
    "node_id": "MDQ6VXNlcjExMTI3Njg=",
    "organizations_url": "https://api.github.com/users/metral/orgs",
    "received_events_url": "https://api.github.com/users/metral/received_events",
    "repos_url": "https://api.github.com/users/metral/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/metral/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/metral/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/metral"
  }
}