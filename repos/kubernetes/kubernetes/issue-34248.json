{
  "active_lock_reason": null,
  "assignee": null,
  "assignees": [],
  "author_association": "NONE",
  "body": "**What keywords did you search in Kubernetes issues before filing this one?** (If you have found any duplicates, you should instead reply there.): vSphere, \"message\": \"no endpoints available for service \\\"kube-dns\\\"\", kube-dns, etc -- similar issues include: https://github.com/kubernetes/kubernetes/issues/24407 however it's not quite the same\n\n---\n\n**Is this a BUG REPORT or FEATURE REQUEST?** (choose one): Bug\n\n**Kubernetes version** (use `kubectl version`): \n\n```\nClient Version: version.Info{Major:\"1\", Minor:\"3\", GitVersion:\"v1.3.0\", GitCommit:\"283137936a498aed572ee22af6774b6fb6e9fd94\", GitTreeState:\"clean\", BuildDate:\"2016-07-01T19:26:38Z\", GoVersion:\"go1.6.2\", Compiler:\"gc\", Platform:\"darwin/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"4\", GitVersion:\"v1.4.0\", GitCommit:\"a16c0a7f71a6f93c7e0f222d961f4675cd97a46b\", GitTreeState:\"clean\", BuildDate:\"2016-09-26T18:10:32Z\", GoVersion:\"go1.6.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n```\n\n**Environment**:\n- **Cloud provider or hardware configuration**: vSphere\n- **OS** (e.g. from /etc/os-release): Using provided vmdk\n- **Kernel** (e.g. `uname -a`): `Linux kubernetes-minion-4 3.16.0-4-amd64 #1 SMP Debian 3.16.7-ckt20-1+deb8u2 (2016-01-02) x86_64 GNU/Linux` and `Linux kubernetes-master 3.16.0-4-amd64 #1 SMP Debian 3.16.7-ckt20-1+deb8u2 (2016-01-02) x86_64 GNU/Linux`\n- **Install tools**: GOVC + the `cluster/vsphere/config-default.sh` script\n\n**What happened**: Our environment utilizes the RFC1918 10.0.0.0/8 block, so I edited `cluster/vsphere/config-default.sh` to utilize an address space we are not using. This is my current configuration:\n\n```\nNODE_IP_RANGES=\"192.168.0.0/17\"\nMASTER_IP_RANGE=\"${MASTER_IP_RANGE:-192.168.128.0/17}\"\nSERVICE_CLUSTER_IP_RANGE=\"192.168.120.0/21\"  # formerly PORTAL_NET\nDNS_SERVER_IP=\"192.168.120.120\"\n```\n\nAfter the deployment is finished, I am able to login to the dashboard via the URL provided via `kubectl cluster-info`, however, when I check the DNS server I see:\n\n```\n> curl -sk https://admin:password@10.248.30.36/api/v1/proxy/namespaces/kube-system/services/kube-dns\n{\n  \"kind\": \"Status\",\n  \"apiVersion\": \"v1\",\n  \"metadata\": {},\n  \"status\": \"Failure\",\n  \"message\": \"no endpoints available for service \\\"kube-dns\\\"\",\n  \"reason\": \"ServiceUnavailable\",\n  \"code\": 503\n}\n```\n\nWhen I list services, I see:\n\n```\n> kubectl get svc --namespace=kube-system\nNAME                   CLUSTER-IP        EXTERNAL-IP   PORT(S)         AGE\nkube-dns               192.168.120.120   <none>        53/UDP,53/TCP   50m\nkubernetes-dashboard   192.168.127.194   <none>        80/TCP          50m\n```\n\nWhen I start a container and try to ping kube-dns, I am unable to:\n\n```\n> kubectl exec -ti testing-network-2429464084-8jauq /bin/bash\nroot@testing-network-2429464084-8jauq:/# ping 192.168.120.120\nPING 192.168.120.120 (192.168.120.120) 56(84) bytes of data.\n^C\n--- 192.168.120.120 ping statistics ---\n5 packets transmitted, 0 received, 100% packet loss, time 4032ms\n```\n\nI can ping external IP addresses:\n\n```\n# ping 216.58.192.142\nPING 216.58.192.142 (216.58.192.142) 56(84) bytes of data.\n64 bytes from 216.58.192.142: icmp_seq=1 ttl=50 time=52.0 ms\n64 bytes from 216.58.192.142: icmp_seq=2 ttl=50 time=51.9 ms\n^C\n--- 216.58.192.142 ping statistics ---\n2 packets transmitted, 2 received, 0% packet loss, time 1001ms\nrtt min/avg/max/mdev = 51.968/51.999/52.031/0.230 ms\n```\n\nHere's the configuration on each minion and the master:\n\n```\nMaster - IP: 10.248.30.36\nkube@kubernetes-master:~$ ip ro sh\ndefault via 10.248.30.1 dev eth0\n10.248.30.0/24 dev eth0  proto kernel  scope link  src 10.248.30.36\n172.17.0.0/16 dev docker0  proto kernel  scope link  src 172.17.0.1\n172.18.0.0/16 via 10.248.30.39 dev eth0\n192.168.0.0/24 via 10.248.30.38 dev eth0\n192.168.1.0/24 via 10.248.30.40 dev eth0\n192.168.2.0/24 via 10.248.30.37 dev eth0\n192.168.128.0/17 dev cbr0  proto kernel  scope link  src 192.168.128.1\n\n\nMinion 1 - IP: 10.248.30.38\nkube@kubernetes-minion-1:~$ ip ro sh\ndefault via 10.248.30.1 dev eth0\n10.248.30.0/24 dev eth0  proto kernel  scope link  src 10.248.30.38\n172.17.0.0/16 dev docker0  proto kernel  scope link  src 172.17.0.1\n172.18.0.0/16 via 10.248.30.39 dev eth0\n192.168.0.0/24 dev cbr0  proto kernel  scope link  src 192.168.0.1\n192.168.1.0/24 via 10.248.30.40 dev eth0\n192.168.2.0/24 via 10.248.30.37 dev eth0\n\n\nMinion 2 - IP: 10.248.30.40\nkube@kubernetes-minion-2:~$ ip ro sh\ndefault via 10.248.30.1 dev eth0\n10.248.30.0/24 dev eth0  proto kernel  scope link  src 10.248.30.40\n172.17.0.0/16 dev docker0  proto kernel  scope link  src 172.17.0.1\n172.18.0.0/16 via 10.248.30.39 dev eth0\n192.168.0.0/24 via 10.248.30.38 dev eth0\n192.168.1.0/24 dev cbr0  proto kernel  scope link  src 192.168.1.1\n192.168.2.0/24 via 10.248.30.37 dev eth0\n\nMinion 2 - IP: 10.248.30.37\nkube@kubernetes-minion-3:~$ ip ro sh\ndefault via 10.248.30.1 dev eth0\n10.248.30.0/24 dev eth0  proto kernel  scope link  src 10.248.30.37\n172.17.0.0/16 dev docker0  proto kernel  scope link  src 172.17.0.1\n172.18.0.0/16 via 10.248.30.39 dev eth0\n192.168.0.0/24 via 10.248.30.38 dev eth0\n192.168.1.0/24 via 10.248.30.40 dev eth0\n192.168.2.0/24 dev cbr0  proto kernel  scope link  src 192.168.2.1\n\n\nMinion 4 - IP: 10.248.30.39\nkube@kubernetes-minion-4:~$ ip ro sh\ndefault via 10.248.30.1 dev eth0\n10.248.30.0/24 dev eth0  proto kernel  scope link  src 10.248.30.39\n172.17.0.0/16 dev docker0  proto kernel  scope link  src 172.17.0.1\n192.168.0.0/24 via 10.248.30.38 dev eth0\n192.168.1.0/24 via 10.248.30.40 dev eth0\n192.168.2.0/24 via 10.248.30.37 dev eth0\n192.168.3.0/24 dev cbr0  proto kernel  scope link  src 192.168.3.1\n```\n\n**What you expected to happen**: I expect containers can reach ping eachother.\n\n**How to reproduce it** (as minimally and precisely as possible): I've reproduced this problem using both 172.16.0.0/16 addresses as well as the 192.168.0.0/16 addresses.\n\n**Anything else do we need to know**: I followed the documentation here: http://kubernetes.io/docs/getting-started-guides/vsphere/ and the only change I made was to the network configuration.\n",
  "closed_at": "2016-10-21T13:16:38Z",
  "closed_by": {
    "avatar_url": "https://avatars0.githubusercontent.com/u/13653959?v=4",
    "events_url": "https://api.github.com/users/k8s-github-robot/events{/privacy}",
    "followers_url": "https://api.github.com/users/k8s-github-robot/followers",
    "following_url": "https://api.github.com/users/k8s-github-robot/following{/other_user}",
    "gists_url": "https://api.github.com/users/k8s-github-robot/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/k8s-github-robot",
    "id": 13653959,
    "login": "k8s-github-robot",
    "node_id": "MDQ6VXNlcjEzNjUzOTU5",
    "organizations_url": "https://api.github.com/users/k8s-github-robot/orgs",
    "received_events_url": "https://api.github.com/users/k8s-github-robot/received_events",
    "repos_url": "https://api.github.com/users/k8s-github-robot/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/k8s-github-robot/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/k8s-github-robot/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/k8s-github-robot"
  },
  "comments": 14,
  "comments_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/34248/comments",
  "created_at": "2016-10-06T16:55:06Z",
  "events_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/34248/events",
  "html_url": "https://github.com/kubernetes/kubernetes/issues/34248",
  "id": 181470031,
  "labels": [
    {
      "color": "0052cc",
      "default": false,
      "description": null,
      "id": 128716589,
      "name": "area/kube-proxy",
      "node_id": "MDU6TGFiZWwxMjg3MTY1ODk=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/area/kube-proxy"
    }
  ],
  "labels_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/34248/labels{/name}",
  "locked": false,
  "milestone": null,
  "node_id": "MDU6SXNzdWUxODE0NzAwMzE=",
  "number": 34248,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/kubernetes/kubernetes",
  "state": "closed",
  "title": "vSphere Deployment container communication broken",
  "updated_at": "2016-10-21T17:58:20Z",
  "url": "https://api.github.com/repos/kubernetes/kubernetes/issues/34248",
  "user": {
    "avatar_url": "https://avatars1.githubusercontent.com/u/5529651?v=4",
    "events_url": "https://api.github.com/users/ZedCode/events{/privacy}",
    "followers_url": "https://api.github.com/users/ZedCode/followers",
    "following_url": "https://api.github.com/users/ZedCode/following{/other_user}",
    "gists_url": "https://api.github.com/users/ZedCode/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/ZedCode",
    "id": 5529651,
    "login": "ZedCode",
    "node_id": "MDQ6VXNlcjU1Mjk2NTE=",
    "organizations_url": "https://api.github.com/users/ZedCode/orgs",
    "received_events_url": "https://api.github.com/users/ZedCode/received_events",
    "repos_url": "https://api.github.com/users/ZedCode/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/ZedCode/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/ZedCode/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/ZedCode"
  }
}