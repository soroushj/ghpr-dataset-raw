{
  "active_lock_reason": null,
  "assignee": null,
  "assignees": [],
  "author_association": "MEMBER",
  "body": "At least one user has had issues with this, and I expect more.  It manifests as dropped packets/connections and dmesg show:\n\n```\n[1454500.910215] nf_conntrack: table full, dropping packet\n[1454500.911030] nf_conntrack: table full, dropping packet\n[1454502.184942] nf_conntrack: table full, dropping packet\n[1454502.186097] nf_conntrack: table full, dropping packet\n[1454503.898933] nf_conntrack: table full, dropping packet\n[1454503.899431] nf_conntrack: table full, dropping packet\n[1454505.211093] nf_conntrack: table full, dropping packet\n[1454505.211688] nf_conntrack: table full, dropping packet\n[1454506.507374] nf_conntrack: table full, dropping packet\n[1454506.539645] nf_conntrack: table full, dropping packet\n[1454508.027134] nf_conntrack: table full, dropping packet\n[1454508.027234] nf_conntrack: table full, dropping packet\n[1454509.461080] nf_conntrack: table full, dropping packet\n[1454509.461217] nf_conntrack: table full, dropping packet\n```\n\nMaybe something like:\n\n```\nX=$(cat /proc/sys/net/netfilter/nf_conntrack_max); echo $((X*4)) > /proc/sys/net/netfilter/nf_conntrack_max; echo -n \"was $X; now \"; cat /proc/sys/net/netfilter/nf_conntrack_max\n\nX=$(cat /sys/module/nf_conntrack/parameters/hashsize); echo $((X*4)) > /sys/module/nf_conntrack/parameters/hashsize; echo -n \"was $X; now \"; cat /sys/module/nf_conntrack/parameters/hashsize\n\nX=$(cat /proc/sys/net/netfilter/nf_conntrack_generic_timeout); echo $((X/4)) > /proc/sys/net/netfilter/nf_conntrack_generic_timeout; echo -n \"was $X; now \"; cat /proc/sys/net/netfilter/nf_conntrack_generic_timeout \n\nX=$(cat /proc/sys/net/netfilter/nf_conntrack_tcp_timeout_established); echo $((X/5)) > /proc/sys/net/netfilter/nf_conntrack_tcp_timeout_established; echo -n \"was $X; now \"; cat /proc/sys/net/netfilter/nf_conntrack_tcp_timeout_established\n```\n\nOr maybe we should monitor `nf_conntrack_count` and increase only when needed (it does consume some kernel memory)\n\nLet's keep an eye on this for 1.2.\n",
  "closed_at": "2016-01-02T10:36:18Z",
  "closed_by": {
    "avatar_url": "https://avatars0.githubusercontent.com/u/13653959?v=4",
    "events_url": "https://api.github.com/users/k8s-github-robot/events{/privacy}",
    "followers_url": "https://api.github.com/users/k8s-github-robot/followers",
    "following_url": "https://api.github.com/users/k8s-github-robot/following{/other_user}",
    "gists_url": "https://api.github.com/users/k8s-github-robot/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/k8s-github-robot",
    "id": 13653959,
    "login": "k8s-github-robot",
    "node_id": "MDQ6VXNlcjEzNjUzOTU5",
    "organizations_url": "https://api.github.com/users/k8s-github-robot/orgs",
    "received_events_url": "https://api.github.com/users/k8s-github-robot/received_events",
    "repos_url": "https://api.github.com/users/k8s-github-robot/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/k8s-github-robot/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/k8s-github-robot/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/k8s-github-robot"
  },
  "comments": 8,
  "comments_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/18604/comments",
  "created_at": "2015-12-11T22:50:41Z",
  "events_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/18604/events",
  "html_url": "https://github.com/kubernetes/kubernetes/issues/18604",
  "id": 121807532,
  "labels": [
    {
      "color": "0052cc",
      "default": false,
      "description": null,
      "id": 128716589,
      "name": "area/kube-proxy",
      "node_id": "MDU6TGFiZWwxMjg3MTY1ODk=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/area/kube-proxy"
    },
    {
      "color": "eb6420",
      "default": false,
      "description": "Must be staffed and worked on either currently, or very soon, ideally in time for the next release.",
      "id": 114528223,
      "name": "priority/important-soon",
      "node_id": "MDU6TGFiZWwxMTQ1MjgyMjM=",
      "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/priority/important-soon"
    }
  ],
  "labels_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/18604/labels{/name}",
  "locked": false,
  "milestone": null,
  "node_id": "MDU6SXNzdWUxMjE4MDc1MzI=",
  "number": 18604,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/kubernetes/kubernetes",
  "state": "closed",
  "title": "kube-proxy: increase conntrack limits, decrease timeouts",
  "updated_at": "2017-03-17T21:23:04Z",
  "url": "https://api.github.com/repos/kubernetes/kubernetes/issues/18604",
  "user": {
    "avatar_url": "https://avatars0.githubusercontent.com/u/5595220?v=4",
    "events_url": "https://api.github.com/users/thockin/events{/privacy}",
    "followers_url": "https://api.github.com/users/thockin/followers",
    "following_url": "https://api.github.com/users/thockin/following{/other_user}",
    "gists_url": "https://api.github.com/users/thockin/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/thockin",
    "id": 5595220,
    "login": "thockin",
    "node_id": "MDQ6VXNlcjU1OTUyMjA=",
    "organizations_url": "https://api.github.com/users/thockin/orgs",
    "received_events_url": "https://api.github.com/users/thockin/received_events",
    "repos_url": "https://api.github.com/users/thockin/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/thockin/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/thockin/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/thockin"
  }
}