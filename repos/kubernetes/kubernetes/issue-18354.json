{
  "active_lock_reason": null,
  "assignee": null,
  "assignees": [],
  "author_association": "CONTRIBUTOR",
  "body": "While investigating a socket leak in our kubernetes-deployed application, I have found out that the kube-proxy also seems to have a serious leak of its own.\n\nIn two of my three nodes, out of the ~44K connections of the kube-proxy ....\n\n```\nubuntu@ip-172-20-0-60:~$ sudo netstat -np | grep kube-proxy > netstat.txt\nubuntu@ip-172-20-0-60:~$ wc -l netstat.txt\n44445 netstat.txt\n```\n\n... about 65% are legit established connections caused by the aforementioned leak ...\n\n```\nubuntu@ip-172-20-0-60:~$ grep ESTABLISHED netstat.txt | wc -l\n28922\n```\n\n... but ~14K are in FIN_WAIT2 state ...\n\n```\nubuntu@ip-172-20-0-60:~$ grep FIN_WAIT2 netstat.txt | wc -l\n14544\n```\n\n... and ~1K are in CLOSE_WAIT.\n\n```\nubuntu@ip-172-20-0-60:~$ grep CLOSE_WAIT netstat.txt | wc -l\n977\n```\n\nHere's some debug info:\n- Gist with service descriptions, node descriptions and iptables rules from node `ip-172-20-0-60` (we are running kubernetes 1.1 in AWS): https://gist.github.com/2opremio/24adfa5a10b45b1b77da\n- Goroutine dump of kube-proxy at node `ip-172-20-0-60`, obtained with `curl localhost:10249/debug/pprof/goroutine?debug=2`: [kube-proxy-go-routines.log.gz](https://www.dropbox.com/s/2bfz30z4q7pt5dl/kube-proxy-go-routines.log.gz?dl=1)\n- `sudo netstat -np | grep kube-proxy` at node `ip-172-20-0-60`: [netstat.txt.gz](https://www.dropbox.com/s/1q4ncrf1xzxuj5b/netstat.txt.gz?dl=1)\n- `/proc/sys/net/ipv4/tcp_fin_timeout` has a value of 60 in all my nodes.\n\nAfter deploying the fix for application-level leak and waiting 10 minutes, according to `sudo netstat -np | grep kube-proxy` the number of ESTABLISHED connections is ~100 in all nodes as expected but, in the two affected nodes:\n- The CLOSE_WAIT connections only halve from 1K to 500\n- The FIN_WAIT2 ones also halve from 14K to 7K\n\nI obtained new goroutine and netstat dumps, in case it helps:\n- [kube-proxy-go-routines-after.log.gz](https://www.dropbox.com/s/xxcz0eb5p4l6xqt/kube-proxy-go-routines-after.log.gz?dl=1)\n- [netstat-after.txt.gz](https://www.dropbox.com/s/o6igs1avb01apr1/netstat-after.txt.gz?dl=1)\n\nAlso, it may be valuable to know that the application-level leaks were caused by a websocket proxy (part of the `app-mapper` pods) which failed to clean up connections when the client-side closed the underlying TCP socket. Both the app-mapper and the destination are accessed through kubernetes services, which means that the kube-proxy is caught up in-between:\n\n```\n frontend -> (kube-proxy local to frontend) -> app-mapper -> (kube proxy local to app-mapper) -> destination\n```\n\nThe two kube-proxy instances affected live in the same nodes where the two app-mapper pods live: `ip-172-20-0-60` and `ip-172-20-0-62`\n",
  "closed_at": "2015-12-17T09:33:12Z",
  "closed_by": {
    "avatar_url": "https://avatars0.githubusercontent.com/u/13653959?v=4",
    "events_url": "https://api.github.com/users/k8s-github-robot/events{/privacy}",
    "followers_url": "https://api.github.com/users/k8s-github-robot/followers",
    "following_url": "https://api.github.com/users/k8s-github-robot/following{/other_user}",
    "gists_url": "https://api.github.com/users/k8s-github-robot/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/k8s-github-robot",
    "id": 13653959,
    "login": "k8s-github-robot",
    "node_id": "MDQ6VXNlcjEzNjUzOTU5",
    "organizations_url": "https://api.github.com/users/k8s-github-robot/orgs",
    "received_events_url": "https://api.github.com/users/k8s-github-robot/received_events",
    "repos_url": "https://api.github.com/users/k8s-github-robot/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/k8s-github-robot/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/k8s-github-robot/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/k8s-github-robot"
  },
  "comments": 12,
  "comments_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/18354/comments",
  "created_at": "2015-12-08T15:12:32Z",
  "events_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/18354/events",
  "html_url": "https://github.com/kubernetes/kubernetes/issues/18354",
  "id": 121027349,
  "labels": [],
  "labels_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/18354/labels{/name}",
  "locked": false,
  "milestone": null,
  "node_id": "MDU6SXNzdWUxMjEwMjczNDk=",
  "number": 18354,
  "performed_via_github_app": null,
  "repository_url": "https://api.github.com/repos/kubernetes/kubernetes",
  "state": "closed",
  "title": "Kube-proxy socket descriptor leak",
  "updated_at": "2015-12-17T09:33:12Z",
  "url": "https://api.github.com/repos/kubernetes/kubernetes/issues/18354",
  "user": {
    "avatar_url": "https://avatars0.githubusercontent.com/u/2362916?v=4",
    "events_url": "https://api.github.com/users/2opremio/events{/privacy}",
    "followers_url": "https://api.github.com/users/2opremio/followers",
    "following_url": "https://api.github.com/users/2opremio/following{/other_user}",
    "gists_url": "https://api.github.com/users/2opremio/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/2opremio",
    "id": 2362916,
    "login": "2opremio",
    "node_id": "MDQ6VXNlcjIzNjI5MTY=",
    "organizations_url": "https://api.github.com/users/2opremio/orgs",
    "received_events_url": "https://api.github.com/users/2opremio/received_events",
    "repos_url": "https://api.github.com/users/2opremio/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/2opremio/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/2opremio/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/2opremio"
  }
}